[
  {
    "objectID": "cv.html",
    "href": "cv.html",
    "title": "CV",
    "section": "",
    "text": "R, SQL, Stata\nR is my preferred language and I’m proficient with SQL and Stata\n\n\n\n\nConsulting\nThere are a lot of good questions out there being asked, I like helping figure out how to answer them\n\n\n\n\nReproducible research\nFrom start to finish I like my make sure my reports are reproducible and as automated as possible\n\n\n\n\n\nData cleaning\nWho doesn’t like taking some dirty data and giving it a good scrub\n\n\n\n\nData visualisation\nSure, pictures speak a thousand words, but they might take a thousand lines of code too\n\n\n\n\nGoogling\nThe majority of my R knowledge is self-taught, so I’d say my Google-Fu is pretty good"
  },
  {
    "objectID": "cv.html#skills",
    "href": "cv.html#skills",
    "title": "CV",
    "section": "",
    "text": "R, SQL, Stata\nR is my preferred language and I’m proficient with SQL and Stata\n\n\n\n\nConsulting\nThere are a lot of good questions out there being asked, I like helping figure out how to answer them\n\n\n\n\nReproducible research\nFrom start to finish I like my make sure my reports are reproducible and as automated as possible\n\n\n\n\n\nData cleaning\nWho doesn’t like taking some dirty data and giving it a good scrub\n\n\n\n\nData visualisation\nSure, pictures speak a thousand words, but they might take a thousand lines of code too\n\n\n\n\nGoogling\nThe majority of my R knowledge is self-taught, so I’d say my Google-Fu is pretty good"
  },
  {
    "objectID": "cv.html#qualifications",
    "href": "cv.html#qualifications",
    "title": "CV",
    "section": "Qualifications",
    "text": "Qualifications\n\n\n\nDoctor of Philosophy\nThe University of Melbourne, 2025\nThe Health of Aboriginal Children born in Western Australia in the Context of Out-of-Home Care\n\n\n\n\nMaster of Biostatistics\nThe University of Melbourne, 2018\nElectives in survival analysis, modelling longitudinal and correlated data, and survey design and analysis\n\n\n\n\nBachelor of Arts (Honours)\nUniversity of Western Australia, 2015\nDouble major in psychology, minor in anthropology"
  },
  {
    "objectID": "cv.html#employment",
    "href": "cv.html#employment",
    "title": "CV",
    "section": "Employment",
    "text": "Employment\n\nBiostatistician, Data Manager, Research Fellow\n\nYardhura Walani, Australian National University\n\nOctober 2024 – Present\n\n\nMy work focuses predominantly on the Mayi Kuwayu Study, where I developed a data cleaning pipeline using R that harmonises the raw paper and online survey data, incorporates results of our data audits, performs a series of data validation steps, derives new variables and survey weights, integrates external data, and outputs cleaned datasets. Using this pipeline, I also report on question performance and missingness to inform our questionnaire redesign process.\nI also provide my expertise to multiple other studies and research groups, as well as supervise graduate students and conduct survey methodology research of my own. In my first few months I also took the lead on finishing the study’s operational manual. In doing this, I converted the existing Word draft into a HTML document using Quarto, making the manual more user-friendly, improving the interface, and making the maintenance of documentation easier.\n\n\nQuantitative Social Scientist, Research Fellow\n\nCentre for Indigenous Policy Research, Australian National University\n\nOctober 2023 – October 2024\n\n\nIn my short time at CIPR I worked on two major reports. For the first, I examined social and emotional wellbeing for Aboriginal and Torres Strait Islander children and youth in the Longitudinal Study of Indigenous Children (LSIC). Starting with an Aboriginal and Torres Strait Islander theory of social and emotional wellbeing, I used exploratory factor analysis and structural equation modelling to map data items in LSIC to different domains of social and emotional wellbeing.\nThe second was a technical report commissioned by the Productivity Commission and Coalition of Peaks, where my co-authors and I proposed a more statistically rigorous method for measuring progress toward Closing the Gap targets. The report covered improvements in measuring progress, recommendations for increasing the quality, frequency, and relevance of data collected for these measures, and guidelines on how to communicate probabilistic statements from statistical models in easy to understand ways.\n\n\nPhD Candidate\n\nIndigenous Health and Epidemiology Group, University of Melbourne\n\nMarch 2020 – June 2024\n\n\nThroughout my PhD I translated findings from Aboriginal-led qualitative research and community reference group conversations into questions I could address using linked administrative datasets. This included how contacts by child protective services are clustered within sibling groups, the prevalence and cumulative incidence of mental and neurodevelopmental health conditions, and estimating the effect of placement in out-of-home care on rates of potentially preventable hospitalisations.\nI used a variety of statistical methods, including descriptive statistics, various regression models, survival analysis, and matching methods. All of my research was written in R and RMarkdown, where I created a reproducible pipeline from data cleaning through to multiple journal articles and my final thesis.\n\n\nBiostatistician\n\nDeakin University\n\nAugust 2022 – October 2023\n\nGrampians Health\n\nSeptember 2021 – October 2023\n\n\nIn these two biostatistician roles I acted as the sole statistical expert in clinical research and academic settings. Across these roles I provided study design and statistical oversight for a randomised trials, including sample size calculations, developing statistical analysis plans and randomisation schemes, advising on technical challenges arising, and analysing trial data. I also developed educational materials and delivered seminars for clinicians on the topic of good research practices."
  },
  {
    "objectID": "cv.html#volunteering",
    "href": "cv.html#volunteering",
    "title": "CV",
    "section": "Volunteering",
    "text": "Volunteering\n\nWearer of Many Hats\n\nStatistical Society of Australia\n\nDecember 2018 – Present\n\n\nCurrently I’m the Vice President of the SSA. Since joining back in 2018, I have taken on many different voluntary roles, including:\n\nSecretary and then President of the Victorian and Tasmanian Branch\nCoordinator of the 2021 Early Career and Student Statisticians Conference\nCommittee member and Secretary of the Equity, Diversity, and Inclusion (EDI) committee\nCommittee member of the Reconciliation Action Plan committee\nMentor in the SSA’s Mentoring Program\n\nAcross these roles I coordinated strategic planning, managed teams, maintained relationships with external organisations, surveyed and reported on EDI in the Australian statistics profession, and wrote EDI recommendations for the Society."
  },
  {
    "objectID": "cv.html#research-supervision",
    "href": "cv.html#research-supervision",
    "title": "CV",
    "section": "Research supervision",
    "text": "Research supervision\n\nCurrent\nDoctor of Philosophy — Sedgwick, M., Understanding the Health and Wellbeing of Aboriginal and Torres Strait Islander Peoples with Disability.\nMaster of Applied Epidemiology — Moreton, K., TBC.\n\n\nCompleted\nPsychology Honours — Madeley, B., Intentions and preferences of adults with diabetes toward seeking psychological support, 2022.\nPsychology Honours — Chhatiawala, A., Differences in coping self-efficacy between adults with type 1 and type 2 diabetes and the association with emotional-well-being, 2022.\nMaster of Medicine — Haussegger, Z., Sleep and Mental Health in Aboriginal and Torres Strait Islander Young People: A retrospective data analysis, 2021.\nMaster of Medicine — Moffroid, H., ‘Next Generation Youth Well-being Study:’ The importance of cultural connectedness for Aboriginal adolescent health and wellbeing., 2021."
  },
  {
    "objectID": "cv.html#awards",
    "href": "cv.html#awards",
    "title": "CV",
    "section": "Awards",
    "text": "Awards\n2025 Bruce Lord Award for Excellence in Research Methodology — Australian Association of Social Workers\n2023 T-shirt design competition winner — Australian Statistical Conference\n2022 President’s Award for Leadership in Statistics — Statistical Society of Australia\n2021 T-shirt design competition winner — Statistical Society of Australia"
  },
  {
    "objectID": "cv.html#memberships-and-accreditations",
    "href": "cv.html#memberships-and-accreditations",
    "title": "CV",
    "section": "Memberships and Accreditations",
    "text": "Memberships and Accreditations\nStatistical Society of Australia\nAccredited Graduate Statistician, Statistical Society of Australia\nInternational Population Data Linkage Network\nInternational Society of Non-Binary Scientists"
  },
  {
    "objectID": "cv.html#professional-development",
    "href": "cv.html#professional-development",
    "title": "CV",
    "section": "Professional Development",
    "text": "Professional Development\n\nWorkshops\n\n2024\nSpatial Analysis in R — Australian Consortium for Social and Political Research Incorporated\nWorking Smarter with Targets presented by Miles McBain — Statistical Society of Australia\n\n\n2021\nA Crash Course in SQL — Statistical Society of Australia\nAMSI Winter School for Statistical Data Science — Australian Mathematical Sciences Institute\n\n\n2020\nData wrangling with R — Statistical Society of Australia\nData visualisation with R — Statistical Society of Australia\nSemiparametric regression in R — Statistical Society of Australia\n\n\n\nConferences\n\n2025\nGlobal Indigenous Data Sovereignty Conference — Attendee\n\n\n2023\nAustralian Statistical Conference and Australian Conference on Teaching Statistics — Attendee\nAboriginal and Torres Strait Islander Mathematics Alliance Conference — Attendee\n\n\n2022\nInternational Population Data Linkage Network Conference — Presenter\n\n\n2021\n9th SNAICC Annual Conference — Attendee\nThe Early Career and Student Statisticians Conference — Presenter\n\n\n2020\nInternational Population Data Linkage Network Conference — Attendee\n\n\n2018\nInternational Metropolis Conference — Presenter\nJoint International Society for Clinical Biostatistics and Australian Statistical Conference — Attendee\nUseR! Conference Brisbane — Attendee"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ben Harrap",
    "section": "",
    "text": "Biostatistics, quantitative social science, data science. There’s a lot of names to describe what I do, which, fundamentally, is things with data. I love thinking about data in the real-world; how our worldview impacts data collection decisions, how data are used in a research context, and how I can best use data to help people answer questions they have. At the end of the day, I want to contribute to research that ends up improving the lives of others.\nI also think it’s important that Aboriginal and Torres Strait Islander people are leading the research agenda — my place as a non-Indigenous person is to listen, collaborate, and support that agenda as best I can with the skills that I have."
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Ben Harrap",
    "section": "",
    "text": "Biostatistics, quantitative social science, data science. There’s a lot of names to describe what I do, which, fundamentally, is things with data. I love thinking about data in the real-world; how our worldview impacts data collection decisions, how data are used in a research context, and how I can best use data to help people answer questions they have. At the end of the day, I want to contribute to research that ends up improving the lives of others.\nI also think it’s important that Aboriginal and Torres Strait Islander people are leading the research agenda — my place as a non-Indigenous person is to listen, collaborate, and support that agenda as best I can with the skills that I have."
  },
  {
    "objectID": "index.html#my-interests",
    "href": "index.html#my-interests",
    "title": "Ben Harrap",
    "section": "My interests",
    "text": "My interests\n\nAboriginal and Torres Strait Islander health and wellbeing\nIndigenous Data Sovereignty and Governance\nData collection and survey design\nStatistical consulting\nData literacy"
  },
  {
    "objectID": "post/2022-11-29-joke/index.html",
    "href": "post/2022-11-29-joke/index.html",
    "title": "What do you call music composed by apes?",
    "section": "",
    "text": "A chimphony"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html",
    "href": "post/2023-07-17-intro-to-research/index.html",
    "title": "A brief introduction to research for health professionals",
    "section": "",
    "text": "I originally did this talk for Ballarat Health Services (now Grampians Health) back in 2021. I’d intended to upload the recording but unfortunately it didn’t materialise! Instead I’ve put the material from the talk here. I was first asked to do a ‘Stats 101’ talk for clinicians, but I don’t think that’s ever going to be useful. So instead, I wrote this talk to try and address the most common problems I face as a consultant biostatistician."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#lets-work-together",
    "href": "post/2023-07-17-intro-to-research/index.html#lets-work-together",
    "title": "A brief introduction to research for health professionals",
    "section": "Let’s work together",
    "text": "Let’s work together\n\nThe first thing that I want to acknowledge is that your time is precious and limited - I’m frankly amazed at your ability to fit research into your already busy jobs. It’s a testament to the passion and interest that you all have in learning and improving your practice. So given your busy when we work together I’ll do my best to work around your schedule and capacity.\nWhen we are working together, you bring your clinical expertise and content knowledge to the table along with a question you think is important. I bring my statistical and methodological expertise that can help answer your question and my main goal is to help you do the best research that you can.\nNow because I don’t have your clinical background, when we’re working together I’m going to have to ask you a lot of questions at the beginning to make sure I understand what the clinical context is. This is really important for me to be able to guide us towards a study design or analysis method that’s going to help answer the question that you have.\nI’m not trying to make your life difficult by asking you 20 questions, I promise. I do want to note though that in the process of asking you 20 questions it’s not unlikely that your original question will change slightly, perhaps due to some constraint of available data or the number of people that’s feasible to recruit into your study, or some other reason. Don’t be disheartened when this happens, it’s a good thing - we’re refining your research question into something workable!"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician",
    "href": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician",
    "title": "A brief introduction to research for health professionals",
    "section": "When to talk to me (or any statistician)",
    "text": "When to talk to me (or any statistician)\n\nQuite often I’ll have people come seek my help after they’ve already done the data collection."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician-1",
    "href": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician-1",
    "title": "A brief introduction to research for health professionals",
    "section": "When to talk to me (or any statistician)",
    "text": "When to talk to me (or any statistician)\n\nIf you come to me only at the data analysis stage, the chances of me being able to help are low! Come and see me before then."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician-2",
    "href": "post/2023-07-17-intro-to-research/index.html#when-to-talk-to-me-or-any-statistician-2",
    "title": "A brief introduction to research for health professionals",
    "section": "When to talk to me (or any statistician)",
    "text": "When to talk to me (or any statistician)\n\nI can help at all of these stages, but we should start chatting at the very early stages of your research.\nThis is a broad overview of the different stages of research. We start off at the research question formulation stage and progress through each stage sequentially.\nQuite often people progress through these stages and only talk to a statistician at the analysis stage. Having been in this situation a number of times I can tell you that it’s really challenging to be able to help. More often than not it turns out that I can’t answer the research question with the data that’s been gathered, and this is frustrating for everyone involved. So please try to involve a statistician earlier on.\nIf you come to me early on in the planning phase we can work together to create a comprehensive methods section of the protocol and set your study up for success. Once we’ve done this it will be much easier for myself, or another statistician, or even yourself, to be able to perform the analysis."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#lets-start-at-the-start",
    "href": "post/2023-07-17-intro-to-research/index.html#lets-start-at-the-start",
    "title": "A brief introduction to research for health professionals",
    "section": "Let’s start at the start",
    "text": "Let’s start at the start\n\nLet’s start off at the research question stage. It’s really important to think carefully and come up with a very explicit research question. It’s OK to start off with some general ideas for what you’re interested in but you need to pin down exactly what you are trying to find out and write this as a research question. Once you’ve figured this question out it’s a good time to come and chat to me"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#think-carefully-about-your-research-question",
    "href": "post/2023-07-17-intro-to-research/index.html#think-carefully-about-your-research-question",
    "title": "A brief introduction to research for health professionals",
    "section": "Think carefully about your research question",
    "text": "Think carefully about your research question\nA handy framework to use in creating a research question is the PICOT:\n\nPopulation - who are you interested in?\nIntervention - what is the intervention or exposure?\nComparator - are you comparing to a control group, a different treatment?\nOutcome - what is the outcome of interest?\nTime - how long are you following people up for?\n\nThis framework might not work in all cases but it is a helpful place to start"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example",
    "text": "PICOT example\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example---population",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example---population",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example - Population",
    "text": "PICOT example - Population\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example---intervention",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example---intervention",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example - Intervention",
    "text": "PICOT example - Intervention\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example---comparator",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example---comparator",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example - Comparator",
    "text": "PICOT example - Comparator\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example---outcome",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example---outcome",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example - Outcome",
    "text": "PICOT example - Outcome\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#picot-example---timeframe",
    "href": "post/2023-07-17-intro-to-research/index.html#picot-example---timeframe",
    "title": "A brief introduction to research for health professionals",
    "section": "PICOT example - Timeframe",
    "text": "PICOT example - Timeframe\nIs a pedometer and activity coaching intervention effective in limiting gestational weight gain in obese pregnant women compared to a pedometer with self-managed activity over the course of their pregnancy.\n\nP - Obese women\nI - pedometer and activity coaching intervention\nC - a pedometer with self-managed activity\nO - gestational weight gain\nT - over the course of their pregnancy\n\nI want to point out that coming up with good and concise research questions really is a skill and it takes practice. I find it’s much easier to just write a general version of your research question - a rough draft - and workshop it into something specific"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#study-designs",
    "href": "post/2023-07-17-intro-to-research/index.html#study-designs",
    "title": "A brief introduction to research for health professionals",
    "section": "Study designs",
    "text": "Study designs\nObservational studies:\n\nCross-sectional (single measurement)\nCase-control study\nCohort study:\n\nRetrospective cohort\nProspective cohort\n\n\nExperimental studies:\n\nRandomised studies\nNon-randomised studies\n\nIt can also help to consider what the right study design is to answer your research question. Different studies require different levels of involvement. I already know that you’re incredibly busy outside of trying to do research, so thinking about how much time you have available is important. I wouldn’t suggest committing to a randomised controlled trial if you or your colleagues haven’t got the time to drive it. Not everything needs to be a randomised controlled trial\nCross-sectional studies are relatively easy, there’s no follow up, no risk of people dropping out. However you can’t determine cause and effect. Useful for hypothesis generation, can be done using medical records (e.g. taking a cross-section of patients who attended your clinic during 2020). So if we were to think of the pedometer study as a cross section, we might just take a cross section of pregnant women and ask them if they have a pedometer or not and measure their weight.\nSelecting people based on their outcome status and obtain information on any exposures retrospectively. Can be done using medical records, but deciding on an appropriate ‘control’ group can be challenging. To fit the pedometer study into this framework we’d have to first define what “excessive gestational weight gain” is, then we could use medical records from a group of women visiting the maternity unit and somehow figure out if they had a pedometer\nIdentification of a cohort of people without your outcome of interest at some baseline and following them up over time. Tend to be harder to run, suffer from people dropping out of the study\nFor a prospective cohort, perhaps we ask women whether they have a pedometer on their first visit to the maternity unit then we keep track of their weight over the course of their visits to the unit.\nRandomised studies:\nPeople with characteristics or health conditions of interest are recruited into a study and randomly allocated to one or more groups, then followed up over time to see what their outcomes are. These studies also tend to be costly and harder to run but are important for estimating cause and effect of treatments.\nSo for the pedometer study again, we could recruit pregnant women who visit the maternity unit and randomise them to one of our treatment groups, keeping track of their activity and weight over the course of their pregnancy, then analyse the results at the conclusion of the study.\nSometimes not always feasible to run a randomised trial though - e.g. we wouldn’t want to randomise someone to an exposure group where we force them to smoke cigarettes to examine lung cancer rates.\nNon-randomised studies:\nAn example of a non-randomised study design is a ‘before and after’ study, where we might only use one intervention and take a measurement of our outcome of interest before and after our the intervention is administered. In this example there is no randomisation and we assume any changes in our outcome are due to the implementation of the intervention."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#the-protocol",
    "href": "post/2023-07-17-intro-to-research/index.html#the-protocol",
    "title": "A brief introduction to research for health professionals",
    "section": "The protocol",
    "text": "The protocol"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#the-protocol-1",
    "href": "post/2023-07-17-intro-to-research/index.html#the-protocol-1",
    "title": "A brief introduction to research for health professionals",
    "section": "The protocol",
    "text": "The protocol\nUse the template: https://www.bhs.org.au/media/koli42au/protocol-template-2018.docx\n\nUse the template for your protocol. It’s helpful, makes it easy to fill in, and is standardised to include all the information you’d expect to find in a protocol.\nYour protocol outlines exactly why and how you (and your collaborators) are going to run the study.\nIt’s a reference framework to guide each step of your study\nIf you disappeared in the middle of your study, someone else should be able to pick up your protocol and see the study through to the end.\nIf people want to replicate your study in another setting, the protocol should contain sufficient detail to enable them to do so.\nThe protocol is also what the ethics committee are going to review to determine whether your research proposal is methodologically sound as well as feasible"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#ethics",
    "href": "post/2023-07-17-intro-to-research/index.html#ethics",
    "title": "A brief introduction to research for health professionals",
    "section": "Ethics",
    "text": "Ethics"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#ethics-1",
    "href": "post/2023-07-17-intro-to-research/index.html#ethics-1",
    "title": "A brief introduction to research for health professionals",
    "section": "Ethics",
    "text": "Ethics\nWe need ethics and research governance approval:\n\nBefore we analyse the data\nBefore we collect any data\nBefore we start recruiting participants\nBefore we access registry data\n\nhttps://www.bhs.org.au/research/ethics-and-research-governance/\nHospital records and other administrative data aren’t collected for the purpose of research, so just because we have access to the data it doesn’t mean that we can start extracting and analysing it"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#plan-your-data-collection",
    "href": "post/2023-07-17-intro-to-research/index.html#plan-your-data-collection",
    "title": "A brief introduction to research for health professionals",
    "section": "Plan your data collection",
    "text": "Plan your data collection"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#plan-your-data-collection-1",
    "href": "post/2023-07-17-intro-to-research/index.html#plan-your-data-collection-1",
    "title": "A brief introduction to research for health professionals",
    "section": "Plan your data collection",
    "text": "Plan your data collection\nIf we are relying on existing data:\n\nPlan in advance which variables we need\nWho is extracting the data?\nIs measurement consistent across time?\n\nIf we are collecting new data:\n\nThink about how we will measure things (instruments, surveys, etc.)\nPilot these measures to make sure they work the way we expect\nOne column per variable\nOne row per observation\n\nPlan in advance. Make a list of variables we need based on your research question and compare them against the reference material or data dictionary for the data source. If the question can’t be answered by the available data we’ll need to change the question or the data source.\nWho is extracting the data? Is it just you? Are multiple people extracting data? We need to make sure everyone is on the same page about what data we need so we end up with consistent and usable data\nIs measurement consistent across time? One of the challenges of using existing data, especially administrative and routinely collected data, is that if an operational change occurs that affects the way data is collected and we don’t know about it we can end up drawing spurious conclusions based on artefacts of the data.\nAre we using a previously validated measure? Are we designing from scratch? Do we need to pilot the measure? Is the measure appropriate for the population we’re interested in? What are the range of values we expect to measure? Do the instruments capture this range?\nThis is especially important if we’re getting people to fill in the information themselves. If the question is confusing or vague, we’ll end up with a variety of data in formats we weren’t expecting or cannot use. This could be as simple as telling people what date format to use when writing the date."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\nHere’s a typical (made up) example of a spreadsheet I might receive\n\nLet’s go through some of the issues!"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-1",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-1",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nDon’t use colour coding in spreadsheets - my analysis programs can’t see it! Instead create a column to represent that information."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-2",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-2",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nWhat’s this cell highlighted for? Don’t encode other important information using colours either - create a column to put comments in"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-3",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-3",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nThere’s a lot of information in this one column! Instead split it into multiple columns"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-4",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-4",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nThis looks like a typo! Be mindful of manually entering data"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-5",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-5",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nBe careful not to include useless identifiable data in the spreadsheet - that goes for email addresses, names, patient numbers, and more!"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-6",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-6",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nIt’s important to make it clear what an empty cell means. Was there no information to record? Write this! Otherwise we can’t tell if we just forgot to record the data, or if there’s another reason it’s missing."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-7",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-7",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nIf multiple people are collecting data make sure you’re all collecting it consistently. Dates are often the biggest problem - some people record D/M/Y, some people record M/D/Y. It doesn’t matter what format you use as long as it’s consistent."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-8",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-8",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nThese two variables have the same name, but they have different values? Maybe they were BMI at baseline and follow-up, but this needs to be explicit in the column names!"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-9",
    "href": "post/2023-07-17-intro-to-research/index.html#data-collection-tips-9",
    "title": "A brief introduction to research for health professionals",
    "section": "Data collection tips",
    "text": "Data collection tips\n\nThis dataset looks much better. One column per variable, one row per observation (in this case a person), no identifying information, no unnecessary information\nArguably the frequency column could be further split into two variables, one for the number of tablets, one for the frequency in days."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#make-a-data-dictionary",
    "href": "post/2023-07-17-intro-to-research/index.html#make-a-data-dictionary",
    "title": "A brief introduction to research for health professionals",
    "section": "Make a data dictionary",
    "text": "Make a data dictionary\nA data dictionary should include:\n\nThe name of the variable (e.g. height or blood pressure)\nThe units of measurement (e.g. cm or mmHg)\nThe range of values that are possible or plausible (e.g. 50cm to 250cm)\nA description of the variable (e.g. the highest of three sitting diastolic blood pressure measurements)\nAny important notes on the data (e.g. whether the variable was self-reported, whether the measurement device changed halfway through data collection)"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#example-data-dictionary",
    "href": "post/2023-07-17-intro-to-research/index.html#example-data-dictionary",
    "title": "A brief introduction to research for health professionals",
    "section": "Example data dictionary",
    "text": "Example data dictionary\n\n\n\n\n\nVariable\nUnits\nRange\nDescription\nNotes\n\n\n\n\nid\n\n1 to 8\nUnique identifier for each participant\n\n\n\ngroup\n\n1 to 2\nParticipant's randomly allocated group\n\n\n\nbmi_baseline\nkg/m^2\n10 to 50\nParticipant's BMI at baseline\n\n\n\nbmi_followup\nkg/m^2\n10 to 50\nParticipant's BMI at the study endpoint\n\n\n\ndrug\n\nRosuvastatin, Atorvastatin\nBrand of statin administered\n\n\n\ndose\nmg\n5 to 20\nPrescribed dosage in mg of the medication\n5mg of Rosuvastatin is equivalent to 10mg of Atorvastatin"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-types",
    "href": "post/2023-07-17-intro-to-research/index.html#data-types",
    "title": "A brief introduction to research for health professionals",
    "section": "Data types",
    "text": "Data types\n\nNominal - Categories that have no inherent order\n\nE.g. Gender or blood type or group allocation\n\nOrdinal - Categories that have an order\n\nE.g. Level of mobility (poor, average, good) and Likert scales\n\nInterval - Continuously valued data with no meaningful zero, where the difference between values is equal\n\nE.g. Temperature in celsius\n\nRatio - Like interval data except there is a meaningful zero\n\nE.g. Age or blood pressure or drug dosage\n\n\nFor nominal data there isn’t any ordering, they’re just different categories. There isn’t any order to blood types.\nFor Likert scales, this means scales like “Strongly disagree, disagree, neutral, agree, strongly agree”. In this example there’s a clear ordering going from the strongest level of disagreement through to the strongest level of agreement. Strongly disagree isn’t ‘twice as disagreeable’ just disagree, but there’s an order to options such that we could rank them in some way.\nThe point about no meaningful zero is important - for example with temperature the difference between 10 and 20 degrees celsius is the same as 20 and 30 degrees celsius - it’s a difference of 10 units in both cases. However, we wouldn’t say that 20 degrees is twice as hot as 10 degrees.\nThinking about the previous example where we couldn’t make statements about something being twice as much, for ratio data we can make those statements. For example, someone age 40 is twice the age of someone aged 20. The zero is also meaningful here as it indicates a complete absence - for example a drug dose of zero means no drug."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-security",
    "href": "post/2023-07-17-intro-to-research/index.html#data-security",
    "title": "A brief introduction to research for health professionals",
    "section": "Data security",
    "text": "Data security\nThis is very important\nWhen collecting study data, we must:\n\nDeidentify data and keep records\nHave a data storage and disposal plan in your protocol\nDo what we say we will in the protocol\nAdhere to privacy requirements of the BHS research office\nBe able to demonstrate we took reasonable steps to ensure the security of your data\n\nWe must not:\n\nStore identifiable data in a non-password-protected spreadsheet or restricted folder\nShare data with people not on the ethics approval\nSend data in an unsecure manner, e.g. emailing someone a non-password protected dataset\nSend data to personal email addresses or storage platforms"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-analysis",
    "href": "post/2023-07-17-intro-to-research/index.html#data-analysis",
    "title": "A brief introduction to research for health professionals",
    "section": "Data analysis",
    "text": "Data analysis"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#data-analysis-1",
    "href": "post/2023-07-17-intro-to-research/index.html#data-analysis-1",
    "title": "A brief introduction to research for health professionals",
    "section": "Data analysis",
    "text": "Data analysis\nI don’t have slides on how to do data analysis, mainly because I’m hesitant to give a set of rote instructions saying “if you have this data do this analysis” as this can lead to doing analysis without thinking about it\nAfter all, you can do an entire degree on how to do data analysis and still not know everything - trust me on this one! Hopefully though we’ve done enough planning in the protocol and the study has gone smoothly enough that the data analysis is simply doing what we said we’d do."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect",
    "href": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect",
    "title": "A brief introduction to research for health professionals",
    "section": "No study is perfect",
    "text": "No study is perfect\nJust like baking, you might set out to make the perfect cake"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect-1",
    "href": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect-1",
    "title": "A brief introduction to research for health professionals",
    "section": "No study is perfect",
    "text": "No study is perfect\nBy coming to talk to me first, we can avoid disasters…"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect-2",
    "href": "post/2023-07-17-intro-to-research/index.html#no-study-is-perfect-2",
    "title": "A brief introduction to research for health professionals",
    "section": "No study is perfect",
    "text": "No study is perfect\nAnd produce something pretty reasonable instead!"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#p-values-forget-about-them",
    "href": "post/2023-07-17-intro-to-research/index.html#p-values-forget-about-them",
    "title": "A brief introduction to research for health professionals",
    "section": "P-values, forget about them!",
    "text": "P-values, forget about them!\nThe p-value is the most commonly misused and misinterpreted statistic\n\nSmall p-value doesn’t mean we found something\nConversely, a large p-values doesn’t mean there is no effect\nReport confidence intervals instead\nThink about clinical significance instead\n\nAlso, don’t put p-values in the baseline/descriptive characteristics table. It’s not useful or necessary.\nThere’s also no such thing as “trending to significance” - I often see it written “p=0.051 there was a trend towards significance”. There’s absolutely no guarantee that if you collected more data your p-value would get smaller and ‘become significant’. Remembering that statistical significance is not anywhere near as important as you think it is.\nFurther reading:\nGreenland, S., Senn, S.J., Rothman, K.J., Carlin, J.B., Poole, C., Goodman, S.N. and Altman, D.G., 2016. Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations. European journal of epidemiology, 31, pp.337-350.\nAltman, D.G. and Bland, J.M., 1995. Statistics notes: Absence of evidence is not evidence of absence. Bmj, 311(7003), p.485."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#drawing-conclusions-from-exploratory-analysis",
    "href": "post/2023-07-17-intro-to-research/index.html#drawing-conclusions-from-exploratory-analysis",
    "title": "A brief introduction to research for health professionals",
    "section": "Drawing conclusions from exploratory analysis",
    "text": "Drawing conclusions from exploratory analysis\nDon’t analyse every single relationship then report a finding based on a small p-value\n\nEven if you use multiple testing ‘corrections’\nUse exploratory analysis for hypothesis generation\n\nWhat I mean by exploratory analysis is any time you do not have a pre-specified question or analysis and are ‘exploring’ the data you’ve collected by seeing what variables have relationships (for example a correlation).\nEven if you correct for multiple hypothesis tests you are still open to drawing false conclusions based on p-values - your ‘significance threshold’ might now be 0.0001. You will unfortunately end up being even more confident in a finding that is spurious because you thought the multiple testing adjustment meant you wouldn’t make that error."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#choosing-variables-for-analysis",
    "href": "post/2023-07-17-intro-to-research/index.html#choosing-variables-for-analysis",
    "title": "A brief introduction to research for health professionals",
    "section": "Choosing variables for analysis",
    "text": "Choosing variables for analysis\nDon’t pick variables based on p-values.\nInstead, give careful consideration about what variables are important to your outcome.\nA common practice is to do a whole bunch of statistical tests between different variables and your outcome and pick the ones with small p-values to go in your main analysis. This includes methods like stepwise regression. Don’t do it. Doing this can cause you to leave out critical variables which you know are prognostic of your outcome.\nFurther reading:\nSmith, G., 2018. Step away from stepwise. Journal of Big Data, 5(1), pp.1-12.\nSun, G.W., Shook, T.L. and Kay, G.L., 1996. Inappropriate use of bivariable analysis to screen risk factors for use in multivariable analysis. Journal of clinical epidemiology, 49(8), pp.907-916."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#post-hoc-power-calculation",
    "href": "post/2023-07-17-intro-to-research/index.html#post-hoc-power-calculation",
    "title": "A brief introduction to research for health professionals",
    "section": "Post-hoc power calculation",
    "text": "Post-hoc power calculation\nAfter finding a ‘null’ result (i.e. big p-value), some people suggest doing post-hoc power calculations\nDon’t do them, they just re-present the p-value in a different way:\n\nA small p-value will come back with ‘high power’\nA large p-value will come back with ‘low power’\n\nInstead do adequate sample size calculations at the planning stage of your study\nFurther reading:\nGoodman, S.N. and Berlin, J.A., 1994. The use of predicted confidence intervals when planning experiments and the misuse of power when interpreting results. Annals of internal medicine, 121(3), pp.200-206.\nHoenig, J.M. and Heisey, D.M., 2001. The abuse of power: the pervasive fallacy of power calculations for data analysis. The American Statistician, 55(1), pp.19-24."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#sample-size-calculation",
    "href": "post/2023-07-17-intro-to-research/index.html#sample-size-calculation",
    "title": "A brief introduction to research for health professionals",
    "section": "Sample size calculation",
    "text": "Sample size calculation\nSample size calculations are not just about using an online calculator to come up with a number\n\nYou need to consider drop-out rates\nConsider the feasibility of the sample size. Do you have the time or staff to be able to recruit and process the number of participants needed?\nCosts of recruiting participants. A basic estimate might say you need to recruit more participants that you have funding for.\nConsider prior research. Considering what previous studies have found is a good place to start for thinking how much of an effect you think a treatment might have.\nConsider clinical significance. How much of a change would we need to see in your outcome to make a case for changing practice?"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#dichotomising-continuous-variables",
    "href": "post/2023-07-17-intro-to-research/index.html#dichotomising-continuous-variables",
    "title": "A brief introduction to research for health professionals",
    "section": "Dichotomising continuous variables",
    "text": "Dichotomising continuous variables\nGenerally speaking, splitting a continuous variable into categories is completely arbitrary and not a good idea. Think about splitting into age groups, say under 50’s and over 50’s. Is there really a difference between people aged 49 versus people aged 50? No, but deciding to put them in separate groups makes the decision that there is.\nSplitting a variable into groups might help with presentation in a table, but for statistical analysis if a variable is continuous, keep it that way.\nFurther reading:\nAltman, D.G. 1994. Problems in dichotomizing continuous variables. Am J Epidemiol. 139(4), pp.442-445.\nAltman, D.G. and Royston, P., 2006. The cost of dichotomising continuous variables. Bmj, 332(7549), p.1080."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation",
    "href": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation",
    "title": "A brief introduction to research for health professionals",
    "section": "Correlation and causation",
    "text": "Correlation and causation\nIce cream sales and aggressive behaviour are positively correlated\nDo ice cream sales cause aggressive behaviour?"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation-1",
    "href": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation-1",
    "title": "A brief introduction to research for health professionals",
    "section": "Correlation and causation",
    "text": "Correlation and causation\nOr does aggressive behaviour cause an increase in ice cream sales?"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation-2",
    "href": "post/2023-07-17-intro-to-research/index.html#correlation-and-causation-2",
    "title": "A brief introduction to research for health professionals",
    "section": "Correlation and causation",
    "text": "Correlation and causation\nMaybe there’s a common cause, like hot weather!\n\nThis one’s a classic, but let’s start off from basics. We know that ice cream sales and violent crime are correlated. This means that when one changes, so does the other. In the case of ice cream sales and violent crime, when sales go up so does violent crime - they are positively correlated.\nHowever, just because the two are correlated, it doesn’t mean that one causes the other. Increasing ice cream sales does not cause violent crime and conversely increasing violent crime does not cause ice cream sales to go up.\nThere’s a third common factor here - the temperature. As summer comes along and the temperature goes up, so do ice cream sales (who doesn’t like an ice cream on a hot day). Violent crime also goes up during summer - maybe because people are hot and bothered, maybe because people spend more time outdoors so there are more opportunities for violent crime to occur, who knows.\nThe point here is that just because you find that two things are correlated with each other, it doesn’t mean that there’s a causal relationship between them."
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#in-conclusion",
    "href": "post/2023-07-17-intro-to-research/index.html#in-conclusion",
    "title": "A brief introduction to research for health professionals",
    "section": "In conclusion",
    "text": "In conclusion\n\nTalk to a statistician early and often\nCome up with specific research questions\nGetting your protocol right will save you headaches later\nDon’t get hung up on doing a perfect study\n\nThanks to\n\nAndrew Althouse\nDarren Dahly\nIsabella Ghement\nMaarten van Smeden\nSabine Braat and the MISCH team\n\nAnd numerous other people who contributed in various ways to this presentation"
  },
  {
    "objectID": "post/2023-07-17-intro-to-research/index.html#the-end",
    "href": "post/2023-07-17-intro-to-research/index.html#the-end",
    "title": "A brief introduction to research for health professionals",
    "section": "The end",
    "text": "The end\nFor more reading on ‘common statistical myths’ see https://discourse.datamethods.org/t/reference-collection-to-push-back-against-common-statistical-myths/1787"
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html",
    "href": "post/2025-10-29-what-is-networking/index.html",
    "title": "What the hell is networking?",
    "section": "",
    "text": "At some point in your student life or early in your career, you’ll get advice telling you how important networking is. What they probably don’t go on to explain is what the hell they actually mean by networking. This has been my experience at least, and for the longest time I had no idea whether I was doing ‘networking’ correctly, or even at all. See @What the hell, Ben? if you don’t relate.\nThe lack of any explanation about what networking actually looked like always made me resistant to the idea of networking, but on reflection I think I’ve probably been doing it semi-successfully for the last few years. So I figured I’d write out what networking seems to have actually been for me, with some examples, in case this turns out to be useful for others — because “do networking” is actually good advice."
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html#so-what-is-it",
    "href": "post/2025-10-29-what-is-networking/index.html#so-what-is-it",
    "title": "What the hell is networking?",
    "section": "So what is it?",
    "text": "So what is it?\nFundamentally it just seems to be talking to a person often enough that they both remember your name and know something about you.\nIdeally they also feel positively about you too, so when the they happen upon a relevant opportunity they can put your name forward or send it through to you. But getting opportunities isn’t the only reason to network — we’re social animals and it’s nice to just know people for who they are too.\nWhen it comes to talking to people though, what seems to be important is the contexts in which you are speaking because it shapes how they see you. For example, I attended a lot of events organised by the SSA over the last ~8 years. The conversations I had with people occasionally were about something related to statistics, but for the most part it was not.\n\nHave you got any pets? Oh nice, what kind of dog! Ah, I love staffys — if I wasn’t a greyhound person I reckon I’d have a staffy.\n\n\nYou doing much over the Christmas break? Oh you’re just having the shutdown period off because you only started work recently? What were you doing before? Oh you used to do physiotherapy? Cool! What made you want to do statistics?\n\nNone of these conversations are about statistics, but by having them at a statistics event there’s a presumption that statistics is a relevant part of my identity. I always hope that after I meet someone for the first time they assign me the labels:\n\nStatistics\nNot a dickhead\nFriendly, talk to again\n\nThe conversations that are about statistics seem important though. Firstly, because I usually learn something. Secondly, and more importantly for networking, it’s an opportunity for the other person to update my labels to:\n\nStatistics, seems sensible\nNot a dickhead\nFriendly, talk to again\n\nThese first two labels seem to be pretty important. It might seem like a low bar, but knowing that someone isn’t a dickhead (the bad kind) and that they seem to know what they’re talking about is all it takes for me to be willing to mention their name to someone else."
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html#so-how-to-do-it",
    "href": "post/2025-10-29-what-is-networking/index.html#so-how-to-do-it",
    "title": "What the hell is networking?",
    "section": "So how to do it?",
    "text": "So how to do it?\nWell, in order to talk to people you need to be somewhere where the people are open to talking to you. This could be with other students during your degree, at work, social events, conferences, etc. Then, all that’s left to do is either initiate conversations with people or wait for someone to do the same with you.\nSo ‘networking’ is just building social relationships? Maybe that the context is around work is what separates it from social relationships more generally — the goal is to get to know people who are doing the same kind of work as you."
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html#how-has-it-helped-me",
    "href": "post/2025-10-29-what-is-networking/index.html#how-has-it-helped-me",
    "title": "What the hell is networking?",
    "section": "How has it helped me?",
    "text": "How has it helped me?\nThis is what led me to write this blog post, because recently I’ve been feeling grateful for the opportunities I’ve been afforded thanks to other people thinking of me. Some specific examples of how ‘networking’ has benefited me:\n\nMy current role, which I love, is a consequence of a series of events that began with someone who knew a few things about me, sending me a job description. I got that job, which ultimately led to my current job. Thanks, Emi!\nI was invited to speak at WOMBAT2025, which wouldn’t have happened if I hadn’t been raving about my work and how much I love R to someone who knew the organisers. Thanks, Nick!\nMy first biostatistics job came mid-degree from the recommendation of one of my lecturers. Thanks Julie! In this job I developed a great relationship with my supervisor, which led to another job. Thanks, Lesleyanne!\n\nI’ve always felt lucky when these kinds of things happen, and attributed them to ‘right place, right time’. It’s not always clear where the right place is and impossible to know when the right time is going to be, but if you keep showing up then eventually you’ll be in the right place at the right time. So keep on showing up!"
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html#how-have-i-helped-others",
    "href": "post/2025-10-29-what-is-networking/index.html#how-have-i-helped-others",
    "title": "What the hell is networking?",
    "section": "How have I helped others?",
    "text": "How have I helped others?\nThe cool thing about networking is that you get to form your own set of labels for the people you meet. Our brains are great at identifying patterns, so when a circumstance arises that someone you’ve met seems relevant to bring up, you should do it!\nI never go into a conversation with the intention of inserting the name of someone I know, but it’s really rewarding when the opportunity comes up to connect people. For example, I met a student at a conference who was just about to finish their master’s degree, who hadn’t been to any SSA events before and didn’t really know anyone from the statistics community. In chatting, I found out they were working nearby another statistician I knew to be kind and supportive, so after the event I made sure to connect the two."
  },
  {
    "objectID": "post/2025-10-29-what-is-networking/index.html#rambly-bits",
    "href": "post/2025-10-29-what-is-networking/index.html#rambly-bits",
    "title": "What the hell is networking?",
    "section": "Rambly bits",
    "text": "Rambly bits\n\nWhat the hell, Ben?\nYes, I’ve got the spicy brain. Maybe all of this is blindingly obvious to most people.\n\n\nIt can be awkward\nTry to embrace it? With time and practice, the awkwardness becomes less frequent and more bearable.\n\n\nDon’t forget about your peers\nA lot of this post is about how networking can lead to opportunities. Those opportunities typically come from people with the ability to create them, and those people tend to be more senior in their careers. One day though, you’ll be senior in your career as will everyone else at the same career stage as you."
  },
  {
    "objectID": "post/2021-08-03-ECSSC2021-presentation/index.html",
    "href": "post/2021-08-03-ECSSC2021-presentation/index.html",
    "title": "What I Didn’t Learn at University",
    "section": "",
    "text": "I presented this talk at the Early Career and Student Statistician’s Conference in 2021. I found that while I learned a lot at university about statistics and data, I didn’t learn a great deal about what it’s like practising statistics in an applied setting. So I made this talk, where I talk about all the things I learned in the first few years of working after graduating from university.\n\n\nIf you have any thoughts about the video or wanted to chat about your experience transitioning out of the student life, let me know on Bluesky!"
  },
  {
    "objectID": "post/2025-10-10-playing-in-your-back-yard/index.html",
    "href": "post/2025-10-10-playing-in-your-back-yard/index.html",
    "title": "I can only play in your back yard if you invite me in",
    "section": "",
    "text": "I read a post called Statistics in the era of AI by Terry McGlynn. I hadn’t come across Terry before. He self-identifies as an ecologist and I have a lot of respect for ecologists — out of all of the not-statistics disciplines, ecologists seem to be uncommonly good at using R and complex statistical methods. But at the end of the day, Terry is an ecologist, not a statistician.\nI say this not to demean or gatekeep, but to highlight that when statistics is outsourced to LLMs, ecologists still get to do ecology. Economists still get to do economics. Psychologists get to do psychology… You get my point.\nWhat do statisticians get to do? We’re humans, living in a society where we have to work to live, doing jobs that we might actually love, too. So what do we get to do when statistics is outsourced to LLMs? Statisticians love John Tukey’s quote about getting to play in everyone’s back yard, but reading Terry’s post made me worry that more and more people are closing their gate and hanging signs saying “No trespassing, ChatGPT on patrol”.\nIt drives me nuts to be an expert in a discipline that every other discipline needs, yet if you listen to a discussion by statistical consultants about consulting I can guarantee they’ll talk about the difficulty of getting collaborators on board early enough and getting them to budget for your time, and the frustration of being handed shithouse datasets that can’t answer the research question."
  },
  {
    "objectID": "post/2025-10-10-playing-in-your-back-yard/index.html#do-people-actually-understand-our-expertise",
    "href": "post/2025-10-10-playing-in-your-back-yard/index.html#do-people-actually-understand-our-expertise",
    "title": "I can only play in your back yard if you invite me in",
    "section": "Do people actually understand our expertise?",
    "text": "Do people actually understand our expertise?\nIn every statistical consult, the most helpful thing I’ve done was not data cleaning. It wasn’t fitting regression models. It wasn’t writing up the results for the paper.\n\nThe single most helpful thing a statistician can do is get you to answer questions you hadn’t even considered\n\nIt really didn’t matter what level of statistical expertise the people I worked with had — undergrad students, postdocs, professors with decades of experience and hundreds of publications — there was always something they had not considered that, in answering, changed something important about their research design and data collection."
  },
  {
    "objectID": "post/2025-10-10-playing-in-your-back-yard/index.html#humans-seem-missing-from-this-equation",
    "href": "post/2025-10-10-playing-in-your-back-yard/index.html#humans-seem-missing-from-this-equation",
    "title": "I can only play in your back yard if you invite me in",
    "section": "Humans seem missing from this equation",
    "text": "Humans seem missing from this equation\nTerry’s blog post was so striking to me because so often he faces problems or has questions where, to me, the answer is “get more humans involved”. But Terry’s answer is “get ChatGPT involved”.\nI include some quotes below that helped crystallise my thinking. I think my original text painted Terry in an unfair light, he points out on Bluesky that he wants to be able to collaborate and include statisticians and data experts in his work but is hamstrung by both lack of funding and people. It would not surprise me if the circumstance he’s in and the appeal of ChatGPT is a consequence of there not being any other option — and this is a systemic problem with academia.\n\nSo I fed it a dataset that’s been giving me headaches. I just gave it my .csv files. I told it how I wanted to clean up the dataset and prepare it for analyses.\n\nThis could just as easily be work for a student or early-career researcher. They’ll overcome the issue you’re having and will learn something about code, data management, analysis, and research in general.\n\nit suggested running a couple additional analyses to decide if I should prefer one parameter over another based on the nature of my question. I was wondering about this, but, frankly, I wasn’t quite sure what approach to take for that issue.\nI looked into it, and lo and behold, the approach that was recommended to me made a LOT of sense\n\nSo 15 minutes into using ChatGPT to do your analysis you’ve reached the limit of your statistical expertise. Terry makes a point of saying he knows how to google and look stuff up on Stack Overflow — which is a great skill to have. What I wonder though, and this relates to my earlier point of asking questions that had not been thought about, is if your search terms are the words ChatGPT uses to describes its methods, then of course you’re going to get back search results that make sense — because you’re reading the same training data that ChatGPT is using to respond to your queries.\nWhen you’re at the limits of your statistical expertise, you’re very much in “don’t know what you don’t know” territory and I worry about the role confirmation bias plays in this situation — you have an idea of what you might do, ChatGPT does something that looks familiar, the search results are consistent with your ideas, so you’re happy with the output. Would an actual statistical expert give you different advice? You’ll never know because ChatGPT is your expert now.\n\n… one of my three goals was to become proficient at R. It was a slog. I wouldn’t say I became proficient but I became slightly capable.\n\nI want to stress my point here isn’t to dunk on Terry, I’m happy to take at face-value his assertion of being good at statistics (he’s an ecologist after all). But this really feels like a Dunning-Kruger problem and reminds me of much of my consulting work — the medical doctors who knew how to interpret a regression coefficient were typically much harder to work with than those who knew nothing.\nBut Terry talks about the coding being the problem — not the statistics. I find this point fascinating because it’s like there’s some hierarchy of expertise, where statistics is the important thing to know and coding is just a mundane implementation. To me, as a practising statistician, coding and data management are just as important as knowing the statistical methods.\n\nAnd then it asked me if I wanted it packaged in a Jupyter notebook.\n\nand\n\nLiterally all the stats I wanted to do on this project were done for by. In this case, ChatGPT provided a service to me that I would have paid a data wizard a couple thousand bucks to do.\n\nand\n\nIf I hired a technician to do the fieldwork instead of doing it myself, would you have an issue with that? If I hired a consultant to write the code when I told them what I needed, would that be a problem? Then, what’s the problem in doing stats with an (AI) consultant?\n\nPeople can do these jobs, and people learn things by doing them, and eventually these people will replace you when you retire. Your expertise is the result of every single thing you’ve ever learned or done, so what are we doing to the expertise of students and postdocs by outsourcing the work they’d usually do to LLMs?"
  },
  {
    "objectID": "post/2025-10-10-playing-in-your-back-yard/index.html#where-does-this-lead",
    "href": "post/2025-10-10-playing-in-your-back-yard/index.html#where-does-this-lead",
    "title": "I can only play in your back yard if you invite me in",
    "section": "Where does this lead?",
    "text": "Where does this lead?\nAcademia suffers from an ever-rising bar of excellence and you can see it so clearly when you talk to current professors. The academia I hear about from them sounds nothing like what I am currently experiencing, having recently finished my PhD. Needing to have first-author publications to get a scholarship for a degree where you learn how to do research. Publish, publish, publish, but only in Q1 journals if you want a permanent job. Make sure you’re winning grants, but don’t worry we’ve cut your admin support, increased your teaching load, and the grant schemes have miniscule success rates.\n\nI was talking to a friend the other day and he told me that in one week, he was able to use AI-supported coding to do the job that a couple years ago would have taken a postdoc several months to get done. Wow.\n\nThis is the exact worry that I have, and Terry sort of comments on this — except he’s not worried, he’s thrilled about not needing to work with “coding wizards”. In his circumstance, I assume the thrill comes from being able to do work that otherwise would never get done. But I can see too how the focus on individual success and the superstar researcher, that many others will be glad to work and publish quickly, by themselves (and ChatGPT).\nWhich brings me to my original worry — where’s the consideration and care for the humans involved? And this isn’t only about statisticians, it’s about students and postdocs too. Teaching statistics and coding in less and less depth because LLMs seem like they can do these things for you is a terrible idea. It’s contrary to the whole point of being a student, a postdoc, or a researcher at any stage of your career — because it’s a choice to not learn any more, but the above quote shows how someone else can make that choice for you.\nIt’s like instead of teaching kids to ride a bike with training wheels, we’re putting them straight onto a road-bike travelling 50km/h down a hill. The sheer momentum of the bike keeps them upright and flying forward, which looks like success, but if we need them to steer or slow down they’ve got no idea.\nAll this said though, the appeal of outsourcing to ChatGPT for statistics or coding work is a consequence of there not being enough resources (money, time, or people) available. I know we’re all constantly trying to use what little resources we have in the most effective way possible (university bureaucracy be damned), but we need a better solution than outsourcing expertise to LLMs."
  },
  {
    "objectID": "post/2020-12-03-joke/index.html",
    "href": "post/2020-12-03-joke/index.html",
    "title": "Why was Christmas ruined for the Germans?",
    "section": "",
    "text": "Because all their cakes were stollen"
  },
  {
    "objectID": "post/2025-05-23-tidyverse-functions/index.html",
    "href": "post/2025-05-23-tidyverse-functions/index.html",
    "title": "tidyverse functions you might not know about",
    "section": "",
    "text": "Sometimes you ask for help and people provide you with solutions using functions you didn’t know exist. That happened to me today and made me realise that I should look through the list of functions provided in the tidyverse packages I regularly use. So I did that and I discovered some cool functions that I should definitely be using!\nI’ve listed some handy functions here and some use cases I’ve had for them."
  },
  {
    "objectID": "post/2025-05-23-tidyverse-functions/index.html#dplyr",
    "href": "post/2025-05-23-tidyverse-functions/index.html#dplyr",
    "title": "tidyverse functions you might not know about",
    "section": "dplyr",
    "text": "dplyr\nIf you want to check out the list of dplyr functions yourself, you can find them at https://dplyr.tidyverse.org/reference/index.html\n\nCombining values from multiple columns row-wise (c_across())\nScenario: You have set of variables you need to create a total score for, like the Kessler K-5.\n\n\n# A tibble: 4 × 6\n     id    q1    q2    q3    q4    q5\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     5     5     3     3     3\n2     2     3     1     2     1     5\n3     3     1     2     3     1     2\n4     4     2     1     5     1     4\n\n\nc_across() provides a neat way of doing this and is designed to work with data grouped using rowwise():\n\nk5 |&gt; \n  rowwise() |&gt; \n  mutate(\n    k5_score = sum(c_across(q1:q5)),\n  ) |&gt; \n  ungroup()\n\n# A tibble: 4 × 7\n     id    q1    q2    q3    q4    q5 k5_score\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1     5     5     3     3     3       19\n2     2     3     1     2     1     5       12\n3     3     1     2     3     1     2        9\n4     4     2     1     5     1     4       13\n\n\nMy original approach would’ve used a combination of rowSums() and pick():\n\nk5 &lt;- k5 |&gt; \n  mutate(\n    k5_score = rowSums(pick(q1:q5))\n  )\nk5\n\n# A tibble: 4 × 7\n     id    q1    q2    q3    q4    q5 k5_score\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1     5     5     3     3     3       19\n2     2     3     1     2     1     5       12\n3     3     1     2     3     1     2        9\n4     4     2     1     5     1     4       13\n\n\nThe advantage of my original approach is you don’t need to specify rowwise() and ungroup(), but this only works for sums and means because base only provides rowSums and rowMeans. If you want to do any other operations, c_across() is your friend!\n\n\nSet values to missing under a condition (na_if())\nI would normally use case_when() to set observations to missing when they meet particular conditions, but na_if() seems like a more direct way of doing that:\n\nk5 &lt;- k5 |&gt; \n  mutate(\n    k5_score = na_if(k5_score, 13)\n  )\nk5\n\n# A tibble: 4 × 7\n     id    q1    q2    q3    q4    q5 k5_score\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1     5     5     3     3     3       19\n2     2     3     1     2     1     5       12\n3     3     1     2     3     1     2        9\n4     4     2     1     5     1     4       NA\n\n\n\n\nifelse but tidyverse style (if_else())\nI would normally have used case_when() in this case too, as I find it easier read what’s happening in each condition, but occasionally I find myself using ifelse for convenience when I only need to use one condition.\nif_else() just seems like a better version of ifelse(). The main appeal is the inclusion of the missing argument, which lets you specify what you want missing values to be coded as:\n\nk5 |&gt; \n  mutate(\n    k5_category = if_else(k5_score &lt; 12, \"low\",\"high\", missing = \"missing\")\n  )\n\n# A tibble: 4 × 8\n     id    q1    q2    q3    q4    q5 k5_score k5_category\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;      \n1     1     5     5     3     3     3       19 high       \n2     2     3     1     2     1     5       12 high       \n3     3     1     2     3     1     2        9 low        \n4     4     2     1     5     1     4       NA missing    \n\n\n\n\nUsing another dataset to update rows (rows_update())\nThis was a great recommendation by someone who helped me solve a problem efficiently. I had one dataset consisting of uncleaned responses to a paper questionnaire, which had been digitsed using OCR. I had a secondary dataset where the original paper questionnaire had been audited when the OCR seemed to have done a poor job.\nSticking with the K-5 data, imagine we have the audited data as follows:\n\n\n# A tibble: 2 × 4\n     id variable original audited\n  &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1     3 q1              2       1\n2     3 q2              4       5\n\n\nAll I had to do was use pivot_longer() to put the uncleaned data into long format and then use rows_update() to find and replace the corresponding values, then pivot_wider() back into the original format.\n\nk5 |&gt; \n  pivot_longer(\n    !id,\n    names_to = \"variable\",\n    values_to = \"response\"\n    ) |&gt;\n  rows_update(\n    audit |&gt; \n      rename(response = audited) |&gt; \n      select(id, variable, response),\n    by = c(\"id\",\"variable\")\n  ) |&gt; \n  pivot_wider(\n    names_from = \"variable\",\n    values_from = \"response\"\n  )\n\n# A tibble: 4 × 7\n     id    q1    q2    q3    q4    q5 k5_score\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1     1     5     5     3     3     3       19\n2     2     3     1     2     1     5       12\n3     3     1     5     3     1     2        9\n4     4     2     1     5     1     4       NA\n\n\nNote that inside of rows_update() I take audit, rename the column with the correct values to match the column name in the data, then keep only the columns used to identify the unique rows (id and variable) and the value used for updating (response).\nThere’s a whole suite of row-specific functions (see here), but I have found rows_update() being especially helpful.\n\n\nAdding rows to a dataset (bind_rows())\nI feel like everyone probably knows about this, but I wanted to quickly mention that I recently discovered I was using it inefficiently! bind_rows() accepts multiple things to be bound, meaning you can write:\n\ndf1 |&gt; bind_rows(df2, df3, df4)\n\nInstead of what I was previously doing:\n\ndf1 |&gt; \n  bind_rows(df2) |&gt; \n  bind_rows(df3) |&gt; \n  bind_rows(df4)"
  },
  {
    "objectID": "post/2025-05-23-tidyverse-functions/index.html#tibble",
    "href": "post/2025-05-23-tidyverse-functions/index.html#tibble",
    "title": "tidyverse functions you might not know about",
    "section": "tibble",
    "text": "tibble\nYou can find the tibble reference list here https://tibble.tidyverse.org/reference/index.html\n\nAdding rows in specific locations (add_row())\nThe use-case I had for this was actually solved by just using gtsummary, but before I discovered that package I was making summary tables by hand. I’d do this by combining the output from tabyl() and summarise() into one data frame. For example:\n\nsummary &lt;- k5 |&gt;\n  summarise(\n    n = n(),\n    mean = mean(q1),\n    sd = sd(q1),\n    min = min(q1),\n    max = max(q1)\n  ) |&gt;\n  pivot_longer(everything())\n\nsummary\n\n# A tibble: 5 × 2\n  name  value\n  &lt;chr&gt; &lt;dbl&gt;\n1 n      4   \n2 mean   2.75\n3 sd     1.71\n4 min    1   \n5 max    5   \n\n\nBut the number of participants is different to summaries of responses to Q1, so I want to add a row to make this clear. This is easily done by using the .before = argument:\n\nsummary |&gt; \n  add_row(\n    name = \"Q1 responses\",\n    .before = 2\n  )\n\n# A tibble: 6 × 2\n  name         value\n  &lt;chr&gt;        &lt;dbl&gt;\n1 n             4   \n2 Q1 responses NA   \n3 mean          2.75\n4 sd            1.71\n5 min           1   \n6 max           5   \n\n\n\n\nConverting lists to tibbles (enframe())\nI’ve been doing a lot of work with APIs and getting data returned as JSON, which the httr2 package helpfully converts into a more usable format in R. Unfortunately, what I get tends to be a lot of nested lists that I need to combine together into a rectangular format.\n\nmy_list &lt;- c(\"Victoria\",\"Western Australia\",\"Tasmania\")\n\nmy_list\n\n[1] \"Victoria\"          \"Western Australia\" \"Tasmania\"         \n\n\nEnter enframe(). It works with vectors and converts them into a tibble with two columns. Very simple, very useful.\n\nenframe(my_list)\n\n# A tibble: 3 × 2\n   name value            \n  &lt;int&gt; &lt;chr&gt;            \n1     1 Victoria         \n2     2 Western Australia\n3     3 Tasmania"
  },
  {
    "objectID": "post/2025-05-23-tidyverse-functions/index.html#tidyr",
    "href": "post/2025-05-23-tidyverse-functions/index.html#tidyr",
    "title": "tidyverse functions you might not know about",
    "section": "tidyr",
    "text": "tidyr\nSee the tidyr reference list here https://tidyr.tidyverse.org/reference/index.html\n\nGetting values out of list columns (unnest())\nBuilding on the previous example, you might end up with a column that contains lists, but you want those values as columns (or rows).\n\nmy_list &lt;- tibble(\n  state = list(tibble(\"Victoria\",\"Western Australia\",\"Tasmania\")),\n  territory = list(tibble(\"Australian Capital Territory\",\"Northern Territory\"))\n    )\n\nmy_list\n\n# A tibble: 1 × 2\n  state            territory       \n  &lt;list&gt;           &lt;list&gt;          \n1 &lt;tibble [1 × 3]&gt; &lt;tibble [1 × 2]&gt;\n\n\nThese lists can be extracted using unnest:\n\nunnest(my_list, col = c(state, territory))\n\n# A tibble: 1 × 5\n  `\"Victoria\"` `\"Western Australia\"` `\"Tasmania\"` \"Australian Capital Territor…¹\n  &lt;chr&gt;        &lt;chr&gt;                 &lt;chr&gt;        &lt;chr&gt;                         \n1 Victoria     Western Australia     Tasmania     Australian Capital Territory  \n# ℹ abbreviated name: ¹​`\"Australian Capital Territory\"`\n# ℹ 1 more variable: `\"Northern Territory\"` &lt;chr&gt;\n\n\nThere’s also unnest_longer() and unnest_wider(), depending on the shape you.\n\n\nPropagating non-missing values row-wise (fill())\nThis has been such a useful function in so many situations for me, yet somehow I frequently forget about it!\nMy most recent use-case was creating a data dictionary based on metadata output from REDCap. In the questionnaire, section headers are used to paginate the different sections, but in the metadata the header is attached to a single variable:\n\ndictionary &lt;- tibble(\n  variable = c(\"name\",\"dob\",\"q1\",\"q2\",\"q3\",\"q4\",\"q5\"),\n  header = c(\"About you\",NA,\"Psychological distress\",NA,NA,NA,NA)\n)\n\ndictionary\n\n# A tibble: 7 × 2\n  variable header                \n  &lt;chr&gt;    &lt;chr&gt;                 \n1 name     About you             \n2 dob      &lt;NA&gt;                  \n3 q1       Psychological distress\n4 q2       &lt;NA&gt;                  \n5 q3       &lt;NA&gt;                  \n6 q4       &lt;NA&gt;                  \n7 q5       &lt;NA&gt;                  \n\n\nWhen creating the data dictionary, I want the header to be present for every variable as it can be useful to identify or analyse data by section:\n\ndictionary |&gt; \n  fill(header, .direction = \"down\")\n\n# A tibble: 7 × 2\n  variable header                \n  &lt;chr&gt;    &lt;chr&gt;                 \n1 name     About you             \n2 dob      About you             \n3 q1       Psychological distress\n4 q2       Psychological distress\n5 q3       Psychological distress\n6 q4       Psychological distress\n7 q5       Psychological distress\n\n\nThe .direction argument accepts “down”, “up”, “downup”, and “updown”, meaning you can fill in multiple directions. This is especially powerful when you combine it with group_by(), allowing you to fill without worrying about propagating into the wrong group."
  },
  {
    "objectID": "post/2025-03-18-joke/index.html",
    "href": "post/2025-03-18-joke/index.html",
    "title": "What did Euclid say when Dante asked about his bronzed complexion?",
    "section": "",
    "text": "tan cos sin"
  },
  {
    "objectID": "post/2025-06-12-pronoun-function/index.html",
    "href": "post/2025-06-12-pronoun-function/index.html",
    "title": "An R function for pronouns",
    "section": "",
    "text": "People can have pronouns that change over time or multiple pronouns, like myself. In an ideal world, I’d love it if people used a random pronoun each time, but people aren’t random number generators and when presented with “any pronouns” will usually default to exclusively “he”.\nThis got me thinking though… What if I could randomly sample from a list of pronouns? So that’s what I’ve done — for Quarto users at least. It’s simple really, all you need to do is define each person’s pronouns:\n\nben &lt;- list(name = \"ben\",\n            subject = c(\"he\",\"she\",\"they\"),\n            object = c(\"him\",\"her\",\"their\"),\n            dependent = c(\"his\",\"her\",\"their\"),\n            independent = c(\"his\",\"hers\",\"theirs\"),\n            reflextive = c(\"himself\",\"herself\",\"themself\"))\n\nI have to thank Wikipedia for providing the names of the different pronoun forms, it’s been a couple of decades since I had to think about this. Now we can just write a little function that samples from this list and returns the appropriate pronoun, in the format required.\n\npronoun &lt;- function(who, which, format = \"lower\"){\n  if (format == \"title\") {\n  gsub(\"(\\\\w)(\\\\w*)\", \"\\\\U\\\\1\\\\L\\\\2\", sample(who[[which]],1), perl=TRUE)\n  } else {\n    sample(who[[which]],1)\n  }\n}\n\npronoun(ben,\"subject\",\"title\")\n\n[1] \"He\"\n\n\nTo use this, you would just call the function in-text like you would any R function. I was very satisfied getting to this point (and figuring out how to do it in base R), but then I realised that English is a very annoying language. The particularly annoying part is that because any of he, she, and they could be picked, it’s hard to know what the right verb to choose is. To illustrate:\n` r pronoun(ben,\"subject\",\"title\")` likes greyhounds\nIs returned as:\nShe likes greyhounds\nIn my Quarto file I have no idea which pronoun is going to get picked (yay!) but depending on which one gets picked, I should’ve used ‘like’ or ‘likes’.\nWell that’s a future me problem, this was just a fun little proof of concept. If I come back around to this, maybe I’ll:\n\nExtend the function to cover verbs\nIntegrate it with YAML somehow? It’d be cool to attach pronouns to author YAML and turn the function into a Quarto extension"
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html",
    "href": "post/2025-03-03-variable-naming-convention/index.html",
    "title": "What makes a good variable naming convention",
    "section": "",
    "text": "In particular, what makes a good variable naming convention for a longitudinal or panel survey? I wanted to answer this question so I could propose a good naming convention for a project at work. I have lots of opinions about this, largely based on working with variable names I don’t like, but I thought I should see what others thought so I posed the question on BlueSky…\n… and I got just as many comments on what not to do as what to do! So let’s go through the do’s and don’ts and I’ll use the following question to demonstrate.\nIn terms of features, this question:"
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html#what-makes-a-bad-naming-convention",
    "href": "post/2025-03-03-variable-naming-convention/index.html#what-makes-a-bad-naming-convention",
    "title": "What makes a good variable naming convention",
    "section": "What makes a bad naming convention?",
    "text": "What makes a bad naming convention?\nLet’s start out with what makes for a bad naming convention. If we figure out what we don’t like, we can start to figure out what we do.\n\nNot using a convention\nMaking variable names up as you go along is clearly a bad idea. It creates much more work as you’ll have to either remember every specific variable name or look at the data dictionary every time. Planning variable names ahead of time is also important, if you make up a few names then try and fit new names into the pattern you’ve just made up, you’ll quickly run into issues where the names don’t work. So at the very least we need a naming convention.\nFor our general health question, maybe we called it generalhealth. Not terrible, but this isn’t going to be adequate in the context of an entire survey, as hopefully you’ll come to realise.\n\n\nPrioritising brevity\nMaking variable names as short as possible will save a few keystrokes at the cost of constantly referring back to the data dictionary to make sure you’re using the right one.\nWe could call the general health question genh or gh or ghr (general health rating). Yes, they’re short, but see how I had to explain what ghr stood for? It’s not immediately clear.\nAlso, text-completion exists in many IDEs, so don’t prioritise brevity!\n\n\nPrioritising interpretability\nConversely, prioritising interpretability can lead to excessively long variable names, which is at the other extreme!\nwave_1_health_general_health_general_health_rating_ordinal encodes lots of information - the wave, the section, the sub-section, some of the question wording, and the type of data. This kind of length might work for your own solo projects but not for a dataset that’s going to be used by lots of people.\n\n\nNames that are easy to mix up\nThis is more common with conventions that prioritise brevity, as they tend to use abbreviations and avoid delimiters, which makes variables difficult for our brains to process quickly and accurately. Imagine the convention {wave}{respondent}{topic}{2-letter ID} resulted in the variables bcgenmo and bcgemno. They’re from entirely different topics, gen and gem, but it is very easy to mix them up visually and through typos.\n\n\nUsing more than one case\ncamelCase, snake_case, kebab-case, SCREAMING-KEBAB-CASE, they’re all candidates but switching between cases is a no-no for variable names. It might be useful in other situations where you use one case for functions, another for variable names. But we’re just talking about variable names here, so don’t use more than one case.\n\n\nUsing more than one language\nThis was a good point from my BlueSky post (thanks Russell!). In my context in Australia, I’d use English, and only English, to name the variables in my dataset.\nPeople are going to have an easier time if we call the general health question general_health instead of allgemeine_gesundheit. If you were collecting data in Germany, allgemeine_gesundheit might make more sense.\n\n\nUsing letters for wave number\nOk this is probably a controversial one because I see it done time and time again. Yes, it’s a concise and convenient way of representing a number. However, it only works up to 26 waves (our survey’s going to run forever, right!?). It’s also a pain trying to remember which letter is which number and it forces you to write extra code to translate letters into numbers (e.g. match(\"k\",letters[1:26])).\nImagine we’ve got 20 waves of survey data, what wave is the general health question hhlthgenord in? I’m sat here counting out letters on my fingers because I don’t know off the top of my head.\nAlso, it can lead to odd variable names - some examples from the wild include:\n\nasdtype - Wave 1 survey type, not type of autism spectrum disorder\newluge - A question about geriatric care in wave 5, not a disdain for sleds\n\nThese are fairly innocuous examples but I’ve seen some inappropriately named variables too.\n\n\nUsing elements of the questionnaire design\nYou might be tempted to incorporate the question number into the variable name. Don’t.\nImagine the general health question is number 50 in wave 1, so we call it a50genh. In preparation for wave 2 we examine individual question response rates - looks like rates of missing data increase with increasing question number. We could address that in wave 2 by randomising the order of sections or putting the general health question earlier in the questionnaire. Good ideas, but either of these choices break the naming convention.\nThe same goes for using the section. The general health question might’ve been the only health question in the first wave, so it went in the ‘about you’ section and was called aaboutgenh. For wave 2 though we got funding from the Department of Health and they want to add a section on health. Now the general health question has moved to the ‘health’ section. Calling it bhealthgenh is encoding the section in wave 2 but is inconsistent with the wave 1 name. Calling it baboutgenh encodes the incorrect section in the name. Not good!"
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html#what-makes-a-good-naming-convention",
    "href": "post/2025-03-03-variable-naming-convention/index.html#what-makes-a-good-naming-convention",
    "title": "What makes a good variable naming convention",
    "section": "What makes a good naming convention?",
    "text": "What makes a good naming convention?\nWe have an idea of what makes a bad convention, so what makes a good one?\n\nClearly defined components\nNaming conventions are built on components, with their combination resulting in variable names. Components you might use include:\n\nSurvey wave\nData type\nRespondent category\nQuestion theme\nQuestion keyword\n\nOnce you’ve identified the important components, next decide on how they will be combined - and stick to this formula!\nApplying the convention {wave}_{theme}_{keyword} to the general health question in wave 1 could lead to the variable name w01_health_general.\n\n\nConsidered ordering of components\nThe ordering of components should have a logic or hierarchy to it. I’d recommend following a hierarchy of information scope.\nFor example, the hierarchy in {wave}_{theme}_{keyword} goes from broad to narrow - {wave} relates to the whole survey and is the broadest in scope, {theme} relates to the theme or concept the question is getting at, but isn’t necessarily restricted to that question alone, and {keyword} has the most narrow scope, drawing on the specific wording of a question.\nAlso, think about how you might be working with the variables - R’s dplyr provides functions like ends_with() and starts_with() for a reason. From the palmer penguins dataset, consider the variables bill_length_mm, bill_depth_mm, and flipper_length_mm. If we wanted to work with measurements relating to bills, these variables are readily identifiable (starts_with(\"bill_\")). Similarly, if we wanted to change millimetres to centimetres, we can identify these variables using ends_with(\"_mm\").\nThis also makes it easy to see sets of related variables in the data dictionary and produces sensible options in auto-complete lists. Contrast these two approaches (I made up a few extra variables):\n\n\nbill_length_mm\nbill_depth_mm\nbill_width_mm\nbill_colour\nbill_density\n\nlength_bill_mm\ndepth_bill_mm\nwidth_bill_mm\ncolour_bill\ndensity_bill\n\n\nHaving bill as the first component ({bodypart}?) makes it easy to spot variables relating to bills. Having {measurement} as the first component is more visually cluttered and in a dictionary of hundreds of variables would be harder to spot. You should consider the focus of the data though, maybe measurements are the focus in which case it would be more useful to have measurement as the first component.\n\n\nConsistent length of components\nThis consideration might not be relevant if you only have a small number of variables, but once you start hitting a large enough number that your data dictionary requires you to scroll up and down to see everything, it becomes useful to require each component to be the same length. Compare the following variable names following {topic}_{element}_{measurement}:\n\n\nNo restriction on component length:\npenguin_species\nlocation_island\npenguin_bill_length\npenguin_bill_depth\npenguin_bill_width\npenguin_bill_colour\npenguin_bill_density\npenguin_bill_mass\npenguin_flipper_length\npenguin_flipper_depth\npenguin_flipper_width\npenguin_flipper_density\npenguin_flipper_colour\npenguin_flipper_mass\npenguin_sex\nstudy_year\n\n4 characters, 3 characters, 4 characters:\npeng_spe\nloca_isl\npeng_bil_leng\npeng_bil_dept\npeng_bil_widt\npeng_bil_colo\npeng_bil_dens\npeng_bil_mass\npeng_fli_leng\npeng_fli_dept\npeng_fli_widt\npeng_fli_dens\npeng_fli_colo\npeng_fli_mass\npeng_sex\nstud_yea\n\n\nIgnoring whether the abbreviations are good or not (I just cut them off), I find having the variable names the same length means I’m having to do less visual processing when looking at them (I’m not distracted by the varying length) and can focus more easily on finding the variable I’m looking for.\nYou might find yourself in a circumstance where a component is optional, such as in the above example - the bill and flipper both have measurements like length and depth, which are encoded in the second component, but this component is only included where there are multiple measurements of the same thing. Ideally all components are required, however if you are going to use an optional component restrict the convention to one optional component and stick it at the end of the variable name. This prevents the absence of the component from impacting on how the variables look in a list:\n\n\nOptional {measure} 4 characters, {topic} 4 characters, {element} 3 characters:\npeng_spe\nloca_isl\nleng_peng_bil\ndept_peng_bil\nwidt_peng_bil\ncolo_peng_bil\ndens_peng_bil\nmass_peng_bil\nleng_peng_fli\ndept_peng_fli\nwidt_peng_fli\ndens_peng_fli\ncolo_peng_fli\nmass_peng_fli\npeng_sex\nstud_yea\n\n{topic} 4 characters, {element} 3 characters, optional {measure} 4 characters:\npeng_spe\nloca_isl\npeng_bil_leng\npeng_bil_dept\npeng_bil_widt\npeng_bil_colo\npeng_bil_dens\npeng_bil_mass\npeng_fli_leng\npeng_fli_dept\npeng_fli_widt\npeng_fli_dens\npeng_fli_colo\npeng_fli_mass\npeng_sex\nstud_yea\n\n\n\n\nChoose components that are resilient to changes in survey design\nWe know that questionnaire section is a poor component because it breaks as soon as questions are moved between sections. Instead, try and choose components that are unlikely to change over time. For example, the general health question asks about health so we could say its theme or focus is health. In our previous example then, {wave}_{theme}_{keyword} is not going to break when the question moved from ‘about you’ to ‘health’, but {wave}_{section}_{keyword} will.\nA side effect of choosing components that are resilient to changes in survey design is that if a circumstance arises that looks to break a variable name, it could be indicating that you need a new question instead.\n\n\nBalancing brevity and interpretability\nThe goal is to create variable names that are succinct.\n\nsuccinct, adjective. marked by compact precise expression without wasted words\n\nThis is as much of an art as a science, don’t be surprised if it’s difficult!\nTake the previous example wave_1_health_general_health_general_health_rating_ordinal. The section and sub-sections are redundant, repeating the words health and general. We could instead switch these components for the theme, which is still health, and get to wave_1_health_general_rating_ordinal. wave_1 could then be shortened to w01, and we could provide a schema for data type abbreviations:\n\nstr = strings\ncat = categorical\nord = ordinal\nnum = numeric\n\nSo we switch from {wave_#}_{section}_{subsection}_{keywords}_{type} to {wave}_{theme}_{keyword}_{type} and end up with w01_health_general_ord.\nOn abbreviations, I would suggest using them sparingly, rather than not at all. Sometimes there’s an important bit of information you want to encode in a variable or set of variables, but you can’t do it without using an abbreviation.\n\n\nConsider software requirements\nRelated to brevity, it’s important to think about your end-users and the software they use. Stata, SPSS, and SAS only support variable names up to 32 characters in length, meaning that is the hard maximum for your variable names. Variable names shouldn’t start with numbers either, hence why my examples for {wave} have been w01 not 01.\nIn coming up with my proposed convention, I kept in mind that people use datasets in long and wide format. I was debating whether to include wave as a component, w01_health_general, or to store it as a separate variable. Moving wave to be a variable instead of a component didn’t mean I now had an extra four characters (w01_) to work with though - if Stata users reshape the dataset into wide format using wave, they’ll run into problems with variable names that are 29 characters or more.\nWhile this might seem like over-engineering, it was a legitimate requirement of the end-users.\n\n\nConsider survey requirements\nAspects of the survey can also inform the components you choose, and also how you define those components.\nI’ve used w01 as an example of how wave could be encoded in the variable name. The reason for w01 and not w1 is that this allows for more than 10 waves to be encoded in a way that can be sorted:\n\nsort(c(\"w1\",\"w2\",\"w3\",\"w10\",\"w11\",\"w12\"))\n\n[1] \"w1\"  \"w10\" \"w11\" \"w12\" \"w2\"  \"w3\" \n\nsort(c(\"w01\",\"w02\",\"w03\",\"w10\",\"w11\",\"w12\"))\n\n[1] \"w01\" \"w02\" \"w03\" \"w10\" \"w11\" \"w12\"\n\n\nThe Longitudinal Study of Indigenous Children gathers responses from children, their parents, their teacher or carer, and their school principal. Respondent is included as a component in their variable names:\n\na = parent 1\nb = parent 2\nc = study child\nd = teacher/carer\ne = principal\n\nThe use of single letters here is prioritising brevity over interpretability, but you can see how this element of the survey informed the naming convention.\n\n\nUse a delimiter, consistently\nUsing a delimiter to separate the components of your variable names makes them much easier for humans to read, just make sure you pick one and stick with it. Which delimiter do you prefer:\nbill_length_mm\n\nbill.length.mm\n\nbill-length-mm\nI prefer underscores, I think they’re the easiest to read. But you also need to consider your end-user’s software. Programs like Stata don’t support dashes or dots in variable names, so you’re kinda forced into using underscores anyway. Fine by me!\n\n\nHave a human create and review the names\nThe convention you choose might act as a guide or it might act as a rule. If it’s a guide, there’s going to be some discretion involved in choosing what to use for certain elements, like {keyword}. For the general health rating, both w01_health_general and w01_health_rating are suitable options, but you have to choose one.\nRegardless of whether the convention is applied as a guide or rule, make sure you have a human review the resulting list of variable names, it’s important that you don’t end up with names that are offensive."
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html#other-considerations",
    "href": "post/2025-03-03-variable-naming-convention/index.html#other-considerations",
    "title": "What makes a good variable naming convention",
    "section": "Other considerations",
    "text": "Other considerations\nHere’s a few other things that aren’t necessarily do’s or don’ts:\n\nCan a component be a variable in itself\n\nRecall I contemplated turning {wave} into a variable, rather than using it in the variable name\n\nAre there other creative ways of managing components?\n\nFor example, could questionnaires completed by children versus their parents be separate datasets instead of including respondent as a component?\n\nDo you use a different convention for administrative variables?\n\nParticipant ID doesn’t change over waves, so perhaps pid is sufficient over admin_pid\n\nTalk to people who will be typing the variable names, using the data\n\nGetting feedback from analysts, data managers, database admins will help shape your convention\nDesign it for real users, not hypothetical ones"
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html#further-reading",
    "href": "post/2025-03-03-variable-naming-convention/index.html#further-reading",
    "title": "What makes a good variable naming convention",
    "section": "Further reading",
    "text": "Further reading\nEmily Riederer wrote a great blog post on this topic, which helped inform my thinking - https://www.emilyriederer.com/post/column-name-contracts/\nWikipedia has articles on:\n\nNaming conventions\nDelimiters\n\nThe tidyverse style guide has opinions about names and more https://style.tidyverse.org/"
  },
  {
    "objectID": "post/2025-03-03-variable-naming-convention/index.html#want-to-cite-this",
    "href": "post/2025-03-03-variable-naming-convention/index.html#want-to-cite-this",
    "title": "What makes a good variable naming convention",
    "section": "Want to cite this?",
    "text": "Want to cite this?\n@online{harrap2025variable,\n  author = {Benjamin Harrap},\n  title = {What makes a good variable naming convention},\n  year = {2025},\n  url = {https://benharrap.com/post/2025-03-03-variable-naming-convention},\n}"
  },
  {
    "objectID": "post/2025-11-05-joke/index.html",
    "href": "post/2025-11-05-joke/index.html",
    "title": "What is the sheep’s favourite graph?",
    "section": "",
    "text": "A baa plot"
  },
  {
    "objectID": "post/2021-06-28-confirmation-presentation/index.html",
    "href": "post/2021-06-28-confirmation-presentation/index.html",
    "title": "PhD Confirmation Presentation",
    "section": "",
    "text": "This is the video recording of my PhD confirmation presentation delivered at the Centre for Epidemiology and Biostatistics, Melbourne School of Population and Global Health on the 31st of May, 2021.\n\n\nIf you have any questions or comments, let me know on Twitter."
  },
  {
    "objectID": "post/2025-03-17-joke/index.html",
    "href": "post/2025-03-17-joke/index.html",
    "title": "How can you tell that statisticians love Vietnamese food?",
    "section": "",
    "text": "They’re always talking about P(H0)"
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html",
    "href": "post/2026-02-04-stata-log-files/index.html",
    "title": "Using R to extract results from Stata log files",
    "section": "",
    "text": "Taking results from Stata and inserting them into a report is a colossal pain in the ass, to put it mildly. There are a few custom commands out there, like baselinetable, that help ease the pain somewhat, but copy-pasting results from console output or log files seems inevitable and introduces human error.\nIt doesn’t have to be this way though! Recently, my predominantly Stata-using team has started making an effort to use Quarto for some regular reports we need to deliver. Naturally I’m thrilled, because Quarto is such a useful tool and it’ll save us a lot of time and error copy-pasting results from Stata. The only problem is we need Stata output in a format that we can read in for our Quarto report.\nMy solution for this? Write R functions that extract results from Stata’s log files! mind_blown.gif"
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#whats-a-log-file",
    "href": "post/2026-02-04-stata-log-files/index.html#whats-a-log-file",
    "title": "Using R to extract results from Stata log files",
    "section": "What’s a log file?",
    "text": "What’s a log file?\nEvery Stata user should already be familiar with log files, but if you’re not, they just log all of the commands you run during a Stata session, along with their outputs, in an .smcl file. This stands for “Stata Markup and Control Language” and is pronounced “smickle” according to Stata’s help files. I don’t care to get into the detail of how these work, all I need to know is I can read it in to R as a text file.\nTo demonstrate, I ran the following commands in Stata\n\n1log using log\n2sysuse auto, clear\n3tab headroom foreign\n4tab rep78\n5su price\n6su price weight length gear_ratio\n7reg mpg displacement gear_ratio weight price\n8margins, at(weight=(2000(500)4500))\n9log close\n\n\n1\n\nStart recording a log of the session, outputting to log.smcl\n\n2\n\nUse the auto data, similar to mtcars\n\n3\n\nCreate a two-way table\n\n4\n\nTabulate a single variable\n\n5\n\nProduce descriptives of a single variable\n\n6\n\nThen for multiple variables\n\n7\n\nFit a regression model with mpg as the outcome\n\n8\n\nProduce predictive margins at a severak values of weight\n\n9\n\nStop recording to the log file\n\n\n\n\nIf you want to see what the file looks like, it’s here."
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#the-guts-of-it",
    "href": "post/2026-02-04-stata-log-files/index.html#the-guts-of-it",
    "title": "Using R to extract results from Stata log files",
    "section": "The guts of it",
    "text": "The guts of it\nNow we’ve got a log file to play with, we can read it into R and have a look.\n\ndata &lt;- read.delim(\"log.smcl\")\ndata[8:22,]\n\n [1] \"{com}. tab headroom foreign\"                                               \n [2] \"  {txt}Headroom {c |}      Car origin\"                                     \n [3] \"     (in.) {c |}  Domestic    Foreign {c |}     Total\"                     \n [4] \"{hline 11}{c +}{hline 22}{c +}{hline 10}\"                                  \n [5] \"       1.5 {c |}{res}         3          1 {txt}{c |}{res}         4 \"     \n [6] \"{txt}       2.0 {c |}{res}        10          3 {txt}{c |}{res}        13 \"\n [7] \"{txt}       2.5 {c |}{res}         4         10 {txt}{c |}{res}        14 \"\n [8] \"{txt}       3.0 {c |}{res}         7          6 {txt}{c |}{res}        13 \"\n [9] \"{txt}       3.5 {c |}{res}        13          2 {txt}{c |}{res}        15 \"\n[10] \"{txt}       4.0 {c |}{res}        10          0 {txt}{c |}{res}        10 \"\n[11] \"{txt}       4.5 {c |}{res}         4          0 {txt}{c |}{res}         4 \"\n[12] \"{txt}       5.0 {c |}{res}         1          0 {txt}{c |}{res}         1 \"\n[13] \"{txt}{hline 11}{c +}{hline 22}{c +}{hline 10}\"                             \n[14] \"     Total {c |}{res}        52         22 {txt}{c |}{res}        74 \"     \n[15] \"{com}. tab rep78\"                                                          \n\n\nThere’s a bunch of markup here that Stata uses to format the file nicely when you view it using Stata. It’s a bit ugly to look at as plain-text but there are some helpful things to notice here, which we can use to extract our results:\n\nCommand lines begin with {com}. (see lines 1 and 15)\nThe results lines end with a number (lines 5 through 12, and 14)\n\nThe output looks a little complicated with how it’s ordered, because it’s tabulating two variables. Line 5 has results, but doesn’t begin with {txt}. The first value in lines 5 to 12 are the values of headroom, while the remaining values correspond to ‘Domestic’, ‘Foreign’ and ‘Total’.\nLet’s check the output for the other commands though. Here’s the summarise (or su) output:\n\ndata[33:43,]\n\n [1] \"{com}. su price\"                                                                             \n [2] \"{txt}    Variable {c |}        Obs        Mean    Std. dev.       Min        Max\"            \n [3] \"{hline 13}{c +}{hline 57}\"                                                                   \n [4] \"{space 7}price {c |}{res}         74    6165.257    2949.496       3291      15906\"          \n [5] \"{com}. su price weight length gear_ratio\"                                                    \n [6] \"{txt}    Variable {c |}        Obs        Mean    Std. dev.       Min        Max\"            \n [7] \"{hline 13}{c +}{hline 57}\"                                                                   \n [8] \"{space 7}price {c |}{res}         74    6165.257    2949.496       3291      15906\"          \n [9] \"{txt}{space 6}weight {c |}{res}         74    3019.459    777.1936       1760       4840\"    \n[10] \"{txt}{space 6}length {c |}{res}         74    187.9324    22.26634        142        233\"    \n[11] \"{txt}{space 2}gear_ratio {c |}{res}         74    3.014865    .4562871       2.19       3.89\"\n\n\nThe results also end with a number here, but they don’t have a trailing whitespace. We can fix that later using stringr::str_trim(). Otherwise it looks fairly straightforward. Lines 2, 6, tell us what the results correspond to.\nLet’s check the regression output:\n\ndata[44:60,]\n\n [1] \"{com}. reg mpg displacement gear_ratio weight price\"                                                                                                                                       \n [2] \"{txt}      Source {c |}       SS           df       MS      Number of obs   ={res}        74\"                                                                                              \n [3] \"{txt}{hline 13}{c +}{hline 34}   F(4, 69)        = {res}    32.92\"                                                                                                                         \n [4] \"{txt}       Model {c |} {res} 1603.26274         4  400.815685   {txt}Prob &gt; F        ={res}    0.0000\"                                                                                    \n [5] \"{txt}    Residual {c |} {res} 840.196719        69   12.176764   {txt}R-squared       ={res}    0.6561\"                                                                                    \n [6] \"{txt}{hline 13}{c +}{hline 34}   Adj R-squared   ={res}    0.6362\"                                                                                                                         \n [7] \"{txt}       Total {c |} {res} 2443.45946        73  33.4720474   {txt}Root MSE        =   {res} 3.4895\"                                                                                    \n [8] \"{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                                           \n [9] \"{col 1}         mpg{col 14}{c |} Coefficient{col 26}  Std. err.{col 38}      t{col 46}   P&gt;|t|{col 54}     [95% con{col 67}f. interval]\"                                                   \n[10] \"{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                                                 \n[11] \"displacement {c |}{col 14}{res}{space 2} .0088833{col 26}{space 2} .0117481{col 37}{space 1}    0.76{col 46}{space 3}0.452{col 54}{space 4}-.0145535{col 67}{space 3}   .03232\"            \n[12] \"{txt}{space 2}gear_ratio {c |}{col 14}{res}{space 2} .9008024{col 26}{space 2} 1.645546{col 37}{space 1}    0.55{col 46}{space 3}0.586{col 54}{space 4}-2.381972{col 67}{space 3} 4.183577\"\n[13] \"{txt}{space 6}weight {c |}{col 14}{res}{space 2}-.0063068{col 26}{space 2} .0012248{col 37}{space 1}   -5.15{col 46}{space 3}0.000{col 54}{space 4}-.0087502{col 67}{space 3}-.0038635\"    \n[14] \"{txt}{space 7}price {c |}{col 14}{res}{space 2}-.0001173{col 26}{space 2} .0001687{col 37}{space 1}   -0.70{col 46}{space 3}0.489{col 54}{space 4}-.0004538{col 67}{space 3} .0002193\"     \n[15] \"{txt}{space 7}_cons {c |}{col 14}{res}{space 2}   36.595{col 26}{space 2} 6.734683{col 37}{space 1}    5.43{col 46}{space 3}0.000{col 54}{space 4} 23.15968{col 67}{space 3} 50.03033\"     \n[16] \"{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                                           \n[17] \"{res}\"                                                                                                                                                                                     \n\n\nIt’s very busy but the same principle applies — result lines (11 to 15) end with a number.\nFinally, the margins output:\n\ndata[61:85,]\n\n [1] \"{com}. margins, at(weight=(2000(500)4500))\"                                                                                                                                         \n [2] \"{res}\"                                                                                                                                                                              \n [3] \"{txt}{col 1}Predictive margins{col 61}{lalign 13:Number of obs}{col 74} = {res}{ralign 2:74}\"                                                                                       \n [4] \"{txt}{col 1}Model VCE: {res:OLS}\"                                                                                                                                                   \n [5] \"{txt}{p2colset 1 13 13 2}{...}\"                                                                                                                                                     \n [6] \"{p2col:Expression:}{res:Linear prediction, predict()}{p_end}\"                                                                                                                       \n [7] \"{p2colreset}{...}\"                                                                                                                                                                  \n [8] \"{lalign 7:1._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:2000}}\"                                                                                                               \n [9] \"{lalign 7:2._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:2500}}\"                                                                                                               \n[10] \"{lalign 7:3._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:3000}}\"                                                                                                               \n[11] \"{lalign 7:4._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:3500}}\"                                                                                                               \n[12] \"{lalign 7:5._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:4000}}\"                                                                                                               \n[13] \"{lalign 7:6._at: }{space 0}{lalign 6:weight} = {res:{ralign 4:4500}}\"                                                                                                               \n[14] \"{res}{txt}{hline 13}{c TT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                               \n[15] \"{col 14}{c |}{col 26} Delta-method\"                                                                                                                                                 \n[16] \"{col 14}{c |}     Margin{col 26}   std. err.{col 38}      t{col 46}   P&gt;|t|{col 54}     [95% con{col 67}f. interval]\"                                                               \n[17] \"{hline 13}{c +}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                                          \n[18] \"{space 9}_at {c |}\"                                                                                                                                                                 \n[19] \"{space 10}1  {c |}{col 14}{res}{space 2} 27.72685{col 26}{space 2} 1.312853{col 37}{space 1}   21.12{col 46}{space 3}0.000{col 54}{space 4} 25.10778{col 67}{space 3} 30.34593\"     \n[20] \"{txt}{space 10}2  {c |}{col 14}{res}{space 2} 24.57344{col 26}{space 2}   .75454{col 37}{space 1}   32.57{col 46}{space 3}0.000{col 54}{space 4} 23.06817{col 67}{space 3} 26.07871\"\n[21] \"{txt}{space 10}3  {c |}{col 14}{res}{space 2} 21.42002{col 26}{space 2} .4063483{col 37}{space 1}   52.71{col 46}{space 3}0.000{col 54}{space 4} 20.60938{col 67}{space 3} 22.23067\"\n[22] \"{txt}{space 10}4  {c |}{col 14}{res}{space 2} 18.26661{col 26}{space 2}  .714807{col 37}{space 1}   25.55{col 46}{space 3}0.000{col 54}{space 4} 16.84061{col 67}{space 3} 19.69261\"\n[23] \"{txt}{space 10}5  {c |}{col 14}{res}{space 2} 15.11319{col 26}{space 2} 1.267604{col 37}{space 1}   11.92{col 46}{space 3}0.000{col 54}{space 4} 12.58439{col 67}{space 3}   17.642\"\n[24] \"{txt}{space 10}6  {c |}{col 14}{res}{space 2} 11.95978{col 26}{space 2} 1.858154{col 37}{space 1}    6.44{col 46}{space 3}0.000{col 54}{space 4} 8.252865{col 67}{space 3} 15.66669\"\n[25] \"{txt}{hline 13}{c BT}{hline 11}{hline 11}{hline 9}{hline 8}{hline 13}{hline 12}\"                                                                                                    \n\n\nThe main thing to notice is that the values of weight at which the estimates are produced are in lines 8 to 13, while the estimates themselves are on separate lines (19 to 24)."
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#separate-out-the-results",
    "href": "post/2026-02-04-stata-log-files/index.html#separate-out-the-results",
    "title": "Using R to extract results from Stata log files",
    "section": "Separate out the results",
    "text": "Separate out the results\nI could’ve split the analysis up across multiple log files. For example, outputting tabulations into tabulation.log, the summaries into summaries.log, the regression model into regression.log and the margins into margins.log. There’s not much need though, since we can use the command rows to subset the data. We’ll need them like this for our Quarto report anyway, plus each command seems to need slightly different work.\n\nlibrary(tidyverse)\ndata &lt;- data |&gt; \n  mutate(\n    # Create a variable to identify each command\n    command = if_else(\n      str_detect(X.smcl., \"\\\\{com\\\\}\\\\.\"),\n      true = X.smcl.,\n      false = NA\n    )\n  ) |&gt; \n  # Fill downward to catch all the lines of output from that command\n  fill(command, .direction = \"down\")\n\nNotice the double backslashes in str_detect() - we need to escape the special characters since we’re using a regular expression here.\nNow we’ve identified the lines from each command, we can separate out our results.\n\ntab_headroom_foreign &lt;- filter(data, command == \"{com}. tab headroom foreign\")\ntab_rep78 &lt;- filter(data, command == \"{com}. tab rep78\")\nsummaries &lt;- filter(data, command == \"{com}. su price weight length gear_ratio\")\nregression &lt;- filter(data, command == \"{com}. reg mpg displacement gear_ratio weight price\")\nmargins &lt;- filter(data, command == \"{com}. margins, at(weight=(2000(500)4500))\")"
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#one-way-tables",
    "href": "post/2026-02-04-stata-log-files/index.html#one-way-tables",
    "title": "Using R to extract results from Stata log files",
    "section": "One-way tables",
    "text": "One-way tables\nStarting with the simplest output, let’s extract the counts of each level of rep78:\n\ntab_rep78 &lt;- tab_rep78 |&gt; \n  mutate(\n    results = case_when(\n1        str_detect(X.smcl., \"((-)?\\\\.)?\\\\d+(\\\\.\\\\d+)?$\")\n2        ~ str_extract_all(X.smcl.,\"((-)?\\\\.)?\\\\d+(\\\\.\\\\d+)?\"),\n        .default = NA\n      ),\n4    X.smcl. = str_squish(str_remove_all(X.smcl.,\"\\\\{.+\\\\}\"))\n  ) |&gt; \n3  hoist(\n    \"results\",\n    repair_record = 1,\n    frequency = 2,\n    percent = 3,\n    cumulative = 4\n  ) |&gt; \n  select(-command)\n\ntab_rep78\n\n\n1\n\nThis regex is looking for strings that optionally start with a negative or decimal (((-)?\\\\.)?), followed by any number of digits (\\\\d+), optionally followed by a decimal and any number of digits ((\\\\.\\\\d+)), at the end of the string $\n\n2\n\nstringr::str_extract_all() then extracts all instances of this pattern anywhere in the string (we omit the $), returning a list-column called results\n\n3\n\ntidyr::hoist() then extracts the elements of results into their own column, to which we assign names\n\n4\n\nI just formatted the output to look nicer on this blog post, this step is unnecessary here\n\n\n\n\n                          X.smcl. repair_record frequency percent cumulative\n1                     . tab rep78            78      &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;\n2                                          &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;\n3  record 1978 Freq. Percent Cum.          &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;\n4                                          &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;\n5                   1 2 2.90 2.90             1         2    2.90       2.90\n6                   8 11.59 14.49             2         8   11.59      14.49\n7                  30 43.48 57.97             3        30   43.48      57.97\n8                  18 26.09 84.06             4        18   26.09      84.06\n9                 11 15.94 100.00             5        11   15.94     100.00\n10                                         &lt;NA&gt;      &lt;NA&gt;    &lt;NA&gt;       &lt;NA&gt;\n11                Total 69 100.00            69    100.00    &lt;NA&gt;       &lt;NA&gt;\n\n\nNotice that the ‘Total’ row (11) hasn’t quite worked. We could tinker with the regex or mutate() the correct values in. Or we could just use janitor::adorn_totals() to make our lives easier:\n\nlibrary(janitor)\ntab_rep78 |&gt; \n  filter(!is.na(cumulative)) |&gt; \n  select(repair_record:percent) |&gt; \n  mutate(across(everything(), as.numeric)) |&gt; \n  adorn_totals(\"row\")\n\n repair_record frequency percent\n             1         2    2.90\n             2         8   11.59\n             3        30   43.48\n             4        18   26.09\n             5        11   15.94\n         Total        69  100.00"
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#regression-output",
    "href": "post/2026-02-04-stata-log-files/index.html#regression-output",
    "title": "Using R to extract results from Stata log files",
    "section": "Regression output",
    "text": "Regression output\nThe combination of str_extract_all() and hoist() is what this all boils down to, but there’s a bit of tweaking we need to do for the regression output. The regex in the previous example was extracting all instances of digits with optional decimals, however in the regression output there’s spacing markup like {hline 13}, which we don’t want to extract.\nWe could fix this by modifying the regex, but I’m not a fan of making large, complicated expressions if I can avoid it, so instead we can just replace anything inside of a curly bracket with a space, using str_replace_all().\n\nregression |&gt;\n  mutate(\n    X.smcl. = str_replace_all(X.smcl., \"\\\\{[\\\\w|\\\\d|\\\\s]+\\\\}\", \" \"),\n    results = case_when(\n      str_detect(X.smcl., \"((-)?\\\\.)?\\\\d+(\\\\.\\\\d+)?$\") ~ str_extract_all(\n        X.smcl.,\n        \"((-)?\\\\.)?\\\\d+(\\\\.\\\\d+)?\"\n      ),\n      .default = NA\n    )\n  ) |&gt;\n  hoist(\n    \"results\",\n    estimate = 1,\n    std_err = 2,\n    t = 3,\n    p_val = 4,\n    ci_lower = 5,\n    ci_upper = 6\n  ) |&gt;\n  filter(!is.na(ci_upper)) |&gt;\n  select(-command) |&gt;\n  mutate(\n    X.smcl. = str_sub(\n      X.smcl.,\n      start = str_locate(X.smcl., \"[:graph:]+\")[, \"start\"],\n      end = str_locate(X.smcl., \"[:graph:]+\")[, \"end\"]\n    )\n  ) |&gt;\n  rename(variable = X.smcl.)\n\n      variable  estimate  std_err    t p_val  ci_lower  ci_upper\n1 displacement  .0088833 .0117481 0.76 0.452 -.0145535    .03232\n2   gear_ratio  .9008024 1.645546 0.55 0.586  2.381972  4.183577\n3       weight -.0063068 .0012248 5.15 0.000 -.0087502 -.0038635\n4        price -.0001173 .0001687 0.70 0.489 -.0004538  .0002193\n5        _cons    36.595 6.734683 5.43 0.000  23.15968  50.03033\n\n\nThe last thing to do here is create the variable column by extracting the variable names using str_sub and the start/end locations of the first place that numbers/letters/punctuation are detected."
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#margins-output",
    "href": "post/2026-02-04-stata-log-files/index.html#margins-output",
    "title": "Using R to extract results from Stata log files",
    "section": "Margins output",
    "text": "Margins output\nFor the margins we can recycle the same code to extract the results, although we need to do a bit more work to name the margins correctly.\n\nmargins |&gt;\n  mutate(\n    X.smcl. = str_replace_all(X.smcl., \"\\\\{[\\\\w|\\\\d|\\\\s]+\\\\}\", \" \"),\n    results = case_when(\n      str_detect(X.smcl., \"\\\\d+(\\\\.\\\\d+)?$\") ~ str_extract_all(X.smcl.,\"((-)?\\\\.)?\\\\d+(\\\\.\\\\d+)?\"),\n      .default = NA\n    )\n  ) |&gt;\n  hoist(\n    \"results\",\n    margin = 1,\n    estimate = 2,\n    std_err = 3,\n    t = 4,\n    p_val = 5,\n    ci_lower = 6,\n    ci_upper = 7\n  ) |&gt; \n  filter(!is.na(ci_upper)) |&gt; \n  select(-command, -X.smcl.) |&gt; \n  mutate(\n    margin = case_when(\n      margin == \"1\" ~ \"weight = 2000\",\n      margin == \"2\" ~ \"weight = 2500\",\n      margin == \"3\" ~ \"weight = 3000\",\n      margin == \"4\" ~ \"weight = 3500\",\n      margin == \"5\" ~ \"weight = 4000\",\n      margin == \"6\" ~ \"weight = 4500\",\n    )\n  )\n\n         margin estimate  std_err     t p_val ci_lower ci_upper\n1 weight = 2000 27.72685 1.312853 21.12 0.000 25.10778 30.34593\n2 weight = 2500 24.57344   .75454 32.57 0.000 23.06817 26.07871\n3 weight = 3000 21.42002 .4063483 52.71 0.000 20.60938 22.23067\n4 weight = 3500 18.26661  .714807 25.55 0.000 16.84061 19.69261\n5 weight = 4000 15.11319 1.267604 11.92 0.000 12.58439   17.642\n6 weight = 4500 11.95978 1.858154  6.44 0.000 8.252865 15.66669\n\n\nI could’ve written code to automatically extract the margin value and assign it, instead of manually coding the value of margin, but I want to finish this blog post so *waves hands*."
  },
  {
    "objectID": "post/2026-02-04-stata-log-files/index.html#extracting-a-two-way-table",
    "href": "post/2026-02-04-stata-log-files/index.html#extracting-a-two-way-table",
    "title": "Using R to extract results from Stata log files",
    "section": "Extracting a two-way table",
    "text": "Extracting a two-way table\n\ntab_headroom_foreign |&gt; select(-command)\n\n                                                                      X.smcl.\n1                                                 {com}. tab headroom foreign\n2                                         {txt}Headroom {c |}      Car origin\n3                            (in.) {c |}  Domestic    Foreign {c |}     Total\n4                                    {hline 11}{c +}{hline 22}{c +}{hline 10}\n5              1.5 {c |}{res}         3          1 {txt}{c |}{res}         4 \n6  {txt}       2.0 {c |}{res}        10          3 {txt}{c |}{res}        13 \n7  {txt}       2.5 {c |}{res}         4         10 {txt}{c |}{res}        14 \n8  {txt}       3.0 {c |}{res}         7          6 {txt}{c |}{res}        13 \n9  {txt}       3.5 {c |}{res}        13          2 {txt}{c |}{res}        15 \n10 {txt}       4.0 {c |}{res}        10          0 {txt}{c |}{res}        10 \n11 {txt}       4.5 {c |}{res}         4          0 {txt}{c |}{res}         4 \n12 {txt}       5.0 {c |}{res}         1          0 {txt}{c |}{res}         1 \n13                              {txt}{hline 11}{c +}{hline 22}{c +}{hline 10}\n14           Total {c |}{res}        52         22 {txt}{c |}{res}        74 \n\n\nI left this to last because it looks annoying to do. Unfortunately, my patience for dealing with Stata log files has run out as I write this blog post, so let’s pretend this last one is homework for you to figure out ;)\nHopefully though I’ve demonstrated that, with a little bit of work, you can get results out of Stata log files. Once you’ve done that, it’s business as usual as you write up your Quarto report!"
  },
  {
    "objectID": "post/2025-08-06-joke/index.html",
    "href": "post/2025-08-06-joke/index.html",
    "title": "What did the doctor prescribe Dumbo to help with his pain?",
    "section": "",
    "text": "Elephentanyl"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html",
    "href": "post/2024-05-10-completion-seminar/index.html",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "",
    "text": "I presented my PhD completion seminar to the Melbourne School of Population and Global Health on the 10th of May, 2024. I’ve included the recording of the seminar here and the content from the slides is beneath. If you have any questions feel free to reach out!"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#child-removals",
    "href": "post/2024-05-10-completion-seminar/index.html#child-removals",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Child removals",
    "text": "Child removals\nAboriginal and Torres Strait Islander children are over-represented in child protection statistics in every state and territory1\nRisk of entering out-of-home care increased by:\n\nTeenage parents, substance use during pregnancy, parental intellectual disability, poor maternal mental health2–5\nParental experience of out-of-home care, living in low-SES areas, systemic racism2–4,6,7\nConsequences of colonisation7,8"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#health",
    "href": "post/2024-05-10-completion-seminar/index.html#health",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Health",
    "text": "Health\nAboriginal and Torres Strait Islander children also have inequitable health outcomes:\n\nHigher burden of disease generally9\nHigher rates of potentially preventable hospitalisations10\n\nAttributable to housing, SES, systemic racism\n\nColonisation"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#data-gaps",
    "href": "post/2024-05-10-completion-seminar/index.html#data-gaps",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Data gaps",
    "text": "Data gaps\nCurrent research examines child protection and health independently, little on the intersection of these topics.\nOf the studies that do exist, they either:\n\nExamine how health predicts child protection involvement2,11,12\nExamine specialist referrals at hospital clinics13–16 and Aboriginal Medical Services17–19\n\nNo studies quantifying specific health needs for Aboriginal children in out-of-home care or comparing to other Aboriginal children."
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#i-care-wa-study",
    "href": "post/2024-05-10-completion-seminar/index.html#i-care-wa-study",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "I-CaRe WA study",
    "text": "I-CaRe WA study\nPrincipal Investigator: Professor Sandra Eades\nQualitative objectives\n\nExplore views from Aboriginal kinship carers\nExplore views from Aboriginal primary healthcare staff\n\nQuantitative objectives\n\nExamine contemporary WA child protection data\nIdentify predictors of out-of-home care\nDescribe the health of the children before and after entering care"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#my-phd",
    "href": "post/2024-05-10-completion-seminar/index.html#my-phd",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "My PhD",
    "text": "My PhD\n\nIntroduction and literature review\nMethodology\nDescriptive analysis of trends in the child protection system\nPrevalence of mental and neurodevelopmental health conditions\nRates of potentially preventable hospitalisations\nDiscussion\n\nInformed by qualitative research findings and reference group discussions\nSupervisors:\n\nProf Sandra Eades (University of Melbourne)\nProf Melissa O’Donnell (University of South Australia)\nDr Alison Gibberd (University of Melbourne)\nDr Koen Simons (University of Gothenburg)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#data-linkage",
    "href": "post/2024-05-10-completion-seminar/index.html#data-linkage",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Data linkage",
    "text": "Data linkage\nProvided by Data Linkage Services Western Australia (DLSWA)\nProbabilistic matching to link individual records across datasets20,21\nAll Aboriginal children born in Western Australia between 2000 and 2013\nData covering 2000 to 2019"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#data-sources",
    "href": "post/2024-05-10-completion-seminar/index.html#data-sources",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Data sources",
    "text": "Data sources\n\nBirth registrations\nMidwives Notification System\nDeath registrations\nChild Protection and Family Support Data\nHospital Morbidity Database Collection\nEmergency Department Database Collection\nWA Register of Developmental Anomalies - Birth defects\nWA Register of Developmental Anomalies - Cerebral Palsy\nIntellectual Disability Exploring Answers\nMental Health Information System"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#published-paper-harrap2023",
    "href": "post/2024-05-10-completion-seminar/index.html#published-paper-harrap2023",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Published paper22",
    "text": "Published paper22"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#aims",
    "href": "post/2024-05-10-completion-seminar/index.html#aims",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Aims",
    "text": "Aims\n\nExamine contacts with CPS by stage and birth cohort\nExamine how contacts are clustered within sibling groups"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#methods",
    "href": "post/2024-05-10-completion-seminar/index.html#methods",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Methods",
    "text": "Methods\nData\n\nChild protection data from 2000 to 2015\n\nAnalysis\n\nCumulative incidence\n\nBy two-year birth cohort\nBy sibling contact status\n\nTabulation of timing of placements relative to first within sibling group"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-first-contacts-with-cps-2000-to-2015",
    "href": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-first-contacts-with-cps-2000-to-2015",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Cumulative incidence of first contacts with CPS, 2000 to 2015",
    "text": "Cumulative incidence of first contacts with CPS, 2000 to 2015"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-first-contacts-with-cps-2000-to-2015-by-year-of-birth",
    "href": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-first-contacts-with-cps-2000-to-2015-by-year-of-birth",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Cumulative incidence of first contacts with CPS, 2000 to 2015, by year of birth",
    "text": "Cumulative incidence of first contacts with CPS, 2000 to 2015, by year of birth"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#siblings",
    "href": "post/2024-05-10-completion-seminar/index.html#siblings",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Siblings",
    "text": "Siblings"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#timing-of-contacts-within-maternal-sibling-groups-2000-2015",
    "href": "post/2024-05-10-completion-seminar/index.html#timing-of-contacts-within-maternal-sibling-groups-2000-2015",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Timing of contacts within maternal sibling groups, 2000-2015",
    "text": "Timing of contacts within maternal sibling groups, 2000-2015\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSame as first contact\n\n\nAfter first contact\n\n\nNo contact\n\n\n\nStage\nN\n%\nN\n%\nN\n%\n\n\n\n\nNotification\n6195\n64.1%\n1085\n11.2%\n2390\n24.7%\n\n\nInvestigation\n5708\n60.0%\n1177\n12.4%\n2628\n27.6%\n\n\nSubstantiation\n3442\n57.7%\n616\n10.3%\n1911\n32.0%\n\n\nPlacement\n2023\n64.7%\n260\n8.3%\n846\n27.0%"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#siblings-1",
    "href": "post/2024-05-10-completion-seminar/index.html#siblings-1",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Siblings",
    "text": "Siblings"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-contacts-by-birth-relative-to-first-contact",
    "href": "post/2024-05-10-completion-seminar/index.html#cumulative-incidence-of-contacts-by-birth-relative-to-first-contact",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Cumulative incidence of contacts by birth relative to first contact",
    "text": "Cumulative incidence of contacts by birth relative to first contact"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#aims-1",
    "href": "post/2024-05-10-completion-seminar/index.html#aims-1",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Aims",
    "text": "Aims\n\nEstimate prevalence of mental and neurodevelopmental health conditions for ever/never placed Aboriginal children\nExamine cumulative incidence of conditions for ever/never placed children\nCompare conditions for ever placed Aboriginal children depending on when first placement occurred (pre/post 1-year old)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#methods-1",
    "href": "post/2024-05-10-completion-seminar/index.html#methods-1",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Methods",
    "text": "Methods\nMatched never-placed children to ever-placed children, 2:1 on:\n\nYear of birth\nRemoteness area at birth23\nIndex of relative socioeconomic advantage/disadvantage at birth24\n\nEstimated prevalence of mental and neurodevelopmental conditions using:\n\nHospital data\nMental Health Information System\nRegistries"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#prevalence-estimates-for-never-vs.-ever-placed-children-n11159",
    "href": "post/2024-05-10-completion-seminar/index.html#prevalence-estimates-for-never-vs.-ever-placed-children-n11159",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Prevalence estimates for never vs. ever placed children (N=11,159)",
    "text": "Prevalence estimates for never vs. ever placed children (N=11,159)\n\n\n\n\n\nCondition\nNever placed n=7,439\nEver placed n=3,720\n\n\n\n\nAny ID/DD/CA\n2% (1.7 - 2.4)\n6.2% (5.5 - 7)\n\n\nAutism\n0.9% (0.7 - 1.1)\n1.1% (0.8 - 1.5)\n\n\nFASD\n0.2% (0.1 - 0.4)\n2.2% (1.7 - 2.7)\n\n\nDevelopmental delay\n1% (0.8 - 1.2)\n2.2% (1.8 - 2.8)\n\n\nAny MH\n5% (4.5 - 5.5)\n14.8% (13.7 - 16)\n\n\nAnxiety\n1% (0.7 - 1.2)\n1.9% (1.5 - 2.4)\n\n\nDepression\n0.7% (0.5 - 0.9)\n1% (0.7 - 1.4)\n\n\nPTSD\n0.5% (0.4 - 0.7)\n3.6% (3 - 4.3)\n\n\nAdjustment\n1% (0.8 - 1.2)\n3% (2.5 - 3.6)\n\n\nHyperkinetic\n0.1% (0.1 - 0.2)\n1% (0.7 - 1.4)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#results",
    "href": "post/2024-05-10-completion-seminar/index.html#results",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Results",
    "text": "Results"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#prevalence-estimates-for-placement-pre-vs.-post-1-yr-old-n3432",
    "href": "post/2024-05-10-completion-seminar/index.html#prevalence-estimates-for-placement-pre-vs.-post-1-yr-old-n3432",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Prevalence estimates for placement pre vs. post 1-yr old (N=3,432)",
    "text": "Prevalence estimates for placement pre vs. post 1-yr old (N=3,432)\n\n\n\n\n\nCondition\nPre 1-year n=1,098\nPost 1-year n=2,333\n\n\n\n\nAny ID/DD/CA\n9% (7.4 - 10.9)\n5.2% (4.3 - 6.2)\n\n\nAutism\n1.4% (0.8 - 2.2)\n1% (0.7 - 1.5)\n\n\nFASD\n4% (2.9 - 5.3)\n1.4% (0.9 - 1.9)\n\n\nDevelopmental delay\n2.7% (1.9 - 3.9)\n2.2% (1.6 - 2.9)\n\n\nAny MH\n13.3% (11.3 - 15.4)\n15.3% (13.8 - 16.8)\n\n\nAnxiety\n2.5% (1.6 - 3.6)\n1.8% (1.3 - 2.4)\n\n\nDepression\n0.9% (0.4 - 1.7)\n1% (0.7 - 1.5)\n\n\nPTSD\n2.1% (1.3 - 3.1)\n4.1% (3.3 - 5)\n\n\nAdjustment\n2.3% (1.5 - 3.3)\n3.3% (2.6 - 4.1)\n\n\nHyperkinetic\n1.3% (0.7 - 2.1)\n0.9% (0.6 - 1.4)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#aims-2",
    "href": "post/2024-05-10-completion-seminar/index.html#aims-2",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Aims",
    "text": "Aims\n\nEstimate rates of potentially-preventable hospitalisations (PPHs) for ever and never-placed Aboriginal children\nCompare types of conditions diagnosed during PPHs for ever and never-placed children\nEstimate rates of PPHs for ever-placed children before and after their first placement"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#methods-2",
    "href": "post/2024-05-10-completion-seminar/index.html#methods-2",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Methods",
    "text": "Methods\nMatching never-placed to ever-placed children 2:1 on month-year of birth, remoteness, and socio-economic status.\nEstimate incidence rate of days spent in hospital where primary diagnosis was PPH condition using child-appropriate definition25\n\nRates expressed as days in hospital per 1,000 days at risk\nRate ratios used to compare groups\n\nEstimate effect of placement in care on rate of admissions using mixed-effects model"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#incidence-rate-for-ever-and-never-placed-children",
    "href": "post/2024-05-10-completion-seminar/index.html#incidence-rate-for-ever-and-never-placed-children",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Incidence rate for ever and never-placed children",
    "text": "Incidence rate for ever and never-placed children\n\n\n\n\n\nAge group\nExposure\nIncidence rate\nIRR\n\n\n\n\n0-4\nEver placed\n3.37 (3.33 to 3.41)\n2.2 (2.2 to 2.2)\n\n\n0-4\nNever placed\n1.53 (1.51 to 1.55)\n\n\n\n5-9\nEver placed\n0.67 (0.65 to 0.69)\n1.7 (1.6 to 1.8)\n\n\n5-9\nNever placed\n0.40 (0.38 to 0.41)\n\n\n\n10-14\nEver placed\n0.58 (0.55 to 0.60)\n2.3 (2.2 to 2.5)\n\n\n10-14\nNever placed\n0.25 (0.24 to 0.26)\n\n\n\nAll\nEver placed\n1.74 (1.72 to 1.76)\n2.1 (2.1 to 2.2)\n\n\nAll\nNever placed\n0.82 (0.81 to 0.83)\n\n\n\n\na Rate per 1,000 days at risk"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#most-common-pph-conditions",
    "href": "post/2024-05-10-completion-seminar/index.html#most-common-pph-conditions",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Most common PPH conditions",
    "text": "Most common PPH conditions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAges 0-4\n\n\nAges 5-9\n\n\nAges 10-14\n\n\n\nDiagnosis\nNever\nEver\nNever\nEver\nNever\nEver\n\n\n\n\nAcute Bronchiolitis\n1121 (19.4%)\n1023 (20.9%)\n\n\n\n\n\n\nAcute Rheumatic Fever\n\n\n\n\n14 (2.6%)\n21 (5.0%)\n\n\nAcute Upper Respiratory Tract Infection Excluding Croup\n623 (10.8%)\n517 (10.6%)\n77 (4.3%)\n59 (4.8%)\n41 (7.5%)\n28 (6.7%)\n\n\nAsthma\n389 (6.7%)\n307 (6.3%)\n118 (6.6%)\n61 (4.9%)\n31 (5.7%)\n16 (3.8%)\n\n\nBacterial/Unspecified Pneumonia\n517 (9.0%)\n434 (8.9%)\n119 (6.6%)\n81 (6.6%)\n58 (10.6%)\n41 (9.8%)\n\n\nConstipation\n\n\n32 (1.8%)\n33 (2.7%)\n26 (4.8%)\n12 (2.9%)\n\n\nDental (Dental Caries/Pulp/Periodontal)\n413 (7.2%)\n260 (5.3%)\n472 (26.3%)\n287 (23.3%)\n40 (7.3%)\n49 (11.8%)\n\n\nGastroenteritis\n989 (17.1%)\n803 (16.4%)\n101 (5.6%)\n60 (4.9%)\n36 (6.6%)\n16 (3.8%)\n\n\nOtitis Media\n451 (7.8%)\n508 (10.4%)\n276 (15.4%)\n240 (19.5%)\n42 (7.7%)\n46 (11.0%)\n\n\nSkin Infection\n518 (9.0%)\n457 (9.4%)\n395 (22.0%)\n244 (19.8%)\n164 (30.0%)\n108 (25.9%)\n\n\nUrinary Tract Infection\n\n\n42 (2.3%)\n42 (3.4%)\n21 (3.8%)\n23 (5.5%)\n\n\nViral Infection Of Unspecified Site\n233 (4.0%)\n190 (3.9%)\n54 (3.0%)\n50 (4.1%)\n\n\n\n\nViral Pneumonia\n76 (1.3%)\n75 (1.5%)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#incidence-rate-for-prepost-first-placement",
    "href": "post/2024-05-10-completion-seminar/index.html#incidence-rate-for-prepost-first-placement",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Incidence rate for pre/post first placement",
    "text": "Incidence rate for pre/post first placement\n\n\n\n\n\nAge group\nExposure\nIncidence rate\nIRR\n\n\n\n\n0-4\nPost-placement\n2.34 (2.29 to 2.40)\n0.6 (0.5 to 0.6)\n\n\n0-4\nPre-placement\n4.19 (4.12 to 4.26)\n\n\n\n5-9\nPost-placement\n0.59 (0.57 to 0.61)\n0.6 (0.6 to 0.7)\n\n\n5-9\nPre-placement\n0.94 (0.89 to 0.99)\n\n\n\n10-14\nPost-placement\n0.57 (0.54 to 0.59)\n0.8 (0.6 to 0.9)\n\n\n10-14\nPre-placement\n0.75 (0.65 to 0.87)\n\n\n\nAll ages\nPost-placement\n1.05 (1.03 to 1.07)\n0.3 (0.3 to 0.3)\n\n\nAll ages\nPre-placement\n3.17 (3.12 to 3.22)\n\n\n\n\na Rate per 1,000 days at risk"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#dag",
    "href": "post/2024-05-10-completion-seminar/index.html#dag",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "DAG",
    "text": "DAG"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#model-fit",
    "href": "post/2024-05-10-completion-seminar/index.html#model-fit",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Model fit",
    "text": "Model fit\nNegative binomial regression with random intercepts\nCount ~ Exposure + Pre_Post + Exposure*Pre_Post + log(Age) + I(Age^0.5) + Remoteness + IRSAD + (1 | id) + offset(log(Followup))\nEstimated average causal effect: IRR 0.89 (95% CI 0.82 - 0.97)"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#marginal-rates-per-1000-days-at-risk-across-follow-up",
    "href": "post/2024-05-10-completion-seminar/index.html#marginal-rates-per-1000-days-at-risk-across-follow-up",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Marginal rates per 1,000 days at risk across follow-up",
    "text": "Marginal rates per 1,000 days at risk across follow-up"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#marginal-rates-per-100000-days-at-risk-by-condition",
    "href": "post/2024-05-10-completion-seminar/index.html#marginal-rates-per-100000-days-at-risk-by-condition",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Marginal rates per 100,000 days at risk by condition",
    "text": "Marginal rates per 100,000 days at risk by condition"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#summary",
    "href": "post/2024-05-10-completion-seminar/index.html#summary",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Summary",
    "text": "Summary\n\nRates of contact with CPS have been occurring at younger ages for children born more recently\nContacts are clustered within sibling groups and risk carries over to siblings born later\nPrevalence of mental and neurodevelopmental health ~3x higher for children in OOHC compared to children never removed\nPrevalence of neurodevelopmental health conditions ~2x higher for children removed before the age of one than children first removed after the age of one\nRates of PPHs are higher for ever-placed children across all ages\nRates remain higher compared to never-placed children, even after CPS intervention\nPlacement in care has largest impact on PPHs in first few years of life"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#child-protection-implications",
    "href": "post/2024-05-10-completion-seminar/index.html#child-protection-implications",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Child protection implications",
    "text": "Child protection implications\n\nParents with children removed need more support\n\nWe know they are at increased risk of future children being removed\nReunification and prevention of future removals\n\nSupport needs to be culturally safe\nInput from Aboriginal people and Elders important in decision making process\n\nStaff within child protection system\nAboriginal family-led decision making\nAssigning child protection responsibilities to Aboriginal agencies"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#health-implications",
    "href": "post/2024-05-10-completion-seminar/index.html#health-implications",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Health implications",
    "text": "Health implications\nChildren with experience of out-of-home care often have multiple, complex health needs\n\nPublic health system capacity is an issue (for everyone)\n\nAvailability of affordable general practice\nLengthy wait times for specialist care\nIncrease in culturally competent medical professionals\n\nReducing risk of PPHs\n\nImprovements in housing\nAccess and availability of healthcare\n\nTransport\nWait times\nCost"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#what-this-contributes",
    "href": "post/2024-05-10-completion-seminar/index.html#what-this-contributes",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "What this contributes",
    "text": "What this contributes\n\nAddresses research gap\n\n“We already knew this”\nQuantifies some intersections of child protection and health\n\nPrioritising Aboriginal voices in the research process\nLaying groundwork for future research\n\nDisaggregation by region\nBuilding on DAG, include broader datasets\nEstimating effects of policy changes\nMeasuring informal care"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#research-translation-activities",
    "href": "post/2024-05-10-completion-seminar/index.html#research-translation-activities",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Research translation activities",
    "text": "Research translation activities\n\nTranslational workshops with community, government stakeholders, peak bodies\nPresentations to staff at NSW and WA child protection offices\nPresentation at International Population Data Linkage Conference 2022\nInfographics and lay summaries\nOpen-access publications"
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#data-custodians",
    "href": "post/2024-05-10-completion-seminar/index.html#data-custodians",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Data custodians",
    "text": "Data custodians\nI wish to thank the staff at DLSWA and the custodians of the Birth registrations, Midwives Notification System, Death registrations, Child Protection and Family Support Data, Hospital Morbidity Database Collection, Emergency Department Database Collection, WA Register of Developmental Anomalies - Birth defects, WA Register of Developmental Anomalies - Cerebral Palsy, Intellectual Disability Exploring Answers, Mental Health Information System.\nThe information presented does not reflect the views of the Data Linkage Branch or any of the data custodians."
  },
  {
    "objectID": "post/2024-05-10-completion-seminar/index.html#thanks",
    "href": "post/2024-05-10-completion-seminar/index.html#thanks",
    "title": "The Health of Aboriginal Children in Western Australia in the Context of the Child Protection System",
    "section": "Thanks",
    "text": "Thanks\n\nSupervisory team\nPhD cohort\nFamily and friends\nCommunity reference group"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html",
    "href": "post/2021-06-28-confirmation-report/index.html",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "",
    "text": "This is the report I prepared for my PhD confirmation on the 31st of May, 2021."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#acknowledgement-of-country",
    "href": "post/2021-06-28-confirmation-report/index.html#acknowledgement-of-country",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Acknowledgement of Country",
    "text": "Acknowledgement of Country\nI acknowledge the Wurundjeri Woi-wurrung, Wadawurrung, and Dja Dja Wurrung peoples who are the Traditional Owners of the lands that I live on and work from and I pay respect to their Elders past and present. I acknowledge their continuing connection to lands, waters, and communities and that sovereignty was never ceded. I also extend this respect to the communities across Western Australia who are affected by and contributed to this research project."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#engagement-with-aboriginal-people-and-community",
    "href": "post/2021-06-28-confirmation-report/index.html#engagement-with-aboriginal-people-and-community",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Engagement with Aboriginal People and Community",
    "text": "Engagement with Aboriginal People and Community\nI will be seeking the supervision and feedback throughout my PhD from Aboriginal and Torres Strait Islander people. Specifically:\n\nMy primary supervisor and the principal investigator, Professor Sandra Eades\nChief and Associate Investigators on the broader research team of which my PhD is a part of\nStaff from Aboriginal Community-Controlled Health Organisations who sit on the study advisory group\nMembers of the community and policy reference groups\nWestern Australian Aboriginal Health Ethics Committee\n\nMy PhD is part of a larger research project that is based on a co-creation of research model, which is the collaborative generation of knowledge by academics working alongside the community. Information collected as part of the qualitative component of the study (interviews with Aboriginal carers, community members, and staff at Aboriginal Community-Controlled Health Organisations) will also be used to direct the aims of the research."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#justification-of-research",
    "href": "post/2021-06-28-confirmation-report/index.html#justification-of-research",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Justification of research",
    "text": "Justification of research\nBased on my review of the literature there are several aspects of Aboriginal and Torres Strait Islander child removals and health that need more consideration.\n\nA more detailed analysis of child protection data\nMore up-to-date data is needed to evaluate the state of child removals in Western Australia and the outcomes of government policy over the last decade. The most current research has been based on data covering up to 2010, leaving out over a decade of child removals. The Australian Institute of Health and Welfare published more recent data in their report on child protection (Australian Institute of Health and Welfare (2020a)) however it is restricted to a fairly general overview of the state of child protection across Australia. The Family Matters Report 2019 (Lewis et al. 2019) examines child protection data in a little more detail, however this still is not to the level of detail explored in studies such as Bilson et al. (2017) or Jenkins et al. (2018). Examining trends in the data in greater detail can reveal impacts of changes to policy and practice at the departmental or regional level. Having this information available will help inform what policy changes were effective, which may have had unintended consequences, and develop new policy recommendations.\nAnother reason why a more detailed examination of the child protection data is needed is previous analyses have focused on risk factors, rather than taking a strengths-based approach and examining protective factors. The overall goal of the I-CaRe WA study is to identify factors that can help reduce the number of Aboriginal children going into out-of-home care, as well ways of supporting families who are at risk and children who are already in care.\n\n\nThe need to understand the health of children going into care\nIn the qualitative interviews conducted for the I-CaRe WA study, many carers raised the issue that the Department of Communities (the agency responsible for child protection in WA) does not pass on any information about the health of the children. This lack of information creates a barrier for the child and carer to accessing adequate primary healthcare and support services. This puts the children at risk of having health issues result in more severe illness, causing increased burden on the carers as well as the hospital services. Understanding what conditions are common in these children, and breaking it down by geographic region, can help inform healthcare services provided by local Aboriginal Community Controlled Health Organisations and other support agencies.\nBuilding a health profile of the children in care is also relevant for policymakers for two reasons. Firstly, this can inform service planning and delivery. For example, if children are appearing in hospital data with conditions that should have been managed in a primary care setting this may indicate that the appropriate services are not available or accessible to the families who need them. This can then inform the provision of additional services or outreach programs to help families at risk and prevent their children from ending up in hospital. More outreach is certainly needed, as Aboriginal and Torres Strait Islander people are under-represented in service usage data for services designed to support and prevent entry into the out-of-home care system (Lewis et al. 2019). Secondly, the treatment and management of health conditions has a monetary cost associated with it. Quantifying the number and type of health conditions means the monetary cost of providing this healthcare can be estimated, relevant for budgeting and funding of services.\n\n\nIdentifying protective factors and strengths of Aboriginal culture and practices\nIn addition to understanding the health of Aboriginal and Torres Strait Islander children going into care, it would also be beneficial to identify the strengths of the communities and cultural practices which protect against ill-health and interactions with the child protection system.\nAboriginal culture and practices are important, and Aboriginal ways of being and doing are critical to the principle of self-determination. By identifying strengths of these communities, more localised support can be provided to encourage and enhance these practices.\nThe overall goal of my research is to contribute new knowledge and evidence that can be used to support Aboriginal and Torres Strait Islander communities at risk of child protection involvement and help reduce the rate of children going into care."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#child-protection-in-australia",
    "href": "post/2021-06-28-confirmation-report/index.html#child-protection-in-australia",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Child protection in Australia",
    "text": "Child protection in Australia\nAustralia has a history of removing Aboriginal and Torres Strait Islander children from their families since colonisation, with the Stolen Generations being a very recent reminder of racist colonial practices of assimilation. The history of colonisation and the impact of these practices resulted in intergenerational trauma which is still felt by Aboriginal and Torres Strait Islander people and contributes to many challenges they face today, including deficits in parenting skills due to the disruption of families and prevention of passing on of knowledge, and high levels of substance use and mental health issues (Wilson & Wilkie 1997).\nWhile the policies underpinning the Stolen Generations came to an end in the late 1960s, Aboriginal and Torres Strait Islander children continue to be removed from their parents at an alarming rate, as evidenced by the over-representation of Aboriginal and Torres Strait Islander children in out-of-home care. In June 2019, the national rate of Aboriginal and Torres Strait Islander children in out-of-home care was 9.7 times higher than the rate for non-Indigenous children, with 1 in every 16.6 Aboriginal and Torres Strait Islander children in out-of-home care (Hunter et al. 2020). Western Australia was above the national average and the highest in the country at 16.7 times higher. In a recent Western Australian government report over 56% of children and young people in care were Aboriginal or Torres Strait Islander (Department of Communities 2020) despite only constituting around 6.4% of the child population (Commissioner for Children and Young People 2020). For Aboriginal and Torres Strait Islander children in Western Australia, placement with Indigenous carers is also below the national average at 46.9% in 2017-18 (SNAICC 2019a).\nThe tie to family, community, culture, and Country is a key part of Aboriginal and Torres Strait Islander children’s identity and growth and intrinsic to the concept of permanency (SNAICC 2016). This aspect of permanency is formalised in the Aboriginal and Torres Strait Islander Child Placement Principle (ATSICPP), which (from SNAICC (2013)) aims to:\n\nRecognise and protect the rights of Aboriginal and Torres Strait Islander children, family members and communities\nIncrease the level of self-determination for Aboriginal and Torres Strait Islander people in child welfare matters\nReduce the disproportionate representation of Aboriginal and Torres Strait Islander children in the child protection system.\n\nThis Principle has been adopted in jurisdictions around Australia, and, specifically in Western Australia, has been enshrined in law as part of the Child and Community Services Act 2004 (WA 2004). The ATSICPP also appears throughout policy documentation published by the Western Australian Department of Communities (hereafter referred to as ‘the Department’) over the last decade. The Department sees permanency as the most important outcome for children (Department of Communities 2017) and incorporates permanency planning into child protection cases from the beginning. Permanency, however, is defined differently by the Department, with the ATSICPP being one aspect of permanency planning. The difference in the Department’s understanding of permanency is that the critical aspect is the formation of a long-term attachment to a carer, which disregards Aboriginal and Torres Strait Islander perspectives and ways of experiencing permanency (SNAICC 2019b).\nOn paper, the Department’s operations are aimed at reducing the over-representation of Aboriginal and Torres Strait Islander children in care, with policy directives stating that more Aboriginal Community-Controlled Organisations will be engaged to provide services, Department staff will be trained to provide ‘culturally safe’ services, more services will be funded to support families at risk, provision of support is preferred over removal of a child, and in the case of removal, reunification is worked towards (Department of Communities 2017, 2016a, 2016b). In addition to these positive policies, the Department’s operations have been based on the Signs of Safety framework (Department of Communities 2011) since 2011, a framework which encourages real relationship building between families involved and various professionals, and the consideration of strengths of parents and opportunities for safety, rather than operating in a purely risk-averse way (Turnell & Edwards 1999).\nThe combination of the ATSICPP being embedded in the legal framework and the various policy documents from the last decade would suggest that a reduction would have been achieved. This is unfortunately not the case, with the rate and number of Aboriginal and Torres Strait Islander children in out-of-home care increasing yearly for at least the past decade."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#key-definitions",
    "href": "post/2021-06-28-confirmation-report/index.html#key-definitions",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Key definitions",
    "text": "Key definitions\nBefore exploring the research on child protection issues in Australia I will first define some key terminology used by the Department and in research more generally.\nMaltreatment of a child is categorised into four broad categories, of which several can be present at the same time:\n\nNeglect - when a child does not receive adequate food or shelter, medical treatment, supervision, care or nurturance to such an extent that their development is damaged or they are injured (Department of Communities 2012a).\nPhysical abuse - when a child is severely and/or persistently hurt or injured by an adult or a child’s caregiver. It may also be the result of putting a child at risk of being injured (Department of Communities 2012b).\nSexual abuse - when a child is exposed to, or involved in, sexual activity that is inappropriate to the child’s age and developmental level (Department of Communities 2012c).\nEmotional abuse - when an adult harms a child’s development by repeatedly treating and speaking to a child in ways that damage the child’s ability to feel and express their feelings (Department of Communities 2012d).\n\nIn the child protection system in Western Australia there are four broad stages:\n\nNotification - where an individual raises concern for a child’s welfare to the Department. These individuals can be anyone, however they tend to be police officers, healthcare workers, and teachers, in part because these groups of professionals are subject to mandatory reporting of sexual abuse (Children and Community Services Amendment (Reporting Sexual Abuse of Children) Act 2008).\nInvestigation - if a notification includes a concern of maltreatment, abandonment, death, or inadequate provision of care, then the department may choose to investigate.\nSubstantiation - after case worker from the Department investigates the report, interviewing relevant parties, they decide whether the concern is substantiated. The three outcomes here are “unsubstantiated”, “substantiated - significant harm (actual)” where actual harm to a child has been substantiated, or “substantiated likelihood of significant harm (has or will occur)” where no harm was substantiated but the investigator believes there is a great risk of harm to the child. This is the stage at which the types of maltreatment are identified.\nConclusion - depending on the evidence in the investigation, the conclusion can result in no action, the provision of support services to address issues of concern, or the removal of a child from their parents.\n\nThe latter two outcomes at the conclusion stage usually lead to a protection order being issued. These protection orders are either temporary (up to two years long) or permanent (until the age of 18). There are four kinds of protection order in the legal framework which governs child protection (WA 2004):\n\nSupervision - this temporary order leaves the child in the care of the parents, but the Department supervises the care of the child. This may include conditions that the parents must meet in order to satisfy the concerns of the Department.\nTime-limited - this temporary order assigns the Department parental responsibility of the child (which usually means removal from the parents).\nUntil 18 - a permanent version of the time-limited order, where the Department is assigned parental responsibility until the child turns 18 or is adopted, or the order is revoked.\nSpecial guardianship - a permanent order where up to two individuals are given parental responsibility for a child until the age of 18. Aboriginal and Torres Strait Islander children must be placed according to the ATSICPP for this order.\n\nThe overall framework of the child protection system is represented in Figure 1.\n\n\n\nFigure 1: An overview of the child protection system in Western Australia"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#trends-in-child-protection-data",
    "href": "post/2021-06-28-confirmation-report/index.html#trends-in-child-protection-data",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Trends in child protection data",
    "text": "Trends in child protection data\nIn a study of Aboriginal children born in Western Australia in 1990 and 1991 and followed up until their 18th birthday, Bilson et al. (2015) found an estimated 41.8% were reported to child protective services, compared to 11% of non-Aboriginal children. In fact, Aboriginal children were more likely to appear across all stages of the child protection system - they were 3.8 times more likely to be reported, 4.1 times more likely to be investigated, and 5.3 times more likely to have substantiated maltreatment. In the Northern Territory, Aboriginal and Torres Strait Islander children were similarly over-represented in rates of notification (4.6 times) and substantiation (3.7 times) (Guthridge et al. 2012).\nAnother trend in child protection data has been children entering out-of-home care at younger ages and remaining in care for longer periods. The proportion of children in Western Australia entering care for the first time under the age of one rose from 15.3% to 24.8% between 1996 and 2009 (Bilson et al. 2017). In New South Wales, a more recent study of all children who started school in 2009 or 2012 found by age 1, 5.4% had a notification and 0.5% had been placed in out-of-home care, increasing to 13.8% and 1.4% respectively by age 5. These percentages seem small but they still represent over 2,100 children in out-of-home care by the age of five. This trend of increasingly younger entry into out-of-home care is even stronger in South Australia. Segal et al. (2019) estimated the cumulative incidence rates for five different birth cohorts (the earliest of which was births between 1986-91 and the latest was 2010-17), showing an acceleration of the percentage of Aboriginal and Torres Strait Islander children in out-of-home care at younger ages. Spending longer time in out-of-home care is also naturally correlated with earlier entry into out-of-home care as the younger a child is when they enter the system, the more potential years they have to spend in it.\nAn interesting effect of policy change can be observed with the implementation of the Child and Community Services Act 2004 (WA 2004). There was a sharp rise in the number of notifications and investigations by the Department, however the rate of substantiation did not change (Bilson et al. 2017). This is illustrative of how a policy or operational change can have a great impact on the data being recorded but the reality of the situation is not changing. Figure 2 illustrates the changes in the data - note that the 2004 Act was not implemented until 2006, indicated by the change in shading of the bars representing notifications. A later amendment to the Act (Children and Community Services Amendment (Reporting Sexual Abuse of Children) Act 2008) also made it mandatory for certain professionals, e.g. police, teachers, to report concerns of sexual abuse, which also resulted in an increase in the number of notifications for sexual abuse.\n Source: Bilson et al. (2017)"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#factors-associated-with-child-protection-interaction",
    "href": "post/2021-06-28-confirmation-report/index.html#factors-associated-with-child-protection-interaction",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Factors associated with child protection interaction",
    "text": "Factors associated with child protection interaction\nThe rate of interactions and removals in the child protection system have been well documented. Several studies have examined which characteristics are related to increasing appearance in the data. Studies on this topic typically rely on administrative data linked with various sources of health information, using the data linkage to estimate the risk associated with particular characteristics. Data linkage can be a powerful way to access large amounts of data on a variety of different topics, however it has some drawbacks. One key issue is identifying Indigenous status. It has been documented that Indigenous people hesitate to identify in healthcare settings, such as hospitals, for fear of mistreatment and discrimination (Christensen et al. 2014). Methods have been developed to improve the quality of Indigenous identifiers, such as comparing the status across multiple different datasets including birth records and family relations. McNamara et al. (2020) demonstrated the use of Indigenous status across family members (i.e. child, parent, and grandparents) to derive a child’s Indigenous status was a more inclusive method than relying on Indigenous status of only the child across datasets. This relies on having multiple datasets available in a linkage, which means studies relying solely on the analysis of hospital records are very likely underestimating the number of Aboriginal and Torres Strait Islander people in the data.\nIn the research published on risk factors for entry into the child protection system, the following have consistently been identified to increase the risk of a child having substantiated maltreatment and entering out-of-home care:\n\nMaternal and paternal substance use (O’Donnell et al. 2010, 2015; Jenkins et al. 2018; Orr et al. 2019)\nPoor maternal or paternal mental health (O’Donnell et al. 2010, 2015; Jenkins et al. 2018)\nTeenage mother or father (Orr et al. 2019; O’Donnell et al. 2019)\nMaternal hospital admissions for assault (O’Donnell et al. 2010, 2015; Orr et al. 2019)\nExposure to family domestic violence (Jenkins et al. 2018; Orr et al. 2019)\nLiving in socioeconomically disadvantaged areas (O’Donnell et al. 2010; Orr et al. 2019; Segal et al. 2019)\n\nSeveral congenital conditions have been associated with increased risk of appearing in child protection data. O’Donnell et al. (2010) reported hazard ratios for intellectual disability and cerebral palsy and other birth defects of 1.86 and 1.48 respectively. O’Donnell et al. (2009) also found that Aboriginal mothers were twice as likely to have a child born with neonatal withdrawal syndrome and identified poor maternal mental health and smoking during pregnancy as risk factors for being born with neonatal withdrawal syndrome - the same risk factors for having a child appear in child protection data.\nThese parental characteristics and health issues are only part of the picture though. There are common causes that underlie poor child and maternal health and appearing in child protection data - poverty, intergenerational trauma, systemic racism, lack of support or access to support services, poor housing and homelessness (Hunter et al. 2020)."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#health-of-children",
    "href": "post/2021-06-28-confirmation-report/index.html#health-of-children",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Health of children",
    "text": "Health of children\nThe health conditions identified previously have been those associated with increased risk of appearing in child protection data, but what does the overall health of these children going into care look like? This is an important question since carers taking on children need to ensure appropriate healthcare is provided, which means healthcare services need to be available and accessible. This information can also be used to inform early-intervention services to promote good development and wellbeing while children are young - a strategy which has been documented to be more cost effective than treating ill-health and other negative outcomes later in life (Alperstein & Dyer 2012). Providing support early on is not just about preventing ill-health either, good health has influences on every aspect of a child’s life, including education and social activities (Australian Institute of Health and Welfare 2020b).\nGood health begins for a child during pregnancy and the first years of life. The health of the mother during pregnancy impacts birth outcomes, with behaviours like smoking and substance use (factors also associated with child protection involvement) contributing to poor outcomes like low birthweight, which is itself a risk factor for several health conditions in adulthood, such as diabetes (Australian Institute of Health and Welfare 2020b). It has also been found that mothers who experienced family domestic violence (again, another factor for child protection involvement) are twice as likely to give birth to a low birthweight baby (Brown et al. 2015). The provision and uptake of early-intervention support services can help reduce the likelihood of poor prospective health, however this will not change the health needs of Aboriginal and Torres Strait Islander children already in, and at risk of going into, out-of-home care.\nThe Australia’s Children report (Australian Institute of Health and Welfare 2020b) gives an overview of the general burden of disease among Aboriginal and Torres Strait Islander children. Asthma and mental health conditions are the leading causes of disease burden among Aboriginal and Torres Strait Islander children aged 0-14. For Aboriginal and Torres Strait Islander children under five, the leading chronic health conditions were infant and congenital conditions (such as complications of low birthweight and pre-term birth) while for children aged 5 to 14 the leading causes of health burden were conduct, anxiety, and depressive disorders, asthma, and dental caries. While mental health conditions are common amongst children generally, children in out-of-home care are at even greater risk of experiencing poor mental health (Jones 2017).\nOn a positive note however, Aboriginal and Torres Strait Islander children have high rates of immunisation at age two (Australian Institute of Health and Welfare 2020b). The Australia’s Children report acknowledges that data for children living in out-of-home care is limited, demonstrating that even the Australian Institute of Health and Welfare, a government organisation that has access to large and varied datasets, struggles to get information on the health of children in out-of-home care. This further highlights the need to make health information on children in out-of-home care available.\nFew studies have been published on the health of Aboriginal and Torres Strait Islander children in out-of-home care, and the ones that do use highly-localised samples from service providers, limiting their generalisability. In a study of children attending KARI Aboriginal Resources Inc. clinics in south-western Sydney, half of the children had incomplete immunisation schedules (Raman, Reynolds & Khan 2011). This is an important contrast to what is reported in the Australia’s Children report, suggesting Aboriginal and Torres Strait Islander children at risk of entry into out-of-home care may be a subgroup of the larger Indigenous child population, who experience differential rates of health and healthcare. A follow up study consistently found hearing, vision, dental issues in children across several years (prevalences ranging from 30% to 50%), and several developmental deficits in the areas of speech and language and fine motor skills (Raman et al. 2017). Of the health conditions reported in Australia’s Children, asthma, visual impairment, and behavioural problems were common in the children in out-of-home care. Shmerling et al. (2020) conducted a similar analysis of children seen by the Victorian Aboriginal Health service. The same set of respiratory, hearing, visual, and dental issues were found as those in Raman et al. (2017), with prevalences ranging from 30% to 50% in children aged 0 to 13. Mental health and behavioural difficulties as well as delays to speech development were similarly prevalent. As far as I have been able to determine, no similar studies are published on Aboriginal and Torres Strait Islander children in out-of-home care in Western Australia. It is important to capture this information as the geography and climate of Western Australia is very different to Victoria and New South Wales, with a far greater proportion of Aboriginal and Torres Strait Islander people living in remote and very remote locations (Australian Institute of Health and Welfare 2019a) - a characteristic associated with greater experience of poor health (Australian Institute of Health and Welfare 2020b; Department of Health Western Australia 2021)."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#potentially-preventable-hospitalisations",
    "href": "post/2021-06-28-confirmation-report/index.html#potentially-preventable-hospitalisations",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Potentially preventable hospitalisations",
    "text": "Potentially preventable hospitalisations\nOne source of administrative data that can provide a glimpse into the health of Aboriginal and Torres Strait Islander children in care is hospital and emergency department data. By linking these data with child protection data we can examine what health conditions children are presenting to hospital with (similar to O’Donnell et al. (2015)). While this methodology is powerful, it does not provide information on primary care visits, so we may be less likely to see health conditions that can be managed in a primary care setting. However, this presents an opportunity to consider the health service utilisation and availability by examining potentially preventable hospitalisations.\nPotentially preventable hospitalisations (PPHs) are “defined as hospital admissions that could have potentially been prevented through the provision of appropriate individualised preventative health interventions and early disease management” (Australian Institute of Health and Welfare 2019b). These hospitalisations can be used as a metric to understand how effective and accessible healthcare services are in a community. If there is a high rate of PPHs in a community it suggests that there is a lack of accessible healthcare services, or those services that are available are not sufficiently addressing the health needs of the community. It should be noted however that PPHs will occur more frequently in areas where there are higher rates of disease, so higher rates do not necessarily imply that the primary care system is less effective.\nPotentially preventable hospitalisations are generally categorised into three groups:\n\nVaccine-preventable conditions - further categorised into ‘Influenza and pneumonia’ and ‘Other vaccine-preventable’. The majority of these admissions tend to be influenza and pneumonia, and Hepatitis C accounts for the majority of admissions in the ‘other’ category (Australian Institute of Health and Welfare 2019b).\nAcute conditions - which are quick onset conditions that may not have needed hospitalisation if adequate and timely primary care was provided.\nChronic conditions - hospitalisation for these conditions may have been avoidable through management in the community or lifestyle changes.\n\nEven though there are many conditions that fall under these different categories it is important to note that hospitalisation for such conditions may not have actually been avoidable.\nOf the few studies published that examine rates of PPHs in Aboriginal and Torres Strait Islander children, they have all found consistently higher rates of admission compared to non-Indigenous children, ranging from:\n\n1.7 in children aged 1 to 4 and 11 in children aged 28 days to 1 year (Stamp, Duckett & Fisher 1998), based on an analysis of NSW/NT/QLD/SA/WA data using admissions per 1,000 population\n4 in children aged 0 to 14 (Li et al. 2009), based on an analysis of admissions per 100,000 population in the NT between 1998 and 2006\n1.7 in children aged 0 to 13, based on an analysis of PPHs per 1,000 person-years observed from 2000 to 2012 in NSW (Falster et al. 2016)\n\nThese findings are consistent with the Australian Institute of Health and Welfare (2019b), which reports Indigenous Australians experience PPHs at a rate three times greater than non-Indigenous Australians - a finding that is consistent irrespective of remoteness area (however the rate does increase with increasing remoteness).\nIn a study of Aboriginal and Torres Strait Islander children from the Australian Capital Territory aged 0 to 5, nearly a quarter of PPHs were due to respiratory disease, with injury and infectious disease also in the top 5 (Guthrie 2012). The health categories being found for PPHs is also consistent with nationally published data which finds chronic obstructive pulmonary disorder is the leading cause of PPHs for Aboriginal and Torres Strait Islander peoples and is experienced at a rate 5.4 times greater than that for non-Indigenous people (Australian Institute of Health and Welfare 2020c). The other common conditions causing PPHs reported were diabetes complications, rheumatic heart disease, and in children, ear, nose, and throat infections. These data are predominantly for Aboriginal and Torres Strait Islander people of all ages, using age-standardised rates. Very few studies focus specifically on, or report separately, PPHs in Aboriginal and Torres Strait Islander children. One of the few studies which does, a study in New South Wales, Aboriginal and Torres Strait Islander children were admitted more frequently for every condition, with respiratory and infectious disease conditions among the most common (Falster et al. 2016)."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#conclusion",
    "href": "post/2021-06-28-confirmation-report/index.html#conclusion",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Conclusion",
    "text": "Conclusion\nTo summarise, Aboriginal and Torres Strait Islander children experience similar types of health conditions in their disease burden, but the rate at which it is experienced is disproportionately higher than non-Indigenous children. These children are also over-represented in out-of-home care and the child protection system more generally. There are a variety of factors causing this over-representation, such as poverty, systemic racism, and intergenerational trauma, which ultimately is the result of colonisation and the continuing lack of support for Aboriginal and Torres Strait Islander communities. Research has examined the health of Aboriginal and Torres Strait Islander children generally, but there is little published on the general health of children who enter out-of-home care. Additionally, a more up-to-date analysis is needed for Western Australian child protection data to examine the recent trends in greater detail."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#research-aims",
    "href": "post/2021-06-28-confirmation-report/index.html#research-aims",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Research aims",
    "text": "Research aims\nAs mentioned previously, my thesis has three broad research questions:\n\nWhat are the recent trends in child protection data for Aboriginal and Torres Strait Islander children in Western Australia and how does this vary across the state.\nHow do all the factors that increase the risk of poor child health and entry into out-of-home care relate to each other in a causal framework?\nWhat is the general health profile of Aboriginal and Torres Strait Islander children who go into out-of-home care and how does it compare to children who do not?"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#methods",
    "href": "post/2021-06-28-confirmation-report/index.html#methods",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Methods",
    "text": "Methods\nThe data that will be used to inform the analyses of my thesis comes from a data linkage performed by the Western Australian Data Linkage Branch. The cohort consists of approximately 33,000 Aboriginal and Torres Strait Islander children born in Western Australia and their siblings, parents, and grandparents. In terms of the data linkage methodology, the central linking unit (i.e. the individual to which the other family members are linked to) are Aboriginal and Torres Strait Islander children born in Western Australia between 2000 and 2013. Siblings of these children born outside of those years, as well as parents and grandparents, are included in the linkage. There is maternal information for all children, however paternal information is missing for some children. Grandparental information is missing in some cases too, such as where no father is recorded on a birth certificate, or the mother was born interstate so her birth record is not available to link. The full list of data sources in the data linkage, along with the range of years for each data source, are listed below:\n\nChild Protection and Family Support Data (1979-2019)\nMidwives Notification System (1980-2019)\nBirth registrations (1945-2019)\nHospital Morbidity Database Collection (1970-2019)\nEmergency Department Database Collection (2002-2019)\nWA Notifications of Notifiable Infectious Diseases (1964-2019)\nWA Register of Developmental Abnormalities - Birth defects (1980-2019)\nWA Register of Developmental Abnormalities - Cerebral Palsy (1980-2019)\nIntellectual Disability Exploring Answers\nDeath registrations (1969-2019)\nWA Infant, Child, Youth Mortality database\nMental Health Information System (1966-2019)\nMental Health National Outcomes and Casemix Collection\nDrug and Alcohol Office (1985-2005)\n\nDifferent statistical methods and datasets will used to address the research question for each chapter."
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#thesis-plan",
    "href": "post/2021-06-28-confirmation-report/index.html#thesis-plan",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Thesis plan",
    "text": "Thesis plan\n\nChapter 1 - Literature review\nThe aim of this chapter is to provide a background on Aboriginal and Torres Strait Islander child protection and child health in Australia.\nFor this chapter I conducted a non-systematic review of the literature pertaining to data linkage, child protection in Australia, and Aboriginal and Torres Strait Islander child health. The results of my searches include government reports and policy documentation, technical documentation, and research articles and reports. I have synthesised the information presented in these different sources into a narrative review which explores the history and trends in the child protection system, nationally and in Western Australia, as well as the health of Aboriginal and Torres Strait Islander children and families in relation to child protection.\nTasks for this chapter:\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nIdentify search topics\nApr 2020\nComplete\n\n\nPerform literature search\nMay 2020\nComplete\n\n\nRead literature\nDec 2020\nComplete\n\n\nDraft child protection review\nJan 2021\nComplete\n\n\nDraft child health review\nMar 2021\nNear completion\n\n\nFinalise literature review\nMay 2021\nIn progress\n\n\n\n\n\n\n\nChapter 2 - Methodology\nIn this chapter I will be explaining the data sources and describing the cohort and data linkage methodology. I will be including any pertinent information relating to the data, including issues of data quality and the operational and political history and context of the data. The cohort will be described on a variety of characteristics, including:\n\nNumber of children\nNumber of child years observed in the child protection data\nNumber of siblings (half- and full-), parents (mother and father) and number of grandparents (maternal and paternal)\nAverage and range of duration of follow-up\nAverage and range of number of interactions with the child protection system\nAverage and range of number of admissions in the hospital and emergency data\nRate of missing data and censoring\n\nI will also cover some statistical methodologies I have planned to use in subsequent chapters which involve data analysis and statistical modelling.\nTasks for this chapter:\n\n\n\n\n\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nDraft description of the data and data linkage\nJun 2021\nNot started\n\n\nDraft of proposed analysis methods\nJun 2021\nNot started\n\n\nCoding of the cohort\nJuly 2021\nIn progress\n\n\nDescriptives of the cohort\nJuly 2021\nNot started\n\n\nFinalise chapter\nAug 2021\nNot started\n\n\n\n\n\n\n\nChapter 3 - Descriptive analysis of trends in the child protection system\nAim: Quantify contemporary trends in WA child protection data, examining the rates in different areas of the child protection system such as the different stages (notification through to conclusion) or types of maltreatment.\nThis chapter will be a descriptive analysis, I will not be fitting any statistical models to the data. I will examine the trends in the four stages (notification, investigation, substantiation, placement in out-of-home care) and trends in the different maltreatment categories (neglect, physical abuse, emotional abuse, sexual abuse). The methods used for this chapter will mainly be data visualisation and tabulation. The results will be presented in terms of rates of interactions per 1,000 children, and broken down by key characteristics like age at interaction or child sex.\nI plan to submit this paper for publication by December 2021. The current authorship team includes my four supervisors (Sandra Eades, Alison Gibberd, Bridgette McNamara, Koen Simons) as well as Dan MacAulay (ECU) and Kathleen Falster (UNSW) from the study advisory group.\nTasks for this chapter:\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nOrganise authorship team\nJun 2021\nComplete\n\n\nDraft aims of paper\nJun 2021\nIn progress\n\n\nAnalyse the data\nOct 2021\nNot started\n\n\nWrite up the paper\nNov 2021\nIn progress\n\n\nSubmit the paper\nDec 2021\nNot started\n\n\n\n\n\n\n\nChapter 4 - Causal pathways to the child protection system\nAim: Use directed acyclic graphs (DAGs) to synthesise the literature on child protection and health into a framework which attempts to capture the complexity of the variables involved in both child protection and child health.\nThis chapter does not require the use of any data, the focus is to produce a theoretical framework which can guide my future analyses. I will be drawing heavily on the published research covered in the literature review to build a DAG. By building this framework I also hope to improve understanding of the complex inter-relatedness and causality of the different factors, going beyond simple associations.\nAs I have been reading the literature on Aboriginal and Torres Strait Islander health and child protection issues I have been building a mental map of how I think different variables are related to each other. My current thoughts are captured in Figure 3.\n\n\n\nFigure 3: A theoretical DAG for Indigenous child protection and health\n\n\nTasks for this chapter:\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nDraft aims of the chapter\nDec 2021\nNot started\n\n\nBuild causal framework\nJan 2022\nIn progress\n\n\nWrite up chapter\nFeb 2022\nNot started\n\n\nSeek feedback and make edits\nMar 2022\nNot started\n\n\n\n\n\n\n\nChapter 5 - Health profile of children going into care\nAim: Describe the general health of children prior to entering out-of-home care, examining common conditions and their trends in time and geography and variation by age.\nIn this chapter I plan to build a general health profile of the children who go into care in an effort to understand the health burden placed on carers.\nThe analysis will be descriptive, drawing on data visualisation and summaries to examine which conditions are appearing in the health data prior to entry into out-of-home care. This chapter will also explore the health service utilisation by comparing potentially preventable hospitalisations before and after being placed in care. One hypothesis is that parents whose children end up in out-of-home care may have poor access to primary healthcare and support services, so conditions which could have been treated or managed by primary care and other support services will be more likely to appear in the hospital and emergency admissions data. Once a child is placed into out-of-home care the carer may have better access to primary care services, so will be less likely to see potentially preventable hospitalisations for the child in the admissions data after placement into out-of-home care.\nTasks for this chapter:\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nOrganise authorship team\nApr 2022\nNot started\n\n\nDraft aims of the paper\nApr 2022\nNot started\n\n\nAnalyse data\nMay 2022\nNot started\n\n\nWrite up paper\nJul 2022\nNot started\n\n\nSubmit paper\nAug 2022\nNot started\n\n\n\n\n\n\n\nChapter 6 - Exposed vs. unexposed comparison of health outcomes\nAim: Compare the health outcomes and health service utilisation for children depending on their level of interaction with the child protection system.\nUsing a retrospective cohort design I will construct different cohorts to perform these comparisons. The exposed and unexposed groups will be children who are placed in out-of-home care and children who are never placed in out-of-home care, respectively. Depending on the further consultation with the study advisory group and the community and policy reference groups the analysis can be extended to compare children who ever appear in the child protection data (as opposed to only those who go into out-of-home care) with those who never do. Survival analysis methods may be used to estimate hazard ratios for the two cohorts.\nTasks for this chapter:\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nOrganise authorship team\nSep 2022\nNot started\n\n\nDraft aims of the paper\nSep 2022\nNot started\n\n\nAnalyse data\nOct 2022\nNot started\n\n\nWrite up paper\nDec 2022\nNot started\n\n\nSubmit paper\nJan 2023\nNot started"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#progress-to-date",
    "href": "post/2021-06-28-confirmation-report/index.html#progress-to-date",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Progress to date",
    "text": "Progress to date\nMy progress to date includes:\n\nFirst draft of literature review of child protection in Australia\nSignificant progress towards first draft of Aboriginal and Torres Strait Islander child health in Australia\nPresented thesis ideas to the study advisory group, policy reference group, and community reference group\nSet the aims and put the team together for the first major paper (Chapter 4)\nReceived the data and begun coding the cohort\nPlanning to attend the SNAICC2021 conference\nEnrolment in ‘Indigenous Health & History Insights’ to begin in Semester 2, 2021.\n\nPresentations during my probationary candidature:\n\nIntroduction to REDCap for research and systematic review data extraction\nPresentation of my proposed thesis to the International and Immigrant Health Group at the Peter Doherty Institute\nPresentation of my proposed thesis to the LifeCourse Data Linkage Interest Group\n\nConferences, workshops, seminars:\n\nResearch Integrity Online Training\nCochrane Review Online Training\nInternational Population Data Linkage Network Conference 2020\nMethods and Approaches for Optimising the Use of Linked Data in Indigenous Health Research (IPDLN2020 workshop)\nWA Data Linkage Branch Researcher Training Workshop (Western Australian Department of Health)\nHow to peer review a journal article (Dallas English)\nVersion control and collaboration with Git (Australasian Epidemiological Association)\nIntroduction to RMarkdown (Research Computing Services, Unimelb)\nData visualisation in R (Statistical Society of Australia)\nData wrangling in R (Statistical Society of Australia)\nSemiparametric regression in R (Statistical Society of Australia)"
  },
  {
    "objectID": "post/2021-06-28-confirmation-report/index.html#timeline",
    "href": "post/2021-06-28-confirmation-report/index.html#timeline",
    "title": "The Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System",
    "section": "Timeline",
    "text": "Timeline\n\n\n\n\n\n\n\n\n\n\nItem\nDue\nProgress\n\n\n\n\nConfirmation report\nMay 2021\nComplete\n\n\nConfirmation presentation\nMay 2021\nNear completion\n\n\nCh.1 - Literature review\nJun 2021\nNear completion\n\n\nCh.2 - Methodology\nJuly 2021\nNot started\n\n\nCh.3 - Descriptive analysis of trends in the child protection system\nDec 2021\nIn progress\n\n\nCh.4 - Causal pathways to the child protection system\nMay 2022\nIn progress\n\n\nCh.5 - Health profile of children going into care\nOct 2022\nNot started\n\n\nCh.6 - Case-control comparison of health outcomes\nFeb 2023\nNot started\n\n\nSubmission\nMay 2023\nNot started"
  },
  {
    "objectID": "post/2025-04-28-joke/index.html",
    "href": "post/2025-04-28-joke/index.html",
    "title": "How did Francis pay for his ticket to heaven?",
    "section": "",
    "text": "Via PaPal"
  },
  {
    "objectID": "post/2024-04-12-custom-rstudio-themes/index.html",
    "href": "post/2024-04-12-custom-rstudio-themes/index.html",
    "title": "Making a custom RStudio theme",
    "section": "",
    "text": "This is a re-post of my previous how-to on how to make custom RStudio themes. It unfortunately disappeared by accident as I migrated my site from Hugo/Blogdown to Quarto (it was my own doing). I’ve made a few themes for RStudio, which you can find here."
  },
  {
    "objectID": "post/2024-04-12-custom-rstudio-themes/index.html#step-1---copy-an-existing-.rstheme-file",
    "href": "post/2024-04-12-custom-rstudio-themes/index.html#step-1---copy-an-existing-.rstheme-file",
    "title": "Making a custom RStudio theme",
    "section": "Step 1 - copy an existing .rstheme file",
    "text": "Step 1 - copy an existing .rstheme file\nThere’s no point writing this all from scratch. We’re going to be good little scientists and Frankenstein our theme together.\nTo do this, find where RStudio is installed on your machine and navigate to the following directory /RStudio/resources/app/resources/themes. You’ll see all the default .rstheme files - copy one of these to a location that’s not in the RStudio folder (on Windows it doesn’t like you editing files in this folder). Alternatively you can just download one of the .rstheme from the repo I linked above and use that as your basis. The difference between my file and the default ones is I had a go at grouping the arguments into colours for not-text, colours for text, and other bits.\nOnce you’ve got a copy of an existing theme, open it in RStudio. Initially RStudio won’t know what the hell it is, so using the language drop-down in the corner of the source pane, update the language to CSS. This is useful because RStudio will preview what the colours in your file look like."
  },
  {
    "objectID": "post/2024-04-12-custom-rstudio-themes/index.html#step-2---start-testing-out-different-colours",
    "href": "post/2024-04-12-custom-rstudio-themes/index.html#step-2---start-testing-out-different-colours",
    "title": "Making a custom RStudio theme",
    "section": "Step 2 - start testing out different colours",
    "text": "Step 2 - start testing out different colours\nThis is where the fun begins. There’s lots of different aspects to RStudio that you can control. I was using the guidance from Posit’s website, but there was a lot of back and forth and testing and being confused. I’ve embedded the webpage here so you can scroll through the list of selectors to see what Posit say about them.\nIt wouldn’t be css if it wasn’t confusing though, so I’ll step through some of the different options. I’ll go through changing the colours of not-text first, then is-text second. Delineating these things makes sense to me, you’ll see it in noodle.rstheme where I define css for the editor theme twice, once for the background colour and once for the default text colour.\nBefore you press on you’ll also want to have either a colour scheme handy or some kind of colour picking tool so you can get the hex codes.\n\nBackground colour\n.ace_editor, .ace_editor_theme .profvis-flamegraph, .ace_editor_theme {\n  background-color: #F7DCF0\n}\nThis changes the background colour of RStudio’s panes, except for the terminal tab. It also doesn’t change the colour of the ‘gutter’, which is the part of the source pane where the line numbers appear.\n\n\nGutter colour\n.ace_gutter {\n  background: #F7DCF0\n}\nThis will change the background colour of the ‘gutter’. I made it the same colour as the main part of the source pane but you can do whatever you like.\n\n\nTerminal colour\n.terminal {\n  background-color: #F7DCF0;\n  color: #000000;\n}\nIn the default rstheme files there’s a bunch of other options in the terminal argument. Don’t know what they do, and I don’t really use terminal much either, I just wanted it all to be consistently coloured. background-color changes the background and color changes the cursor colour.\n\n\nCursor colour\n.ace_cursor {\n  color: #000000\n}\nThis changes the colour of the cursor (the little bar indicating where you’re typing).\n\n\nSelection colour\n.ace_marker-layer .ace_selection {\n  background: #82C28273\n}\nThis is one of my favourites. When you select code it’ll have this colour as the background. In the example it would highlight code in this colour!\n\n\nBracket highlights\n.ace_bracket {\n  margin: 0 !important;\n  border: 0 !important;\n  background-color: rgba(0, 184, 25, 0.5);\n}\nThis is my other favourite! When your code has brackets, putting the cursor one of a pair of brackets will highlight them both so you can see where the bracketed code starts and end. Super useful when you’re working with bracketception. Some of the default themes weren’t obvious enough for me so I made it pretty clear with this green. Note in this instance I used rgba rather than a colour hex code - the last input (0.5 in this case) defines the transparency. You can define transparency with hex codes too but this works fine.\n\n\nCode chunks\n.ace_marker-layer .ace_foreign_line {\n  position: absolute;\n  z-index: -1;\n  background-color: #f6d1ed;\n}\nThis one sets the colour of code chunks.\n\n\nDefault text\n.ace_editor, .ace_editor_theme .profvis-flamegraph, .ace_editor_theme {\n  color: #00006B\n}\nThis is the colour the majority of the text in your editor will be, basically any text that isn’t one of the special types defined later.\n\n\nGutter text\n.ace_gutter {\n  color: #333\n}\nRemember the gutter? Well this is how you define what colour the line numbers will be.\n\n\nKeywords\n.ace_keyword {\n  color: #9D00FF !important;\n}\nSpecial words like if and function will be this colour\n\n\nMetadata\n.ace_meta,\n.ace_support.ace_constant.ace_property-value {\n  color: #6585ae\n}\nText in document headers will be this colour, like titles, YAML and the like.\n\n\nTRUE/FALSE and italics\n.ace_constant.ace_language {\n  color: #D29380\n}\nThis sets the colour of the words TRUE and FALSE, plus any italicised text in markdown docs. You can specify a more general argument than this by just using .ace_constant on its own, but I like to be able to easily tell the difference between bolded and italicised text when I’m writing RMarkdown documents.\n\n\nNumeric constants and bold text\n.ace_constant.ace_numeric {\n  color: #FF8080\n}\nThis sets the colour of numeric constants, for example the 8 in mutate(x = 8) would be this colour. It’s also the color that bolded text in markdown documents will be.\n\n\nStrings\n.ace_string {\n  color: #009E18\n}\nThis sets the colour of strings.\n\n\nComments\n.ace_comment {\n  color: #5E5E5E\n}\nThis sets the colour of comments (you better be writing comments!).\n\n\nRainbow indent lines\n.rstudio_rainbow_indent_guides .ace_line .ace_indent-guide:nth-child(2n+1){\n    background: linear-gradient(to left, #f38989 1px, transparent 1px, transparent);\n}\n\n.rstudio_rainbow_indent_guides .ace_line .ace_indent-guide:nth-child(2n+2){\n    background: linear-gradient(to left, #78c1a3 1px, transparent 1px, transparent);\n}\nIf you don’t know what indents are, you can find them by going through the menus Tools -&gt; Global Options -&gt; Code -&gt; Display -&gt; Indentation guidelines. You can have a bit of fun changing these. The two things you need to pay attention to are the colours (obviously) and the nth-child(2n+1) statements. I’m making an assumption here, but I think the number before n indicates how many colours there are in your set of rainbow indent colours, and the number following the + indicate the ordering of the colours. So in the above example, #f38989 comes first and #78c1a3 comes second and repeats for however many indents you have.\n\n\nRainbow indent fills\n.rstudio_rainbow_indent_fills .ace_line .ace_indent-guide:nth-child(2n+1){\n    background: linear-gradient(to left, #f3898977 1px, #f3898977 1px, #f3898977);\n}\n\n.rstudio_rainbow_indent_fills .ace_line .ace_indent-guide:nth-child(2n+2){\n    background: linear-gradient(to left, #78c1a377 1px, #78c1a377 1px, #78c1a377);\n}\nThese are similar to the indent lines, except it fills the indents in blocks (vertically). The main difference here is the addition of two numbers at the end of the hex code, controlling the transparency. I’d suggest keeping the transparency, it looks weird with block colours!\n\n\nGrey line indents\nThis the final thing I’ll mention, and I think the most interesting!\n.ace_indent-guide {\n  background: url(\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAANSURBVBhXY9jYWl4GAAW8AiRaxbuHAAAAAElFTkSuQmCC\") right repeat-y\n}\nIt turns out that the grey line indents are actually tiny base64 images, so if you want to modify the colour to make them more visible you’ll need to create a new 1-pixel image. When I was creating my theme, the default colour of the theme I’d Frankensteined was too light to clearly see, so I ended up making a darker pixel for better contrast. I just made a 1-pixel image in paint and uploaded it to https://www.base64-image.de/ to get the base64 code used here."
  },
  {
    "objectID": "post/2024-04-12-custom-rstudio-themes/index.html#step-3---add-your-theme-to-rstudio",
    "href": "post/2024-04-12-custom-rstudio-themes/index.html#step-3---add-your-theme-to-rstudio",
    "title": "Making a custom RStudio theme",
    "section": "Step 3 - add your theme to RStudio",
    "text": "Step 3 - add your theme to RStudio\nThere’s heaps more settings you can change, but hopefully the ones above are enough to get you going. Before you add your theme to RStudio there’s one final thing you’ll need to change! At the top of the file you’ll see two lines of code:\n/* rs-theme-name: Noodle */\n/* rs-theme-is-dark: FALSE */\nThe first one is where you give it a name and the second is where you specify if you want RStudio’s broader theme to be light (FALSE) or dark (TRUE). Once you’ve changed this last bit, save the file. In order to add your theme to RStudio, navigate to the themes menu (Tools -&gt; Global Options -&gt; Appearance) and click the Add button. Navigate to wherever you’ve been keeping your .rstheme file and select it. It’ll appear in the list of themes, so just select it and click apply. Hey presto!"
  },
  {
    "objectID": "post/2024-04-12-custom-rstudio-themes/index.html#step-4---tinkering",
    "href": "post/2024-04-12-custom-rstudio-themes/index.html#step-4---tinkering",
    "title": "Making a custom RStudio theme",
    "section": "Step 4 - tinkering",
    "text": "Step 4 - tinkering\nIf you’re anything like me you’ll spend several hours tinkering with colours to see what the options do and what your colour palette looks like together. Since you can’t edit the theme file while it’s loaded into RStudio, make the edits to the .rstheme file you created that wasn’t in the RStudio folder. When you’re ready to test your updates, head back to the Appearance menu, change the theme to something else, remove your theme by highlighting it and clicking the Remove button, then add it again.\nThere’s probably a smarter way of doing it but it worked for me. I hope you’ve found this useful! If I’ve made a mistake or misunderstood something in this blog post, be a good scientist and (kindly) let me know."
  },
  {
    "objectID": "post/2021-11-24-joke/index.html",
    "href": "post/2021-11-24-joke/index.html",
    "title": "Why are cows bad at the tightrope?",
    "section": "",
    "text": "Because they lactose"
  },
  {
    "objectID": "post/2021-04-24-basil-pesto/index.html",
    "href": "post/2021-04-24-basil-pesto/index.html",
    "title": "Basil Pesto",
    "section": "",
    "text": "This basil pesto recipe is the result of me making pesto innumerable times and tweaking it each time until I got it just right. My goal was to make a pesto that tastes just like the one you can buy from the Queen Victoria Markets in Melbourne. I think I got pretty close, but you be the judge!"
  },
  {
    "objectID": "post/2021-04-24-basil-pesto/index.html#ingredients",
    "href": "post/2021-04-24-basil-pesto/index.html#ingredients",
    "title": "Basil Pesto",
    "section": "Ingredients",
    "text": "Ingredients\n\n\n3 bunches of basil\n150ml extra-virgin olive oil\n60g parmesan\n60g pine nuts\n2 cloves of garlic\n3 tablespoons of lemon juice\n2 pinches of sea salt flakes\n10 turns of a pepper mill\n\nYou will also need a food processor to combine the ingredients together, unless you fancy doing it all by hand."
  },
  {
    "objectID": "post/2021-04-24-basil-pesto/index.html#instructions",
    "href": "post/2021-04-24-basil-pesto/index.html#instructions",
    "title": "Basil Pesto",
    "section": "Instructions",
    "text": "Instructions\nBegin by attaching both the blade and fine-grating attachment to the food processor.\n\nGrate the parmesan using the processor.\n\nRemove the grating attachment and add all of the remaining ingredients. When you add the basil the food processor should be at least two-thirds full - three bunches usually works for me, but if you have a stingy supplier of basil you might need a fourth.\n\nProcess until smooth. You might need to scrape down the sides of the food processor a couple of times, I find the basil leaves like to stick to the side.\n\nThat’s it! Your pesto is now ready. If you end up making this let me know what you think on Bluesky.\nYou can store it in a jar in the fridge but I find it doesn’t keep longer than a week, even with putting an oil seal on the top. What I do, and I’m very sorry if this upsets any nonnas, is divide the pesto into a large ice-cube tray and freeze it. When you need some pesto just microwave a cube in a bowl for 30 seconds or so to defrost."
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact",
    "section": "",
    "text": "Want to say hi? Send me a message!\nYou can always contact me on social media too:\n Bluesky\n LinkedIn\n GitHub\n Buy me a coffee\n\n\n\n\n\n\nYour name \nEmail address \nMessage\n\n\nSend message"
  },
  {
    "objectID": "post/2025-07-28-joke/index.html",
    "href": "post/2025-07-28-joke/index.html",
    "title": "Why don’t statisticians like getting feedback?",
    "section": "",
    "text": "Because they’re always \\(E[\\bar{X}]\\)"
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html",
    "title": "Not all missings are created equal",
    "section": "",
    "text": "I posted this question on Bluesky the other day, because I wasn’t sure whether a row-wise or column-wise solution would perform better for the problem I was trying to solve.\nThe feedback was consistent in stating that column-wise operations would be faster. So what did I do? I wrote a row-wise solution!\nOk hear me out though, there was a good reason and I’ll go through the problem and my thinking here, because the problem isn’t as simple as I’d laid out in my Bluesky post."
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html#the-problem",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html#the-problem",
    "title": "Not all missings are created equal",
    "section": "The problem",
    "text": "The problem\nPeople do questionnaires (this is not the problem). Some people skip a question or two, some people skip a whole set, and some people get bored and stop half-way. These all lead to missing data, but the pattern of missingness is different and is informative when thinking about designing the next survey wave’s questionnaire.\nThe problem is how to efficiently identify these types of missingness in the data and code them as such.\nLet’s start with a data dictionary some example data to help illustrate."
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html#the-data",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html#the-data",
    "title": "Not all missings are created equal",
    "section": "The data",
    "text": "The data\n\nlibrary(tidyverse)\nlibrary(gt)\nset.seed(4)\n\nsurvey_data &lt;- tibble(\n  id = c(1, 2, 3, 4, 5),\n  name_first = c(\"Tom\", \"Penny\", \"Trevor\", \"Ursula\", \"Jenny\"),\n  name_last = c(\"Smith\", \"Jones\", NA, \"Smith\", \"Jones\"),\n  age = c(62,52,37,44,NA),\n  x1 = runif(5, 0, 2),\n  x2 = runif(5, 0, 2),\n  x3 = runif(5, 0, 2),\n  x_text = c(\"Lorem\", NA, NA, \"Lorem\", NA),\n  y1 = runif(5, 0, 2),\n  y2 = runif(5, 0, 2),\n  y3 = runif(5, 0, 2),\n  z1 = runif(5, 0, 2),\n  z2 = runif(5, 0, 2),\n  z3 = runif(5, 0, 2)\n) |&gt;\n  mutate(\n    across(matches(\"\\\\d\"), \\(x) if_else(x &gt; 1, NA, round(x))),\n    across(everything(), as.character)\n    )\n\ngt(survey_data)\n\n\n\n\n\n\n\nid\nname_first\nname_last\nage\nx1\nx2\nx3\nx_text\ny1\ny2\ny3\nz1\nz2\nz3\n\n\n\n\n1\nTom\nSmith\n62\nNA\n1\nNA\nLorem\n1\nNA\nNA\nNA\nNA\nNA\n\n\n2\nPenny\nJones\n52\n0\nNA\n1\nNA\nNA\nNA\n1\n0\n1\n0\n\n\n3\nTrevor\nNA\n37\n1\nNA\n0\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n4\nUrsula\nSmith\n44\n1\nNA\nNA\nLorem\nNA\n1\nNA\nNA\n1\n0\n\n\n5\nJenny\nJones\nNA\nNA\n0\n1\nNA\nNA\nNA\nNA\n1\n0\nNA\n\n\n\n\n\n\n\nIn this example, we’ve got the data in a tabular format with responses as rows and variables as columns. There’s an ID, the respondent’s names and age, then three sets of questions:\n\nThe x1 to x_text questions are all part of the x group of questions\nThe y1 to y3 and z1 to z3 questions are all part of the y and z group of questions, respectively\n\nLooking at this data, we can see that:\n\nTom didn’t answer any of the z questions\nPenny and Ursula have valid responses for at least one question from each group\nTrevor didn’t give his last name and stopped responding after the x questions\nJenny didn’t respond to the y questions but answered at least one z question"
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html#a-dictionary",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html#a-dictionary",
    "title": "Not all missings are created equal",
    "section": "A dictionary",
    "text": "A dictionary\nLike any good dataset, a data dictionary is available:\n\ndictionary &lt;- tibble(\n  variable = names(survey_data),\n  type = c(\"numeric\",rep(\"string\",2),\"numeric\",rep(\"factor\",3),\"string\",rep(\"factor\",6)),\n  variable_group = c(\"id\", \"name\", \"name\", \"age\", rep(\"x\", 4), rep(\"y\", 3), rep(\"z\", 3))\n)\n\ngt(dictionary)\n\n\n\n\n\n\n\nvariable\ntype\nvariable_group\n\n\n\n\nid\nnumeric\nid\n\n\nname_first\nstring\nname\n\n\nname_last\nstring\nname\n\n\nage\nnumeric\nage\n\n\nx1\nfactor\nx\n\n\nx2\nfactor\nx\n\n\nx3\nfactor\nx\n\n\nx_text\nstring\nx\n\n\ny1\nfactor\ny\n\n\ny2\nfactor\ny\n\n\ny3\nfactor\ny\n\n\nz1\nfactor\nz\n\n\nz2\nfactor\nz\n\n\nz3\nfactor\nz\n\n\n\n\n\n\n\nIt’s rudimentary but will serve its purpose to illustrate how we can use it in data cleaning and the reason for why I opted for a row-wise solution."
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html#my-solution",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html#my-solution",
    "title": "Not all missings are created equal",
    "section": "My solution",
    "text": "My solution\nThe column-wise solution for identifying the drop-offs is fairly straightforward, but I wasn’t sure how to incorporate missingness at the question group level where the participant had not dropped off (e.g. Jenny). Maybe I’m too tidyverse-pilled, but I found it much easier to solve this problem using group_by().\nTo start with, we need to transpose the data such that participant responses are in columns and the variables are in rows.\n\nsurvey_data_tranposed &lt;- survey_data |&gt;\n  select(any_of(dictionary$variable)) |&gt; \n1  t() |&gt;\n2  as.data.frame() |&gt;\n3  rownames_to_column(var = \"variable\")\n\ngt(survey_data_tranposed)\n\n\n1\n\nt() transposes the data into a matrix\n\n2\n\nConvert it back into a data frame\n\n3\n\nThen take the row names (which were previously column names) and turn them into the variable column.\n\n\n\n\n\n\n\n\n\n\nvariable\nV1\nV2\nV3\nV4\nV5\n\n\n\n\nid\n1\n2\n3\n4\n5\n\n\nname_first\nTom\nPenny\nTrevor\nUrsula\nJenny\n\n\nname_last\nSmith\nJones\nNA\nSmith\nJones\n\n\nage\n62\n52\n37\n44\nNA\n\n\nx1\nNA\n0\n1\n1\nNA\n\n\nx2\n1\nNA\nNA\nNA\n0\n\n\nx3\nNA\n1\n0\nNA\n1\n\n\nx_text\nLorem\nNA\nNA\nLorem\nNA\n\n\ny1\n1\nNA\nNA\nNA\nNA\n\n\ny2\nNA\nNA\nNA\n1\nNA\n\n\ny3\nNA\n1\nNA\nNA\nNA\n\n\nz1\nNA\n0\nNA\nNA\n1\n\n\nz2\nNA\n1\nNA\n1\n0\n\n\nz3\nNA\n0\nNA\n0\nNA\n\n\n\n\n\n\n\nNow that the data’s in this format, we can join information from the dictionary\n\nsurvey_data_tranposed &lt;- survey_data_tranposed |&gt;\n  left_join(dictionary, by = \"variable\") |&gt;\n  relocate(c(variable_group,type), .after = variable)\n\ngt(survey_data_tranposed)\n\n\n\n\n\n\n\nvariable\nvariable_group\ntype\nV1\nV2\nV3\nV4\nV5\n\n\n\n\nid\nid\nnumeric\n1\n2\n3\n4\n5\n\n\nname_first\nname\nstring\nTom\nPenny\nTrevor\nUrsula\nJenny\n\n\nname_last\nname\nstring\nSmith\nJones\nNA\nSmith\nJones\n\n\nage\nage\nnumeric\n62\n52\n37\n44\nNA\n\n\nx1\nx\nfactor\nNA\n0\n1\n1\nNA\n\n\nx2\nx\nfactor\n1\nNA\nNA\nNA\n0\n\n\nx3\nx\nfactor\nNA\n1\n0\nNA\n1\n\n\nx_text\nx\nstring\nLorem\nNA\nNA\nLorem\nNA\n\n\ny1\ny\nfactor\n1\nNA\nNA\nNA\nNA\n\n\ny2\ny\nfactor\nNA\nNA\nNA\n1\nNA\n\n\ny3\ny\nfactor\nNA\n1\nNA\nNA\nNA\n\n\nz1\nz\nfactor\nNA\n0\nNA\nNA\n1\n\n\nz2\nz\nfactor\nNA\n1\nNA\n1\n0\n\n\nz3\nz\nfactor\nNA\n0\nNA\n0\nNA\n\n\n\n\n\n\n\nThen I wrote the following function, which incorporates the information we just joined in how missingness categories are identified. The code annotations below the code chunk explain each step.\n\ncode_missingness &lt;- function(data, column) {\n  output &lt;- data |&gt;\n1    mutate(drop_off = row_number() &gt; max(which(!is.na(!!sym(column))))) |&gt;\n    group_by(variable_group) |&gt;\n    mutate(\n2      drop_off = min(drop_off),\n3      n_vars = max(row_number()),\n      n_missing = sum(is.na(!!sym(column))),\n4      missingness = case_when(\n5        drop_off == TRUE ~ \"-777777\",\n6        n_vars &gt; 1 & n_missing == n_vars ~ \"-888888\",\n7        n_missing != n_vars &\n          is.na(!!sym(column)) &\n          type == \"factor\" ~ \"0\",\n8        is.na(!!sym(column)) ~ \"-999999\",\n9        .default = !!sym(column)\n      )\n    ) |&gt; \n    ungroup() |&gt; \n    select(missingness) |&gt; \n10    rename(!!sym(column) := missingness) |&gt;\n    as.vector()\n  \n  return(output)\n}\n\n\n1\n\nFor each row in the column, !is.na() returns TRUE (1) is non-missing or FALSE (0) if missing. which() then returns a vector of indices where the non-missing values are. max() then identifies the last row where non-missing data exists. Up to and including this row, drop_off is FALSE, becoming TRUE for every row thereafter.\n\n2\n\nWe then need to update drop_off if there are any non-missing responses within the question group. I’ll explain why later, but the group minimum of drop_off will set all rows to FALSE if any FALSE exists.\n\n3\n\nThen the number of variables within a group n_vars and number of missing responses within a group n_missing are calculated\n\n4\n\nWith these elements now created, we can use case_when() to apply the missing coding\n\n5\n\nDue to step 2, we can be confident that drop_off == TRUE correctly identifies where responses have dropped off\n\n6\n\nThe value -888888 identifies missingness at the question group level. If the number of missing responses within the question group is equal to the number of questions within said group, that is missing at the question group-level. n_vars &gt; 1 is included since I consider groups to mean a collection of 2 or more questions.\n\n7\n\nIn this condition, any missing values is.na(!!sym(column)) for a factor question type == \"factor\" where there are non-missing values within the question group n_missing != n_vars are coded to 0\n\n8\n\nAny remaining missing values can be coded as plain old -999999\n\n9\n\nAny rows that didn’t meet any of these rules are left as-is\n\n10\n\nFinally, rename the missingness column to whatever the current value of the column input is, since we’re going to iterate over every column\n\n\n\n\nNow that this function is defined, we can apply it to the relevant columns of the data, which are currently named V1 through V5:\n\nresponses &lt;- names(survey_data_tranposed |&gt; select(matches(\"V\\\\d\")))\n\n# Use purrr:map to iterate over the columns identified in `responses`\nsurvey_data_coded &lt;- map(responses, \\(x) code_missingness(survey_data_tranposed, x)) |&gt;\n  bind_cols()\n\nsurvey_data_tranposed |&gt;\n  bind_cols(survey_data_coded |&gt;\n              rename_with( ~ paste0(., \"_new\"), matches(\"V\\\\d\"))) |&gt; \n  select(variable, variable_group, type, starts_with(c(\"V1\",\"V2\",\"V3\",\"V4\",\"V5\"))) |&gt; \n  gt()\n\n\n\n\n\n\n\nvariable\nvariable_group\ntype\nV1\nV1_new\nV2\nV2_new\nV3\nV3_new\nV4\nV4_new\nV5\nV5_new\n\n\n\n\nid\nid\nnumeric\n1\n1\n2\n2\n3\n3\n4\n4\n5\n5\n\n\nname_first\nname\nstring\nTom\nTom\nPenny\nPenny\nTrevor\nTrevor\nUrsula\nUrsula\nJenny\nJenny\n\n\nname_last\nname\nstring\nSmith\nSmith\nJones\nJones\nNA\n-999999\nSmith\nSmith\nJones\nJones\n\n\nage\nage\nnumeric\n62\n62\n52\n52\n37\n37\n44\n44\nNA\n-999999\n\n\nx1\nx\nfactor\nNA\n0\n0\n0\n1\n1\n1\n1\nNA\n0\n\n\nx2\nx\nfactor\n1\n1\nNA\n0\nNA\n0\nNA\n0\n0\n0\n\n\nx3\nx\nfactor\nNA\n0\n1\n1\n0\n0\nNA\n0\n1\n1\n\n\nx_text\nx\nstring\nLorem\nLorem\nNA\n-999999\nNA\n-999999\nLorem\nLorem\nNA\n-999999\n\n\ny1\ny\nfactor\n1\n1\nNA\n0\nNA\n-777777\nNA\n0\nNA\n-888888\n\n\ny2\ny\nfactor\nNA\n0\nNA\n0\nNA\n-777777\n1\n1\nNA\n-888888\n\n\ny3\ny\nfactor\nNA\n0\n1\n1\nNA\n-777777\nNA\n0\nNA\n-888888\n\n\nz1\nz\nfactor\nNA\n-777777\n0\n0\nNA\n-777777\nNA\n0\n1\n1\n\n\nz2\nz\nfactor\nNA\n-777777\n1\n1\nNA\n-777777\n1\n1\n0\n0\n\n\nz3\nz\nfactor\nNA\n-777777\n0\n0\nNA\n-777777\n0\n0\nNA\n0\n\n\n\n\n\n\n\nIt looks to have done the job I intended it to do:\n\nTrevor has -999999 for last name and the x text variable, and -777777 from questions y onward\nJenny has group-level missingness -888888 for the y questions, because she goes on to answer the z questions so has not dropped off\nMissing responses to factor questions in a group are coded to 0 when a non-missing response exists on any other question"
  },
  {
    "objectID": "post/2025-07-14-to-col-or-not-to-col/index.html#some-explanations",
    "href": "post/2025-07-14-to-col-or-not-to-col/index.html#some-explanations",
    "title": "Not all missings are created equal",
    "section": "Some explanations",
    "text": "Some explanations\nThe reason why I update the value of drop_off after grouping (annotation 2) is because of the underlying structure of the data I’m working with, which isn’t quite reflected in the example data. When outputting checkboxes, REDCap (a survey platform) auto-populates unchecked boxes with a 0 as opposed to missing. To work around this in the context of missingness, I first replace every 0 for these checkbox variables with NA so that I’m left with only values of 1 or NA. You might be thinking “someone could reasonably have answered the question by not ticking any boxes”, except that we provide ‘no’ and ‘unsure’ checkboxes to reasonably cover all response options. So if these options are 0 in addition to the other options, I feel more confident in saying the whole question group was skipped.\nThe original reason for asking the question was about performance, and this approach is probably slower than a column-wise solution. It takes around 10 minutes to iterate over ~6,500 responses to ~550 variables across ~100 question groups. In the future this isn’t going to be an issue because the data cleaning is going to be run on a frequent basis as data comes in (so smaller batches), rather than the entire set of responses."
  },
  {
    "objectID": "post/2025-03-29-significance-magazine/index.html",
    "href": "post/2025-03-29-significance-magazine/index.html",
    "title": "A big ask: doing literally anything apparently",
    "section": "",
    "text": "This blog post is about Significance magazine and the transphobic dumpster fire of an article they published in 2023. Over the last couple of years I’ve gone back and forth on whether I should make a blog post about this. Each time, up until now, I figured if I did just a little more advocacy behind the scenes or gave the leadership at Significance magazine and the ASA or RSS a little more time, maybe they would actually do something.\nAlas, this wasn’t to be.\nAnd that’s not for lack of trying either. Before getting into whatever this blog post is (a rant maybe?), I do want to acknowledge there have been multiple people across the American Statistical Association (ASA), Royal Statistical Society (RSS), and Statistical Society of Australia (SSA), with varying degrees of authority and seniority, who have also taken issue with the article and spent time advocating for some kind of action. I say this to highlight that the fact the article remains published, and is thus endorsed as an article of quality and merit by Significance magazine, does not necessarily reflect the perspectives of the membership bases of the aforementioned professional bodies or the editorial board of Significance magazine."
  },
  {
    "objectID": "post/2025-03-29-significance-magazine/index.html#where-to-begin",
    "href": "post/2025-03-29-significance-magazine/index.html#where-to-begin",
    "title": "A big ask: doing literally anything apparently",
    "section": "Where to begin?",
    "text": "Where to begin?\nAt the start I guess, which was the first time I read the article. My initial reaction was one of disbelief. How did this article manage to get published in the first place? Putting aside the fact that it was clearly a political piece with a transphobic agenda (and this is my main issue), the article is so poorly written that it reads like some of my first-year undergraduate essays, and boy were some of those cringe.\nYou might be tempted to pick through the article and compile a list of all the issues it has - but I’ll save you the effort. I did that already and sent this complaint to the editor of Significance magazine. The length of the complaint was actually longer than the article itself, which maybe tells you something about how poor the article is. To summarise my issues with the article, it:\n\nAdvocates for genuinely terrible data collection practices\nFalsely claims that governments are not collecting data on sex\nSuggests there’s a queer illuminati trying to ‘erase sex categories’\nProvides citations which, in the majority of cases, directly contradict the claims they are cited against\nIs riddled with logical fallacies like straw-man arguments and appeals to tradition\nDisingenuously defines sex, gender, and gender identity in relation to binaries\nUses dehumanising language, like describing intersex people as ‘anomalous’\n\nI could go on, but if you want to know more you may as well read the complaint. After sending in the complaint I received… silence. I emailed again two weeks later to again receive silence. Finally after following up a third time, more than a month since the initial submission, I received a response from the editor basically saying “yes I got your email”. Nothing else, so again I had to follow up to see what was being done and finally received this disappointing reply:\n\nThere won’t be any action taken. The article went through the same process as every Significance article (besides interviews, book reviews etc), including a review by members of our editorial board. I’m satisfied that, as a magazine, our coverage of this issue has been balanced.\n\nLmao what? Coverage of ‘this issue’? Are you also actively seeking out anti-vaccine opinions too for the sake of balance?\nAnyway, this reply made me cringe with even more second-hand embarrassment - not only did the original author submit the article with all of its issues but someone on the editorial board apparently read it and went “oh wow this article is fantastic and has no problems at all we should publish it immediately”.\nI kept advocating for something to be done about the article, but nothing eventuated despite what seemed to be considerable discussion on the magazine’s editorial board, on each society’s DEI committees, between the Presidents of the respective societies. Again, I am grateful that many people pursued this issue on my, and many others, behalf, but I am ultimately still disappointed."
  },
  {
    "objectID": "post/2025-03-29-significance-magazine/index.html#why-does-this-matter",
    "href": "post/2025-03-29-significance-magazine/index.html#why-does-this-matter",
    "title": "A big ask: doing literally anything apparently",
    "section": "Why does this matter?",
    "text": "Why does this matter?\nWell for starters, publishing articles like this poses a serious risk to the eye health of trans and gender diverse statisticians from all the eye-rolling it induces. For real though, I’d been thinking of writing a piece for Significance magazine’s competition for early career statisticians, but given this entire debacle I don’t see the magazine as a safe or welcoming place for me or my work. Honestly, if it wasn’t for the support I received from my colleagues at the SSA, I wouldn’t even be sure that the SSA was a safe or welcoming place for me. But not every trans or gender diverse statistician has that relationship with one of the professional bodies, so what are they to make of Significance magazine and the professional societies that govern it?\nAnd this gets to a broader issue I have with organisations being very happy to say they are welcoming and inclusive. It’s easy to say you are a welcoming and inclusive organisation, it’s easy write it into your strategic plan, and it’s easy to do work that makes you feel good, like celebrating the International Day of Women in Statistics and Data Science. But when it comes to doing something hard or uncomfortable, like retracting a transphobic article which goes directly against your principles of inclusivity, all of a sudden there’s nothing to be done. It’s just so disappointing and yet so unsurprising.\nMy other issue is that Significance magazine is considered to be a reputable publication and this quality is conferred to the articles within it. At a surface level the article itself looks reputable too, having the trappings of an academic article. This appearance of legitimacy then leads to the cycle of academic bullshittery:\n\nArticle is published, giving it a degree of legitimacy\nPeople cite the article in their own publications, taking the arguments at face value, giving it further legitimacy\nPeople read this other work, take the citation of the original article at face value and cite it in their own work.\nRinse and repeat, until you have Dan Ariely\n\nUnfortunately and unsurprisingly, my concerns about this cycle have come true and publications in actual academic journals are citing this article. What kind of article would cite this you ask? Why one also full of transphobia, of course! Like this delightful one, that can’t help but talk about transgender women and the sexual abuse of children in the same sentence whilst also citing every TERF’s favourite ex-comedy writer, Graham Linehan.\nIf we put aside the transphobic nature of the article for a moment (and I’d prefer we didn’t), any statistician worth their salt should have picked up on the terrible advice the article gives in relation to data collection. If you’ve ever had to provide statistical consulting on a project you didn’t initiate, you’ll understand that unless researchers collect data that specifically measure the thing they’re interested in, no amount of statistical wizardry can save their research.\nSo why did a magazine run by statisticians publish an article that advocates for not considering the nuances of your research question at all, and instead pushes a political agenda to only collect data on sex and that (wrongly) defines sex in such a limited way? And no, I don’t consider the throwaway line “Data on gender identity should also be collected in contexts where it may be relevant and useful” to be a get-out-of-jail-free card, when the ~2,000 words preceding it argue the complete opposite. Imagine if someone spent ten minutes saying horribly racist things to you and at the end went ‘SIKE!’. Yeah I don’t buy it either."
  },
  {
    "objectID": "post/2025-03-29-significance-magazine/index.html#its-not-all-doom-and-gloom",
    "href": "post/2025-03-29-significance-magazine/index.html#its-not-all-doom-and-gloom",
    "title": "A big ask: doing literally anything apparently",
    "section": "It’s not all doom and gloom",
    "text": "It’s not all doom and gloom\nBy and large, Significance magazine publishes good stuff, this is just one article that I have particular issue with. But my issue is significant and remains unaddressed.\nThere do also seem to have been some positive things arising out of this debacle. By publishing the article, Significance magazine has spurred on some internal developments across the different professional bodies, which will hopefully lead to improved editorial standards when it comes to articles about minorities and politicised populations.\nThe other positive is that the article is like a canary in a coal mine - it’s nice to know which academics to be wary of based on those who unironically cite it in their own work."
  },
  {
    "objectID": "post/2024-12-18-publications-on-your-website/index.html",
    "href": "post/2024-12-18-publications-on-your-website/index.html",
    "title": "Including your publications on your Quarto website",
    "section": "",
    "text": "In my efforts to continue to replicate my old website, I added a list of my publications. Read on if you’d like to do the same for your own Quarto website!"
  },
  {
    "objectID": "post/2024-12-18-publications-on-your-website/index.html#get-a-.bib-file",
    "href": "post/2024-12-18-publications-on-your-website/index.html#get-a-.bib-file",
    "title": "Including your publications on your Quarto website",
    "section": "Get a .bib file",
    "text": "Get a .bib file\nThe first thing you need to get is a bibliography with your publications in it. I would recommend getting yours from ORCiD. If you don’t already have a profile, now’s a good time to get one and start aggregating your publications in one place.\nOnce you’re logged in to your ORCiD account, scroll down to your ‘Works’ section, click the ‘Actions’ drop-down and click ‘Export ALL works’. This will export all your publications to a .bib file. Perfect!\nYou can of course get a .bib file from other places, such as Google Scholar. My issue with Google Scholar was that it didn’t include DOIs, which meant the list of publications did not have clickable links for people to easily go to the articles."
  },
  {
    "objectID": "post/2024-12-18-publications-on-your-website/index.html#tidy-up-the-.bib-file",
    "href": "post/2024-12-18-publications-on-your-website/index.html#tidy-up-the-.bib-file",
    "title": "Including your publications on your Quarto website",
    "section": "Tidy up the .bib file",
    "text": "Tidy up the .bib file\nPut the .bib file somewhere in your Quarto website folder. Mine just sits in the root folder.\nNext, open up the file with RStudio or whatever text editor you prefer. We need to check the entries are sensible and are going to be formatted as you expect.\n\nCheck the titles\nWhile it does depend on what citation style you are using, it seems the majority of styles will format your article title in sentence case, which is a problem for proper nouns. For example, my paper “Mental and neurodevelopmental health needs of Aboriginal children with experience of out-of-home care: a Western Australian data-linkage study” would get formatted such that ‘Aboriginal’ and ‘Western Australia’ would be entirely lower-case, which isn’t correct.\nTo fix this, we have to ‘protect’ the letters we want capitalised by putting them in curly brackets {}. See the example below where I have the original .bib entry from ORCiD and the protected entry which will preserve the capitalisation of the proper nouns.\n\nOriginal entryProtected entry\n\n\n@article{Harrap_2024,title={Mental and neurodevelopmental health needs of Aboriginal children with experience of&lt;0xa0&gt;out-of-home care: a Western Australian data-linkage study},volume={48},ISSN={1326-0200},url={http://dx.doi.org/10.1016/j.anzjph.2024.100181}, DOI={10.1016/j.anzjph.2024.100181},number={5},journal={Australian and New Zealand Journal of Public Health},publisher={Elsevier BV},author={Harrap, Benjamin and Gibberd, Alison and O’Donnell, Melissa and Jones, Jocelyn and Chenhall, Richard and McNamara, Bridgette and Simons, Koen and Eades, Sandra},year={2024},month=oct,pages={100181}}\n\n\n@article{Harrap_2024,title={Mental and neurodevelopmental health needs of {A}boriginal children with experience of&lt;0xa0&gt;out-of-home care: a {W}estern {A}ustralian data-linkage study},volume={48},ISSN={1326-0200},url={http://dx.doi.org/10.1016/j.anzjph.2024.100181}, DOI={10.1016/j.anzjph.2024.100181},number={5},journal={Australian and New Zealand Journal of Public Health},publisher={Elsevier BV},author={Harrap, Benjamin and Gibberd, Alison and O’Donnell, Melissa and Jones, Jocelyn and Chenhall, Richard and McNamara, Bridgette and Simons, Koen and Eades, Sandra},year={2024},month=oct,pages={100181}}\n\n\n\n\n\nCheck for wacky symbols\nYou may have noticed in the title of the above citation that &lt;0xa0&gt; appears in the title. This should just be a space but for some reason ORCiD has exported it as a non-breaking space. Just replace it with a space.\nMake sure you have a look through the entries for other wacky things. In my .bib file, the journal ‘Child Abuse & Neglect’ was entered as Child Abuse {\\&}amp$\\mathsemicolon$ Neglect, which should instead have been Child Abuse {\\&} Neglect. Similarly, my coauthor Melissa O’Donnell had been listed as Melissa O{\\textquotesingle}Donnell, which can just be replaced with Melissa O'Donnell.\nDon’t worry if you can’t find everything at this stage, you’ll probably notice anything you missed when you check the page on your website."
  },
  {
    "objectID": "post/2024-12-18-publications-on-your-website/index.html#get-a-.csl-file",
    "href": "post/2024-12-18-publications-on-your-website/index.html#get-a-.csl-file",
    "title": "Including your publications on your Quarto website",
    "section": "Get a .csl file",
    "text": "Get a .csl file\nNext we need to pick the citation style you want to use. Zotero have a great repository of .csl files to choose from. Which style you pick is personal preference, I went with APA 7th.\nJust like the .bib file, put the .csl file in your Quarto website folder. Again, mine just sits in the root folder.\n\nChange the sort order\nIt varies with the style you use, but the default sort order for APA 7th is to order citations by author and then ascending by date. Instead, I want the citations to be sorted by year of publication first, then by author. To change this, open the .csl file in RStudio and find the start of the &lt;bibliography&gt; tag. Searching for &lt;bibliography should take you there, but if not, it should be somewhere near the bottom.\nTo change the sort order, switch around the arguments inside the &lt;sort&gt; tag and change “ascending” to “descending”. The example below demonstrates.\n\nOriginalDescending year\n\n\n&lt;bibliography hanging-indent=“true” et-al-min=“21” et-al-use-first=“19” et-al-use-last=“true” entry-spacing=“0” line-spacing=“2”&gt; &lt;sort&gt; &lt;key macro=“author-sort”/&gt; &lt;key macro=“date-sort-group” sort=“ascending”/&gt; &lt;key macro=“date-sort” sort=“ascending”/&gt; &lt;key variable=“status”/&gt; &lt;key macro=“title”/&gt; &lt;/sort&gt; ⋮\n\n\n&lt;bibliography hanging-indent=“true” et-al-min=“21” et-al-use-first=“19” et-al-use-last=“true” entry-spacing=“0” line-spacing=“2”&gt; &lt;sort&gt; &lt;key macro=“date-sort-group” sort=“descending”/&gt; &lt;key macro=“date-sort” sort=“descending”/&gt; &lt;key macro=“author-sort”/&gt; &lt;key variable=“status”/&gt; &lt;key macro=“title”/&gt; &lt;/sort&gt; ⋮\n\n\n\n\n\nChange the citation spacing\nThe other thing we need to do is change the spacing between citations. The default is to have no line between them, which looks horrible and claustrophobic on a website. Instead we want to add a line spacing. In the same &lt;bibliography&gt; tag as before, change the entry-spacing argument from 0 to 2, as per below.\n\nNo spacingSome spacing\n\n\n&lt;bibliography hanging-indent=“true” et-al-min=“21” et-al-use-first=“19” et-al-use-last=“true” entry-spacing=“0” line-spacing=“2”&gt; &lt;sort&gt; &lt;key macro=“date-sort-group” sort=“descending”/&gt; &lt;key macro=“date-sort” sort=“descending”/&gt; &lt;key macro=“author-sort”/&gt; &lt;key variable=“status”/&gt; &lt;key macro=“title”/&gt; &lt;/sort&gt; ⋮\n\n\n&lt;bibliography hanging-indent=“true” et-al-min=“21” et-al-use-first=“19” et-al-use-last=“true” entry-spacing=“2” line-spacing=“2”&gt; &lt;sort&gt; &lt;key macro=“date-sort-group” sort=“descending”/&gt; &lt;key macro=“date-sort” sort=“descending”/&gt; &lt;key macro=“author-sort”/&gt; &lt;key variable=“status”/&gt; &lt;key macro=“title”/&gt; &lt;/sort&gt; ⋮"
  },
  {
    "objectID": "post/2024-12-18-publications-on-your-website/index.html#create-your-publications-page",
    "href": "post/2024-12-18-publications-on-your-website/index.html#create-your-publications-page",
    "title": "Including your publications on your Quarto website",
    "section": "Create your publications page",
    "text": "Create your publications page\nThe last thing we need to do is create the page on your website! Create an empty Quarto file in your root directory and call it publications.qmd. Open this up and paste in the below.\n---\ntitle: \"Publications\"\nformat: html\nbibliography: works.bib\ncsl: apa.csl\nnocite: |\n  @*\n---\n\n:::{#refs}\n:::\nWe’re using the .bib and .csl files we just sorted out. The nocite argument with the @* wildcard is what gets Quarto to print all citations from the bibliography.\nOk the actual last thing we need to do is add the publications page to your navigation bar. Open up your site’s _quarto.yml file and add it to the website argument as follows:\nwebsite:\n  navbar:\n    right:\n      - post.qmd\n      - publications.qmd\n      - cv.qmd\n      - contact.qmd\nThat’s it! Feel free to keep tinkering with the layout etc., at least you’ve got something in place now."
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html",
    "href": "post/2024-08-10-phd-reflection/index.html",
    "title": "Reflecting on my PhD experience",
    "section": "",
    "text": "I submitted my PhD thesis nearly two months ago, and while I still have to wait for examiner feedback to claim that I’ve ‘finished’, I think I’ve sufficiently decompressed post-submission. This post is partly me reflecting on my experience doing my PhD, with the aim of helping those of you thinking of or currently doing a PhD."
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html#being-broke",
    "href": "post/2024-08-10-phd-reflection/index.html#being-broke",
    "title": "Reflecting on my PhD experience",
    "section": "Being broke(?)",
    "text": "Being broke(?)\nBack in 2018 I finished my master’s degree in biostatistics and proceeded to work in various roles applying my statistics and data skills. These were predominantly academic positions, and being employed by an Australian university meant my salary was tied to very specific pay bands. I was happy to be working full-time, having been working weekends and studying full-time for the last year and a half. Going from working a minimum-wage casual retail job to earning a full-time Level A wage felt good by comparison.\nI’d wanted to do a PhD for a long time, but now that I was earning a full-time wage my partner and I were able to work toward financial goals. The prospect of being a broke PhD student was not appealing. This didn’t have to be the case though, as I found out after I chatted to a friend of mine who suggested working a couple of days in addition to doing a PhD. I ran the numbers and he was right, if I was able to secure a PhD scholarship (~$30,000 a year tax-free at the time) and work two days a week, my net income was almost the same as my current full-time income as a research assistant.\nWith this in mind, I figured I may as well do a PhD. Graduate researchers are a source of cheap labour and the work would be similar to what I was currently doing. And since the money was practically the same, why not spend the next 3 to 4 years doing the same work and earning the same money, but ending up with a PhD and in turn increasing my earning potential? Well it turns out the work wasn’t the same as being a research assistant (there is a LOT more independence), but the pay was at least the same.\nAt the time however, I wasn’t passionate about any area in particular. I just really enjoyed coding and was agnostic to the context that I was doing it. So how does that turn into a PhD?"
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html#passion-vs.-job",
    "href": "post/2024-08-10-phd-reflection/index.html#passion-vs.-job",
    "title": "Reflecting on my PhD experience",
    "section": "Passion vs. job",
    "text": "Passion vs. job\nI’ve come to the realisation that PhDs tend to fall into one of two categories. You either start a PhD because you’re passionate about something, or you see it as a job that’s a stepping stone to further your career. I was certainly in the latter category initially, however my passion for my topic developed over the course of my PhD.\nSince I didn’t know what I wanted to do, I looked for projects being advertised that were suited to my skills in an area that I thought was interesting. I happened across an advert on the Statistical Society of Australia’s job forum. I saw an advert for a quantitative PhD student to do research into the health outcomes of Aboriginal children in out-of-home care using linked administrative data. I’ve always wanted the work I do to have meaning, be helpful, and ‘do good’ and this project ticked all of those boxes.\nDespite my developing passion for the topic, I still treated my PhD like a job. Besides the last 3 months of ‘crunch’, I never worked evenings or weekends. I worked 9 to 5, five days a week - three being on my PhD and two being in my job. The advent of covid and remote working was a boon, because it meant I could be a lot more flexible with my time. Some weeks I might work 5 days on my PhD and make up work days at a later date - as long as the work got done nobody minded."
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html#a-time-to-learn",
    "href": "post/2024-08-10-phd-reflection/index.html#a-time-to-learn",
    "title": "Reflecting on my PhD experience",
    "section": "A time to learn",
    "text": "A time to learn\nCoursework degrees are rigid in their structure and having a job means learning typically has to be directly applicable to the work you are doing. The timeframe of a PhD and the environment of learning is unique, so make the most of your time and learn and don’t forget that you’re a PhD student. I learned an enormous amount over the course of my PhD that was ancillary to it.\nI could have stuck with Stata and written my thesis in MS Word, but I wanted to learn R so I committed to doing as much as possible in R and RMarkdown. I could have used statistical methods I had used before, but where possible I made sure to implement methods I hadn’t. Try and build opportunities to learn extra skills into your research.\nAlso take every opportunity you can to apply for funding to attend conferences, workshops, etc. When you’re a student, fees are generally a lot lower, so any funding you can get goes a lot further. If you’re in the statistics field in Australia, make sure you join the Statistical Society of Australia - the financial support offered to students far surpasses the cost of membership."
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html#things-that-were-difficult",
    "href": "post/2024-08-10-phd-reflection/index.html#things-that-were-difficult",
    "title": "Reflecting on my PhD experience",
    "section": "Things that were difficult",
    "text": "Things that were difficult\nThere are many difficult parts to doing a PhD, which are usually difficult because you’ve never done them before. I think it’s useful to remember that if something is difficult it probably means you’re learning, and that’s a good thing. Realising this doesn’t make it any less difficult mind you.\n\nWorking on the same thing, for a long time\nThe most difficult part of the PhD for me was completing my first research article. My assessment at the start was that the code would only take a couple of weeks to write, the write-up might take another month, so budgeting three months to have my first draft ready was being generous. In reality, two years passed between the first meeting to discuss the aims of the article and when it was finally published.\nMy expectations for how long the process would take didn’t improve either. For the next article, I still thought three months was a reasonable timeframe. It took nine months from start to submission. The third article took five months from start to submission. With practice and experience, I’ve certainly became more efficient with my time, but I’m still terrible at estimating how long something will take.\nFor the longest time, the disconnection between my expectation of how long it should take and how long it was actually taking made me feel very stupid. This feeling of stupidity also turned into resentment at times - I didn’t want to get feedback from data custodians, I didn’t want reviewer comments, I just wanted the research to be done.\n\n\nDealing with feedback\nI’ve gotten much better at separating myself from my work, in that I don’t see feedback as a criticism of who I am, I see it as an opportunity to improve my work. I do still feel a whole host of emotions when I receive feedback, because after all I thought the work was good enough to submit for review. My advice for managing feedback is to read the feedback during work hours, but only read it. Do not respond to it, just let your mind dwell on it and return to it the next day. This lets you feel whatever emotions you’re going to feel on your initial reading of the feedback and by sleeping on it you’ll return to it with a clearer mind and give more measured responses.\n\n\nMotivation\nI struggled a LOT with motivation. It felt like days or weeks would go by and I hadn’t done anything at all. Then I’d have periods of enormous productivity. Unfortunately, being extremely productive in a short period of time didn’t alleviate the guilt I experienced during my unproductive periods. I was forever beating myself up for not being able to have productive periods all the time. Being diagnosed with ADHD 8 months before I was due to finish wasn’t ideal, but better late than never I guess.\nDeadlines were a mixed source of motivation. External deadlines were excellent - I’m very good at being accountable to someone else. Things like candidature milestones or submission deadlines were very successful motivators. Setting my own deadlines was not so good, sometimes I’d be able to meet them, but often I’d feel guilty because I wasn’t meeting them - a problem exacerbated by my terrible ability to know how long things should take.\n\n\nMental health\nIf you speak to practically anyone that’s done a PhD, they’ll tell you that their mental health suffered. This was true for me and living in Victoria (Australia) during covid lockdowns certainly didn’t help. I think my perspective on hardship, that feeling like shit is usually temporary, helped carry me through it all though. I’m not suggesting you change your mentality though (“have you tried just not being depressed?”), so here’s some other things that also helped get me through:\n\nMy partner, who supported me in many ways through the whole process\nMy supervisors, who were kind, supportive, and understanding throughout the process\nMy greyhound(s), who love their routines and will not let you skip a walk (getting out of the house was good)\nDoing things that made me happy, which at the time were cooking, brewing beer, gardening, and playing video games\nSeeing a psychologist (do this even if you aren’t doing a PhD)"
  },
  {
    "objectID": "post/2024-08-10-phd-reflection/index.html#should-you-do-a-phd",
    "href": "post/2024-08-10-phd-reflection/index.html#should-you-do-a-phd",
    "title": "Reflecting on my PhD experience",
    "section": "Should you do a PhD?",
    "text": "Should you do a PhD?\nOnly you can answer the question, because the answer is going to depend on what your values and aspirations are. However, I hope my experience highlights some of the positives and negatives of doing a PhD, helps you figure out an answer, and, should to start one, make the most out of it."
  },
  {
    "objectID": "post/2025-10-30-joke/index.html",
    "href": "post/2025-10-30-joke/index.html",
    "title": "How did the geologist carry their books to school?",
    "section": "",
    "text": "In their rocksack"
  },
  {
    "objectID": "post/2025-07-23-joke/index.html",
    "href": "post/2025-07-23-joke/index.html",
    "title": "My gardener friend crossbred cauliflower and watermelon and it was the saddest plant I’ve ever seen",
    "section": "",
    "text": "They said it was a meloncauli"
  },
  {
    "objectID": "post/2020-12-02-tshirt-competition/index.html",
    "href": "post/2020-12-02-tshirt-competition/index.html",
    "title": "Designing a t-shirt",
    "section": "",
    "text": "Back in September 2020 I saw the Statistical Society of Australia (SSA) advertise a t-shirt competition. The competition was only open to members, with the winner of the competition having their design become the official design for the SSA’s t-shirts. Initially I dismissed participating since I hated drawing. When I was in school, I didn’t particularly like any of the ‘creative’ subjects, especially not art. Drawing, painting, shading, getting proportions right, I wasn’t good at any of it and I was always disappointed with what I made. I noped out of any creative subjects as soon as I had the opportunity, happily sticking to subjects which relied letters and numbers, not pencils and paint brushes.\nSo why did I end up submitting a design? It happened in a very roundabout way. My partner, Kelsie, is a graphic designer (a very good one, check out her stuff) and I happened to mention the competition to her. The immediate reaction was “Spec work!? Ugh no thanks”. I hadn’t heard of spec work before, what was it? Short for speculative work, it describes when designers do work with the hopes that their design is selected and they end up getting paid. The problem is that it devalues their work and the industry, and puts everyone in a precarious position - they’re working, but there’s no guarantee they’ll be paid for any of it. The American Institute of Graphic Arts has a statement on spec work if you want to read more. Now that you mention it, it sounds exactly like kaggle. But I digress. I thought about spec work and while I didn’t agree that an amateur submission was the best way to represent the SSA, it was out of my control, so I went about my business."
  },
  {
    "objectID": "post/2020-12-02-tshirt-competition/index.html#the-t-shirt-competition",
    "href": "post/2020-12-02-tshirt-competition/index.html#the-t-shirt-competition",
    "title": "Designing a t-shirt",
    "section": "",
    "text": "Back in September 2020 I saw the Statistical Society of Australia (SSA) advertise a t-shirt competition. The competition was only open to members, with the winner of the competition having their design become the official design for the SSA’s t-shirts. Initially I dismissed participating since I hated drawing. When I was in school, I didn’t particularly like any of the ‘creative’ subjects, especially not art. Drawing, painting, shading, getting proportions right, I wasn’t good at any of it and I was always disappointed with what I made. I noped out of any creative subjects as soon as I had the opportunity, happily sticking to subjects which relied letters and numbers, not pencils and paint brushes.\nSo why did I end up submitting a design? It happened in a very roundabout way. My partner, Kelsie, is a graphic designer (a very good one, check out her stuff) and I happened to mention the competition to her. The immediate reaction was “Spec work!? Ugh no thanks”. I hadn’t heard of spec work before, what was it? Short for speculative work, it describes when designers do work with the hopes that their design is selected and they end up getting paid. The problem is that it devalues their work and the industry, and puts everyone in a precarious position - they’re working, but there’s no guarantee they’ll be paid for any of it. The American Institute of Graphic Arts has a statement on spec work if you want to read more. Now that you mention it, it sounds exactly like kaggle. But I digress. I thought about spec work and while I didn’t agree that an amateur submission was the best way to represent the SSA, it was out of my control, so I went about my business."
  },
  {
    "objectID": "post/2020-12-02-tshirt-competition/index.html#coming-up-with-a-design",
    "href": "post/2020-12-02-tshirt-competition/index.html#coming-up-with-a-design",
    "title": "Designing a t-shirt",
    "section": "Coming up with a design",
    "text": "Coming up with a design\nAll my good ideas seem to come to me out of the blue (thanks subconscious), so I was minding my own business when my brain went, “Hey, this would make a GREAT t-shirt design!”. ‘This’ being a design which pays homage to Australia’s great statisticians. The problem was I sucked at drawing, which was a real shame since it was a good idea. I couldn’t shake the idea though, I thought that if it was done right that maybe it would be a t-shirt worthy of official branding. So with the support of my partner (and her various graphic design tools) I began planning out my design. I started out with printing a map of Australia and drawing a bunch of circles (representing the approximate size of each drawing) to see how many statisticians I’d need to include.\n\nAt this stage, I thought I’d be hard pressed to find 37 statisticians to include. Sure, I’d heard of maybe 10 or so statisticians, some who the SSA have named lectures after, others who seem to publish papers with other big-name statisticians from overseas. How wrong I was! It turned out Australia has produced many statisticians who have contributed a lot to the field of statistics, in many different areas! I started out by looking at the list of statisticians on the SSA website - the named lectures and the Pitman Medal recipients. Sadly though, there were very few female statisticians in either of these lists. I wanted to have some semblance of gender balance in the list and I couldn’t believe there weren’t more female statisticians out there, so I kept searching and found this great list on Wikipedia.\nWith my list of 41 statisticians, rougly balanced in gender, the next job was to research in detail what they did. I really enjoyed this process, I learned so much about each of the candidates. At this point I’d like to give a big thanks to the Australian National University and the Australian Academy of Science for creating some excellent biographies of several statisticians on the list - they were so comprehensive and well written, it really helped me come up with some good ideas for the illustrations.\nThe list was complete and the candidates’ achievements noted, so next I selected which candidates I was going to include as they wouldn’t all fit in (despite Australia being so large). Admittedly, the selection process was a little biased as I was more likely to pick things that I actually felt capable of drawing (and also weren’t just equations). With a tentative list of ‘finalists’ I started sketching out on paper.\n\nDoing the drawings was challenging at first, mainly because I was frustrated that they didn’t look clean and I wasn’t used to drawing. But with the encouragement of my partner and the reaffirmation that they were just rough sketches, I pressed on (check out the sheep, it looks very different in the final design, it’s one of my favourites). As I carried on I found the process easier and more enjoyable - who knew drawing could be fun!? With most of the sketches complete I needed to translate them into the final images, this being done using an iPad Pro (thanks again Kelsie, I couldn’t’ve done this without you!). This was the real highlight of the drawing experience - being able to just undo a mistake, getting nice clean lines with the brush, it definitely made me feel more confident in my ability to draw."
  },
  {
    "objectID": "post/2020-12-02-tshirt-competition/index.html#putting-it-all-together",
    "href": "post/2020-12-02-tshirt-competition/index.html#putting-it-all-together",
    "title": "Designing a t-shirt",
    "section": "Putting it all together",
    "text": "Putting it all together\nMy partner helped put all the images together on the map of Australia (which I made sure included Tasmania). With me peering over her shoulder and coming out with zingers like “Can you move that 2 pixels to the left?” and “Can you make it pop?”, we eventually came up with the final arrangement, which I’m stoked with. See for yourself!\n\nSome personal highlights of mine are Helen Turner’s sheep, which looks much happier than the initial sketch\n\nThe Pitman Medal (although he looks a little grumpier than on the original medal)\n\nAnd Annette Dobson’s “Introduction to Generalized Linear Models”, who hasn’t read this book!?\n\nI also ended up creating a back design for the t-shirt too since without a key it’d probably be quite hard to figure out who did what:\n\nAnyway, that’s all from me - I hope you like the design. It’s one of my proudest achievements to date. Go and read about the people on the list - they’re all amazing and really illustrate that as statisticians we do get to play in everyone’s back yards."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html",
    "title": "Thinking About Gender Identity",
    "section": "",
    "text": "I thought I would gather my thoughts on my gender identity in this post. Partly for me to keep track of thoughts and feelings I’ve had, and partly in the hopes that it could be useful to someone. I’d also like to point out that this isn’t an academic work on gender identity, it’s not meant to be profound, it’s really just a diary of sorts on my personal experience and thoughts."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html#where-it-all-began",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html#where-it-all-began",
    "title": "Thinking About Gender Identity",
    "section": "Where it all began",
    "text": "Where it all began\nI was sitting on the couch, idly scrolling Twitter, when my partner asked me “how would you feel if somebody used she to refer to you”. I paused for a bit, and came to the conclusion that it wouldn’t bother me. I hadn’t ever thought about pronouns before, since up until that point I had gone along with the idea that I was a man. My reasoning at the time was that an ‘incorrect’ pronoun didn’t really matter as long as it was clear that the pronoun being used was referring to me.\nI thought it was an interesting question, but didn’t think much more of it at the time. But in the following days my mind kept returning to that question - why doesn’t it bother me what pronouns people use? That’s when I asked myself the question\n\nAm I male?\n\nIt wasn’t a question I had an immediate answer to, but as soon as I asked it I felt some anxiety. That anxiety would come back every time my mind returned to the question. I’m not sure why I felt anxious - maybe it was the uncertainty of not knowing myself, or from challenging the male identity, or feeling that having ‘been male’ for so long I wasn’t allowed to be anything else? At any rate, the rumblings of ditching my male identity had begun, but what it was going to be replaced with I wasn’t sure."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html#trying-to-figure-it-out",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html#trying-to-figure-it-out",
    "title": "Thinking About Gender Identity",
    "section": "Trying to figure it out",
    "text": "Trying to figure it out\nSo at this point I wasn’t quite sure what my gender identity might be, but at the very least the words ‘man’ or ‘guy’ or ‘bloke’ didn’t feel like they described me. Even arriving at these thoughts I was still second-guessing myself. People talk about having known since they were a child that their identity didn’t fit what they were being told - and that’s great! But I was modelling my expectations of understanding my own identity on this inherent ‘just knowing’, which I realise now was foolish. Everyone’s journey toward understanding themselves is different and my journey started with a feeling of ‘something’s not right but I’m not sure what that means’. In hindsight of course everyone’s journey is different, but at the time I was frustrated that I didn’t ‘just know’.\nUp until this point, my knowledge of what it meant to be non-binary was pretty superficial. I understood it meant having a gender identity that didn’t fit into the binary categories of male and female, but that was it. I did a bit of googling and learned about the umbrella that is non-binary, and all the different ways that people identify under it (e.g. genderqueer, agender, genderfluid). I thought maybe agender sounded right, but needed to dwell on it some more.\nIn doing my very academic google search I realised that I hadn’t listened to the experiences of non-binary people who were generous enough to share them (sorry for being a bad ally) - the closest I’d come was incidental thanks to Jonathan Van Ness on Queer Eye. So I sought out people talking about their experience being non-binary. One of the first articles I came across was this article on Teen Vogue. Seeing the diverse appearance and experiences of non-binary people was fantastic and really drove home that there isn’t a non-binary ‘look’.\nSerendipitously, the day that I thought I might be non-binary was actually International Non-Binary Day, which meant there were a wealth of posts on Twitter and videos on YouTube on what it means to be non-binary. This tweet thread by Professor Sandy O’Sullivan is brilliant and further challenged any preconceptions I might’ve had about non-binary people:\n\n\nHey, today (14 July) is International Non-Binary Awareness Day! Let's all be aware of fabulous non-binary people!Here's me looking all non-binary yesterday. Do you have a photo, story or a bit of appreciation to share?Some non-binary mythbusting below! pic.twitter.com/vpXEo9QVEt\n\n— Prof Sandy O'Sullivan (Wiradjuri, trans they/them) (@sandyosullivan) July 13, 2021\n\n\nThe below video (which my partner kindly sent me) has Anthony Padilla interviewing several non-binary people to do some myth-busting and talk about their experiences. This was also helpful and I’m really grateful to Jeffrey, Jacob, and Angel for being so open.\n\n\nAll of the videos and discussions of non-binary identity helped shatter my pre-conceptions of what it meant to be non-binary. The big one for me was associating androgyny with non-binary. As many non-binary folk have said, non-binary people don’t owe you androgyny. Ditching these stereotypes made it clearer to me that non-binary was something that I could indeed be."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html#struggling-with-it",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html#struggling-with-it",
    "title": "Thinking About Gender Identity",
    "section": "Struggling with it",
    "text": "Struggling with it\nOne of the things I found challenging to get to grips with was that gender identity doesn’t have to stay the same. Intellectually I understood this - of course you can feel male one day, non-binary another day, then male again. Emotionally I was having a hard time, I think because I wanted to have some certainty so I could figure out the ‘right answer’ and move on. Eventually I came to terms with gender not being fixed - mostly by just dwelling on it for some time. I found reframing the question from “what is my gender identity” to “what is my gender identity at the moment” helpful. Gender didn’t need to be some immutable characteristic.\nThe next big challenge I came up against was saying words out loud. Up until now, everything had been happening in my head. But there’s a strange power in saying things out loud. At first it was awkward. I started by saying it out loud to myself. “I’m non-binary”. It felt weird and uncomfortable - like I was saying something I wasn’t meant to say - but it was also exciting. Then I said it to my partner, “hey, so I… uhhh… think I’m non-binary?” - it sounded much less certain that time. I think through practice and repetition I’ll feel more confident in owning my identity.\nIt doesn’t feel as weird to say it out loud any more, but I still feel a sense of anxiety around saying it to people. My world has gone from assuming everyone around me is kind, supportive, and understanding (which they are), to being paranoid that they’ll react negatively if I told them. It’s sad that such stigma exists, nobody should be made to feel uncomfortable about who they are.\nI reached out to a non-binary person who I knew, asking them if they’d be willing to have a chat about their experience. They were so kind and I’m so grateful that they were willing to listen to my probably silly questions and ramblings. I still felt a little unsure at the time, finding it difficult to pick the right words to describe what I was feeling, but they were reassuring and let me just talk. Talking actually turned out to be quite difficult, I think because I was still figuring out how to talk about being non-binary, but I didn’t feel like I could find the right language to use either.\nWhile I was writing this I decided to tell one of my PhD supervisors. The experience was terrifying and exhilarating. “Hey, can I tell you something? I’m non-binary”. It was abrupt but it felt right! They were kind in their reaction and asked me if I was changing my pronouns. I felt awkward because I didn’t know what reaction to expect. In one respect I felt like it was a big deal that needed celebrating, but it also doesn’t feel like a big deal because I haven’t really changed - if anything I’m more me. I must admit, in an effort to avoid any awkwardness I kept talking to fill in any potential silence and proceeded to over-explain and justify why I identified as such. On reflection, I definitely didn’t need to justify it - but I’m still learning."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html#the-start-of-the-journey",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html#the-start-of-the-journey",
    "title": "Thinking About Gender Identity",
    "section": "The start of the journey",
    "text": "The start of the journey\nHaving reached the comfortable conclusion that I am non-binary (at the moment) feels good. It certainly wasn’t as big of a deal as I initially thought it would be. I’m still the same person, I just know myself better now.\nAn analogy that works for me is that I’d been sitting in a dark gender-identity room my whole life. In the darkness the only thing I knew was the male identity. Recently, I noticed a little gender-identity light-switch on the wall, but the light-switch was surrounded by big patriarchy signs saying “WARNING DO NOT TOUCH” and “DANGER”. So the thought of switching the light on was very scary. I had to fight the anxiety and muster up the courage to flip the switch, all the while worrying about the massive ramifications that would follow. But after turning the lights on, nothing bad happened - the signs were bullshit. In fact, nothing much happened at all - I could just see the room better.\nIt was liberating. Freeing myself from binary gender has got me challenging a lot of the things that I used to tell myself “that’s not for you”. For example, I want to get myself a cute peach-coloured jumper. It feels kinda stupid, saying that with my new found identity I want to get a colourful jumper, but honestly, feeling like I shouldn’t like colourful jumpers is the kind of dumb shit that being raised as a male in a patriarchal society teaches you."
  },
  {
    "objectID": "post/2021-07-30-thinking-about-gender-identity/index.html#afterthoughts",
    "href": "post/2021-07-30-thinking-about-gender-identity/index.html#afterthoughts",
    "title": "Thinking About Gender Identity",
    "section": "Afterthoughts",
    "text": "Afterthoughts\nIt felt weird writing this and typing that I was a man - it definitely doesn’t feel like the right descriptor any more. Perhaps it never was, or perhaps it was until recently? I’ll never know since I can’t go back in time and interrogate my thoughts on my gender identity. I wrote this up and left it for a couple of days, stewing some more. I’ve started having feelings of “maybe I’m not non-binary, maybe I’m being silly” but then I return to the same question “am I a man” and the answer is still no. I don’t know what to make of that at the moment, I’ll just sit with it for now and see how I feel in the coming weeks.\nSomething I’m still aware of is my ostensibly masculine appearance. I was raised male and with that came privilege. I’ve been thinking about male privilege and how I benefit from it for far longer than I’ve been thinking about my gender identity, but this adds a new complexity. I assume people will still see me as male and treat me as such - my internal change hasn’t changed my external appearance, which is how people see me. The challenge I find is that I’m considering how other people perceive me and trying to shape my behaviour accordingly. This seems silly though, I’ll just be acting a gender identity that isn’t mine. So I’m also paying more attention to how I respond to others and trying to act in a way which is true to me, not true for what others might expect from me.\nAll in all, I’m still the same person in all the nuanced ways that make me me. And I don’t mind what pronouns you use."
  },
  {
    "objectID": "post/2024-07-10-joke/index.html",
    "href": "post/2024-07-10-joke/index.html",
    "title": "What did the pig get to help with their dry skin?",
    "section": "",
    "text": "An oinkment"
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html",
    "href": "post/2023-10-09-atsima-conference/index.html",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "",
    "text": "The Statistical Society of Australia (SSA) were advertising funding to support a member to attend this year’s Aboriginal and Torres Strait Islander Mathematics Alliance (ATSIMA) conference. I’d been wanting to go to an ATSIMA conference for a couple of years so when this funding came up I jumped at the chance - and luckily enough for me I got it! So a big thank you to the SSA for enabling me to attend the conference.\nI wrote some reflections each evening of the happenings each day. If you have an opportunity to attend an ATSIMA conference you should unreservedly pursue it. This conference has been like no other, the atmosphere was one of openness, kindness, and a genuine desire to learn from each other and do better when it comes to teaching Indigenous kids (and children more broadly!)."
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html#day-0",
    "href": "post/2023-10-09-atsima-conference/index.html#day-0",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "Day 0",
    "text": "Day 0\nSince having an infant I’ve become accustomed to waking up at 5am, but it felt like a bit of a stretch waking up at 4am this time. But you do what you’ve got to do! Funnily enough, they woke me up one minute before the alarm was due to go off anyway, so thanks for the help Billie.\nSo up at 4am, dressed, packed, coffeeed, breakfasted, and dropped off at the bus station. Off to a good start! The plane was delayed by 45 minutes, which was a little alarming given there was only an hour in the original schedule to transfer. When we touched down in Cairns I walked briskly to the connecting gate, only to find they hadn’t even opened boarding yet. I relaxed for a moment then realised I’d put my t-shirt on inside-out. Serves me right for getting dressed at 4am in the dark!\nA big line had formed by the time the flight to Gove finally opened. Lots of delegates attending the ATSIMA conference this year! We boarded, only to find out we were now waiting for another flight that had been delayed. All my worries about being on time for naught! No matter though, the flight eventually departed and we landed in Gove airport.\nWhat a sight to behold, the red dirt of East Arnhem land. The land is beautiful up here."
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html#day-1",
    "href": "post/2023-10-09-atsima-conference/index.html#day-1",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "Day 1",
    "text": "Day 1\nWhat a day! I’m sitting back in my room with a thoroughly sunburned neck and a head full of ideas. It’s been fascinating coming to a conference that’s heavily focused on teaching. I have no background in teaching (besides learning vicariously through my partner’s teaching degree), so it was great to listen in on the conversations people were having about teaching. The language they use was quite different to what I’d hear on a day to day basis - I heard pedagogy several times.\n\nThe day started out with a Welcome to Country from local Elders, followed by Professor Chris Matthews and a panel of speakers talking about Garma Mathematics and two-way learning - meaning to teach in a way that incorporates both Western and Indigenous ways of knowing and being and treats them as equal. Then Yingiya Mark Guyala MLA told us part of his story, going from living on his homeland and getting a practical education from his Elders, through going to school and learning English, to getting his pilot’s license. He talked about how learning the balanda (the Yolgnu word for Western people) way was pulling him in one direction, and learning the Yolgnu way pulling him in the opposite, to the point where he couldn’t keep going. His story really drove home the importance of figuring out how to bring Western and Indigenous teaching together.\n\nIn the push against the deficit narrative that so often accompanies how Indigenous people’s lives are talked about, a strengths-based approach that sees Indigenous cultures and communities as a strength is something I often come across. And while this approach is something I agree with and try to incorporate into my own writing, I feel like I’ve only known it at a factual/intellectual level. Today really changed that for me though. I heard so many stories about the brilliance of Indigenous children, how they engaged and learned about mathematical topics typically considered ‘beyond’ the usual capabilities for their age, and this was all possible through their culture. The ‘complex’ mathematics were part of their lives, part of their culture, it just took making the connection between what they already knew and the specific mathematics.\nWe finished off the day with food, chatting, checking out the art gallery, and hanging out with the camp dogs."
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html#day-2",
    "href": "post/2023-10-09-atsima-conference/index.html#day-2",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "Day 2",
    "text": "Day 2\nIn one of the sessions I had my first experience with a virtual reality (VR) headset, boy are they COOL. The workshop was a demonstration of a rapid design challenge the presenters run with children. We had to design come up with our own design of a fish net or trap, similar to those made by Indigenous cultures across Australia. Our group decided to make a crocodile catcher, and after a brief few minutes sketching some 2D designs on paper we were thrust into three dimensions via the VR headset.\n\nI also listened to a couple of presentations how culture can be woven into specific high school educational settings. The theme of yesterday came through again, that Indigenous culture(s) are such a source of strength and engagement in the classroom, even for non-Indigenous kids. We later heard from a group of teachers from the East Arnhem region who talked about the importance of teaching in language (Yolngu for the kids here). For the majority of the children, Yolngu matha is their first language, English is something they learned later. So while it might seem obvious to teach children in the language they know best, apparently it wasn’t obvious to everyone. But after teaching mathematics in their language and linking mathematical concepts to cultural ideas they were familiar with, the kids were more engaged and learned mathematical concepts more readily. One of the quotes that stuck with me too was that “Yolngu parents want their children to succeed, but not at the expense of their culture”, this point once again reaffirming the importance of incorporating Indigenous culture in teaching Indigenous children.\nThe talks finished at 3pm today and we went on a cultural walk through a trail down to a nearby beach. Some of the local kids and rangers explained various plants and their uses as we walked the trail. After passing an unusually angular arrangement of branches, we made it down to a secluded beach with beautiful views across the ocean.\n\nThe conference dinner was the final event of the evening, we shared food and conversation and were entertained by the Andrew Gurruwiwi band. If you haven’t listened to the band before, I highly recommend you check them out!"
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html#day-3",
    "href": "post/2023-10-09-atsima-conference/index.html#day-3",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "Day 3",
    "text": "Day 3\nThe final day was largely dedicated to summarising the key themes we’d covered in the previous two days. We got together in groups of approximately ten to have a yarn about the topics we’d heard at the conference and what we were going to do going forward. It was such a brilliant way to round out a conference. In previous conferences I’ve been to you go to the talks you’re interested in but you effectively miss out on the other sessions you don’t attend. While there might be conference abstracts, you’re left to read them in your own time and reach out to the authors if you want more detail.\nBy getting everyone together and encouraging them to form groups with people they might not have met or know well, we all got to learn more deeply about the conversations had throughout the conference. Then at the end, each group got up and gave a summary of their yarn so everyone could learn. It was such a beautiful way to make sure that nobody missed out on the learnings made at the conference. I wish more conferences would do it!\n\nOne of the themes that really struck a chord with me was the importance of giving back to the Indigenous communities that give their knowledge, knowledge used to develop materials used to teach kids. Schools which have the ability to work with local communities to incorporate their knowledge into the curriculum must make sure that the material they develop is available to everyone. Many of the teachers present were from schools were there were only a few Indigenous students, so the materials mostly benefited non-Indigenous children. Making the resources more broadly available, in particular to other schools where more Indigenous children might be present, means the knowledge of the community can be benefiting as many Indigenous children as possible and help their learning and connection to culture.\nThe reason why this struck a chord with me is because I realised I need to do more of this in my PhD. Up until now I’d been doing research translation back our policy and community reference groups, but the research I’d done was at a broad population level. The communities want to know what the data says about their specific contexts, so I intend to shift my direction to do more community-disaggregated analysis, that’s directly relevant for these communities."
  },
  {
    "objectID": "post/2023-10-09-atsima-conference/index.html#day-4",
    "href": "post/2023-10-09-atsima-conference/index.html#day-4",
    "title": "Going to the ATSIMA 2023 conference",
    "section": "Day 4",
    "text": "Day 4\nThe conference had ended, but the conversations continued at the airport. We’d all gotten to know each other so well over the past few days and there are only a handful of flights out of Gove each day, so naturally we all congregated at the terminal and kept the conference chatter alive for an extra hour or two. While I can only speak for myself, I imagine every single attendee of ATSIMA2023 is grateful to Professor Chris Matthews, Melinda Pearson, Caty Morris, and everyone else who put so much work in to make such an incredible conference happen."
  },
  {
    "objectID": "post/2024-11-25-quarto-migration/index.html",
    "href": "post/2024-11-25-quarto-migration/index.html",
    "title": "Migrating from blogdown/Hugo to Quarto",
    "section": "",
    "text": "So my old website became too painful to keep updated thanks to version differences across the blogdown and Hugo system I was using, so I’ve migrated it to a Quarto website. There were a few things that I had to figure out along the way so I’ve documented them here for your sake."
  },
  {
    "objectID": "post/2024-11-25-quarto-migration/index.html#replicating-the-hugo-academic-url-structure",
    "href": "post/2024-11-25-quarto-migration/index.html#replicating-the-hugo-academic-url-structure",
    "title": "Migrating from blogdown/Hugo to Quarto",
    "section": "Replicating the Hugo Academic URL structure",
    "text": "Replicating the Hugo Academic URL structure\nThe main thing I wanted to do was replicate my old website in that the home page contained my bio and some external links, with my blog posts on a separate page. To do this I started off making a new ‘Quarto Blog’ project in RStudio following the documentation on Quarto’s website. It’s important to select blog, not website at this step.\nThe very first thing you want to do is swap the YAML between the about.qmd and index.qmd files. This is because index.qmd is the home page for your website. Quarto’s default is to make the blog your home page, but we don’t want that. Swapping the YAML puts your bio as the home page. I also renamed the posts folder to post, just in case that mattered but I’m not sure it does.\nThe next thing is to rename about.qmd to post.qmd. This is now your main page for your blog and it has the same URL structure as the old Hugo Academic template. This means when you migrate your blog posts from your old to your new website, the URLs won’t break. Yay!"
  },
  {
    "objectID": "post/2024-11-25-quarto-migration/index.html#migrating-blog-posts",
    "href": "post/2024-11-25-quarto-migration/index.html#migrating-blog-posts",
    "title": "Migrating from blogdown/Hugo to Quarto",
    "section": "Migrating blog posts",
    "text": "Migrating blog posts\n\nKeeping URLs consistent\nQuarto’s method of organising files used in blog posts is way better than blogdown/Hugo. Instead of having a .Rmd file in the post folder and keeping all the content in a separate location (was it in static? I never remember), you have one folder per blog post and all the files go in that folder. I.e.:\n-   post\n  -   2024-11-25-quarto-migration\n  -   2024-08-10-phd-reflection\n  -   etc.\nThe name of each blog post’s folder will be used to create the URL. This means if you want to keep the URLs of your blog posts the same, you must give each blog post’s folder the same name as the original .Rmd file.\nTo copy the content across, just copy and paste the original .Rmd file and rename it to index.qmd. Note the change in extension from .Rmd to .qmd.\nFor example, my blog post reflecting on my PhD experience was originally written in a file called 2024-08-10-phd-reflection.Rmd. This means I would create a folder within the post folder called 2024-08-10-phd-reflection, put my original blog post file 2024-08-10-phd-reflection.Rmd inside this folder and rename the file to index.qmd. Building on the above example, this would look like:\n-   post\n  -   2024-11-25-quarto-migration\n  -   2024-08-10-phd-reflection\n    -   index.qmd\n  -   etc.\n\n\nTranslating .Rmd to .qmd files\nNow you’ve changed your original .Rmd files to .qmd files by just renaming them, you’ll need to fix some of the YAML.\nThe main thing is to delete tags: []. Quarto only uses categories. Without knowing what other YAML options you were using it’s hard to say what else needs to change but if you try and render your website it will either work or not work, and if it doesn’t work something still needs fixing.\nAn example of the YAML for my PhD reflection blog post is:\n\nOld .Rmd YAMLNew .qmd YAML\n\n\ntitle: \"Reflecting on my PhD experience\"\nauthor: \"Ben Harrap\"\ndate: 2024-08-10\ncategories: [\"Academic\", \"Self\"]\ntags: [\"Academic\",\"PhD\",\"Research\",\"Learning\"]\n\n\ntitle: \"Reflecting on my PhD experience\"\nauthor: \"Ben Harrap\"\ndate: 2024-08-10\ncategories: \n  -   academia\n  -   self\n  -   phd\n\n\n\n\n\nMoving images, files, etc.\nIf your old blog posts referenced any files, such as images, you’ll need to move them to the new blog post’s folder and update the path in your blog post’s new index.qmd file. My confirmation report blog post is a good example of this, it uses images, a bibliography, and a .csl file. After moving all the resources to the blog post’s folder, I updated the YAML:\n\nOld Rmd YAMLNew YAML\n\n\nbibliography: [../../static/post/confirmation-report/references.bib]\ncsl: [../../static/post/confirmation-report/harvard-the-university-of-melbourne.csl]\n\n\nbibliography: references.bib\ncsl: \"harvard-the-university-of-melbourne.csl\"\n\n\n\nAnd I updated the locations of the images:\n\nOld image locationNew image location\n\n\n![](/img/confirmation-report/system-overview.png)\n\n\n![](system-overview.png)\n\n\n\n\n\nSetting preview images\nIf your blog post has images in it, the default setting is to pick an image to use as a preview on your main blog page. You can specify which image you want to be used as the preview using in the post’s YAML:\nimage: \"talk.png\"\nIf you don’t want any images displayed, set the option to be false:\nimage: false\nIf you don’t have any images in your blog post but you still specify image: false, Quarto will crash when trying to render your website. I had a few moments of madness figuring this out!"
  },
  {
    "objectID": "post/2024-11-25-quarto-migration/index.html#modifying-the-home-page-layout",
    "href": "post/2024-11-25-quarto-migration/index.html#modifying-the-home-page-layout",
    "title": "Migrating from blogdown/Hugo to Quarto",
    "section": "Modifying the home page layout",
    "text": "Modifying the home page layout\nI liked the home page layout of the academic theme so I wanted to replicate it somewhat. There were a few things that needed to be changed, including the social buttons and the profile picture. If you haven’t already created a custom.scss file, go ahead and create one (see the Quarto documentation), as we’ll need it for this section.\nNext, in _quarto.yml, add the following:\ntheme: custom.scss\nWhich tells Quarto to use your custom styles.\n\nTinkering with your picture\nRefer to the Quarto About Page documentation for more templates, but the trestles template was the one that gave me Hugo Academic vibes. To use this template, add the following to your site’s index.qmd:\nimage: \"img/ben.jpg\"\nabout:\n  template: trestles\n  image-shape: round\n  image-alt: \"A portrait photo of Ben, they've got their hair up in a bun, are wearing a white and navy striped jumper, and are smiling.\"\nThe image argument points to the profile picture you want to use. The main problem with the image in the trestles template is in mobile view - it touches the navigation bar at the top and I don’t like that. To fix it, add the following to your custom.scss file:\n.about-image {\n  margin-top: 20px;\n  width: 15rem !important;\n  height: 15rem !important;\n}\nThe margin-top is the argument that stops the image and navbar from touching, the width and height arguments are personal preference. I find in mobile the default size of the image is so large that it bumps the start of the ‘About me’ text off-screen. By making the image slightly smaller, a couple of lines of text are visible and we hopefully entice people to read more!\n\n\nSocial buttons\nThe default layout of the social links in the Quarto blog (see the About Page documentation) is to create rectangular buttons. This isn’t the worst, but I like the look of just using the company logos. The other downside of the Quarto default is that in mobile view it looks shit, the buttons are arranged vertically and take up the whole screen. That means if you have a lot of links people have to scroll past them to find out more about you.\n\nIncluding extra icons\nTo get the buttons looking like they do on my home page we need to include the fontawesome extension and add some custom styling. The fontawesome extension is needed for a couple of icons which aren’t included in the default Bootstrap pack. To install the extension, run:\nquarto add quarto-ext/fontawesome\nfrom the RStudio terminal. Then add the links like you would according to the About Page documentation. The Font Awesome icons are included as follows:\nlinks:\n    - text: \"{{&lt; fa brands bluesky &gt;}}\"\n      href: https://bsky.app/profile/bharrap.bsky.social\nThe Font Awesome website has a list of all available icons (https://fontawesome.com/search), just make sure you tick the ‘Free’ filter.\n\n\nChanging the icon orientation\nAdd the following three styles to your custom.scss file:\n.about-link-text {\n  font-size: 2rem;\n}\nThis increases the size of the icons, they look comically small otherwise. Make it larger if you like.\n.about-link {\n  border: none !important;\n}\nThis removes the rounded border from the icons. It’s ugly and we don’t need it.\n.about-links {\n  flex-direction: row !important;\n}\nThis is the most important bit. This changes the orientation of the icons to be in a row, rather than a column, when viewing the website in a narrow window (e.g. on mobile or a small browser window)."
  },
  {
    "objectID": "post/2024-11-25-quarto-migration/index.html#other-bits",
    "href": "post/2024-11-25-quarto-migration/index.html#other-bits",
    "title": "Migrating from blogdown/Hugo to Quarto",
    "section": "Other bits",
    "text": "Other bits\nThere were a couple of other bits that I found annoying to do but weren’t directly related to replicating the Hugo Academic theme, so I’ve included them here.\n\nChanging fonts\nThere seem to be a few ways to change fonts in Quarto but only the following way worked for me - in particular for the monospaced font. I like Nunito for regular text and Noto Sans Mono for monospaced text. To change the font, head over to Google Fonts and find the fonts you like.\nWhen you find the fonts you like click on the ‘Get font’ button, then ‘&lt;&gt; Get embed code’, then copy the third &lt;link&gt; tag from the HTML &lt;head&gt; code. Paste that tag into _quarto.yml as follows:\nformat:\n  html:\n    theme: custom.scss\n    header-includes: |\n      &lt;link href=https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&family=Nunito:ital,wght@0,200..1000;1,200..1000&display=swap rel=\"stylesheet\"&gt;\nNext, add the following to the scss:defaults section of your custom.scss file:\n/*-- scss:defaults --*/\n\n$web-font-path: \"Break\";\n$font-family-sans-serif: \"Nunito\", sans-serif !default;\n$font-family-monospace: \"Noto Sans Mono\", monospace !default;\nThe reason for the $web-font-path argument is that I couldn’t figure out how to override the default monospace font being used until I came across this handy Stack Overflow answer. The following two arguments just set the fonts for your sans-serif and monospace text.\n\n\nAdding the ‘Buy me a coffee’ widget\nCailin, my first coffee supporter, very generously offered to buy me a coffee as thanks for the RStudio themes I made, which prompted me to create a Buy me a coffee account. Then I needed to add the widget to my website, which is a pretty simple task.\nFirst, create an account if you don’t already have one, then find your way to ‘Website widget’ in the ‘Buttons & Graphics’ menu. Once you’ve create the button, copy the script.\nNext, paste it in to your _quarto.yml file in the header-includes argument. Building on our example before where we already included the Google Font link, we paste the Buy me a coffee script on a new line with the same indentation as the link.\nformat:\n  html:\n    header-includes: |\n      &lt;link href=https://fonts.googleapis.com/css2?family=Noto+Sans+Mono:wght@100..900&family=Nunito:ital,wght@0,200..1000;1,200..1000&family=Source+Sans+3:ital,wght@0,200..900;1,200..900&display=swap rel=\"stylesheet\"&gt;\n      &lt;script data-name=\"BMC-Widget\" data-cfasync=\"false\" src=\"https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js\" data-id=\"benharrap\" data-description=\"Support me on Buy me a coffee!\" data-message=\"\" data-color=\"#ffddd6\" data-position=\"Right\" data-x_margin=\"18\" data-y_margin=\"18\"&gt;&lt;/script&gt;\nTo change the colour of the widget, update the hex code in the data-color argument. If you entered a widget message when you generated it, there will be text in the data-message argument. Personally I would recommend turning this off as it is pops up every single time a new page is loaded and gets very annoying very quickly. If you leave the argument blank (i.e. data-message=\"\") the button sits there quietly.\nThat’s all my advice for now - and hey if you found it useful, why not buy me a coffee!"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html",
    "href": "post/2025-09-24-combining-strings/index.html",
    "title": "Joining strings with missing data together in R",
    "section": "",
    "text": "Joining multiple string columns together in R isn’t a particularly tricky thing to do. Until recently though, I found it unreasonably annoying trying to join strings where missing data is present. For example, let’s say we’ve got the following address data:\nlibrary(tidyverse)\naddresses &lt;- tibble(\n  unit = c(\"Shop 4\",\"Unit 185\", NA, NA),\n  street = c(\"2 Frencham Pl\",\"20 Allara St\",\"1 McCoy Cct\",\"130 Garran Rd Acton ACT 2601\"),\n  suburb = c(\"Downer\",\"Canberra\",\"Acton\", NA),\n  postcode = c(\"2602\",\"2601\",\"2601\", NA)\n)\nThe first two have a value for each element, while the third address doesn’t have a unit, and the fourth for some reason has all the elements in street. What I want to do is combine all of these address elements into a single string and ignore missing values. Let’s review the ways we can go about this."
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#tidyrunite",
    "href": "post/2025-09-24-combining-strings/index.html#tidyrunite",
    "title": "Joining strings with missing data together in R",
    "section": "tidyr::unite()",
    "text": "tidyr::unite()\nI’ll cut to the chase – tidyr::unite() is perfect for this:\n\naddresses |&gt;\n  bind_cols(\n    unite(\n      data = addresses,\n      col = \"address\",\n      sep = \" \",\n      na.rm = TRUE\n    )\n  )\n\n# A tibble: 4 × 5\n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                 \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601     1 McCoy Cct Acton 2601\n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;     130 Garran Rd Acton A…\n\n\nI only recently learned about unite() (thanks anonymous cat data scientist!) and was surprised to find it in tidyr and not in stringr. Anyway, it’s perfect!"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#basepaste",
    "href": "post/2025-09-24-combining-strings/index.html#basepaste",
    "title": "Joining strings with missing data together in R",
    "section": "base::paste()",
    "text": "base::paste()\nWe could use paste(), except that it includes NA as the letters NA in the output, which is not what I want.\n\naddresses |&gt; \n  mutate(\n    address = paste(\n      unit, street, suburb, postcode,\n      sep = \" \"\n      )\n  )\n\n# A tibble: 4 × 5\n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                 \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601     NA 1 McCoy Cct Acton …\n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;     NA 130 Garran Rd Acto…\n\n\nWe could do some cleaning to overcome this issue:\n\naddresses |&gt;\n  replace_na(\n    replace = list(unit = \"\", suburb = \"\", postcode = \"\")\n  ) |&gt;\n  mutate(\n    address = paste(\n      unit, street, suburb, postcode,\n      sep = \" \"\n    )\n  )\n\n# A tibble: 4 × 5\n  unit       street                       suburb     postcode address           \n  &lt;chr&gt;      &lt;chr&gt;                        &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;             \n1 \"Shop 4\"   2 Frencham Pl                \"Downer\"   \"2602\"   \"Shop 4 2 Frencha…\n2 \"Unit 185\" 20 Allara St                 \"Canberra\" \"2601\"   \"Unit 185 20 Alla…\n3 \"\"         1 McCoy Cct                  \"Acton\"    \"2601\"   \" 1 McCoy Cct Act…\n4 \"\"         130 Garran Rd Acton ACT 2601 \"\"         \"\"       \" 130 Garran Rd A…\n\n\nBut the empty strings are now causing excessive separators to be included. We can fix this with str_trim() and str_squish(), but it’s getting silly at this point. Just use unite()!\n\naddresses |&gt;\n  replace_na(\n    replace = list(unit = \"\", suburb = \"\", postcode = \"\")\n  ) |&gt;\n  mutate(\n    address = str_trim(\n      paste(\n        unit, street, suburb, postcode,\n        sep = \" \"\n      )\n    )\n  )\n\n# A tibble: 4 × 5\n  unit       street                       suburb     postcode address           \n  &lt;chr&gt;      &lt;chr&gt;                        &lt;chr&gt;      &lt;chr&gt;    &lt;chr&gt;             \n1 \"Shop 4\"   2 Frencham Pl                \"Downer\"   \"2602\"   Shop 4 2 Frencham…\n2 \"Unit 185\" 20 Allara St                 \"Canberra\" \"2601\"   Unit 185 20 Allar…\n3 \"\"         1 McCoy Cct                  \"Acton\"    \"2601\"   1 McCoy Cct Acton…\n4 \"\"         130 Garran Rd Acton ACT 2601 \"\"         \"\"       130 Garran Rd Act…"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#basesprintf",
    "href": "post/2025-09-24-combining-strings/index.html#basesprintf",
    "title": "Joining strings with missing data together in R",
    "section": "base::sprintf()",
    "text": "base::sprintf()\nAnother base option is to use sprintf(), which seems like we’d still need to do some extra work to handle the NA.\n\naddresses |&gt; \n  mutate(\n    address = sprintf(\n      \"%s %s %s %s\",\n      unit, street, suburb, postcode\n      )\n  )\n\n# A tibble: 4 × 5\n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                 \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601     NA 1 McCoy Cct Acton …\n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;     NA 130 Garran Rd Acto…"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#stringrstr_c",
    "href": "post/2025-09-24-combining-strings/index.html#stringrstr_c",
    "title": "Joining strings with missing data together in R",
    "section": "stringr::str_c()",
    "text": "stringr::str_c()\nWe could use str_c() but we’ll have the same issues as we did with paste. Notice though that str_c returns NA if any of the input strings are NA.\n\naddresses |&gt; \n  mutate(\n    address = str_c(\n      unit, street, suburb, postcode,\n      sep = \" \"\n      )\n  )\n\n# A tibble: 4 × 5\n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                 \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601     &lt;NA&gt;                  \n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;     &lt;NA&gt;"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#stringrstr_flatten",
    "href": "post/2025-09-24-combining-strings/index.html#stringrstr_flatten",
    "title": "Joining strings with missing data together in R",
    "section": "stringr::str_flatten()",
    "text": "stringr::str_flatten()\nInterestingly, we can achieve the same result as unite() if we perform str_flatten() on a row-wise basis. I doubt this is a good idea though, as row-wise stuff tends to get very expensive, very quickly.\n\naddresses |&gt; \n  rowwise() |&gt; \n  mutate(\n    address = str_flatten(\n      c(unit, street, suburb, postcode),\n      collapse = \" \",\n      na.rm = TRUE\n      )\n  )\n\n# A tibble: 4 × 5\n# Rowwise: \n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                 \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601     1 McCoy Cct Acton 2601\n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;     130 Garran Rd Acton A…"
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#glueglue",
    "href": "post/2025-09-24-combining-strings/index.html#glueglue",
    "title": "Joining strings with missing data together in R",
    "section": "glue::glue()",
    "text": "glue::glue()\nglue is another option and arguably works better than paste or str_c because of the .na option letting us handle the NA within the function itself.\n\nlibrary(glue)\naddresses |&gt; \n  mutate(\n    address = glue(\n      \"{unit}\",\"{street}\",\"{suburb}\",\"{postcode}\",\n      .na = \"\",\n      .sep = \" \"\n      )\n  )\n\n# A tibble: 4 × 5\n  unit     street                       suburb   postcode address               \n  &lt;chr&gt;    &lt;chr&gt;                        &lt;chr&gt;    &lt;chr&gt;    &lt;glue&gt;                \n1 Shop 4   2 Frencham Pl                Downer   2602     Shop 4 2 Frencham Pl …\n2 Unit 185 20 Allara St                 Canberra 2601     Unit 185 20 Allara St…\n3 &lt;NA&gt;     1 McCoy Cct                  Acton    2601      1 McCoy Cct Acton 26…\n4 &lt;NA&gt;     130 Garran Rd Acton ACT 2601 &lt;NA&gt;     &lt;NA&gt;      130 Garran Rd Acton …\n\n\nAgain though, we’d need to trim the leading whitespace created."
  },
  {
    "objectID": "post/2025-09-24-combining-strings/index.html#summary",
    "href": "post/2025-09-24-combining-strings/index.html#summary",
    "title": "Joining strings with missing data together in R",
    "section": "Summary",
    "text": "Summary\nThere’s not much to say except use unite()!"
  },
  {
    "objectID": "post/2020-12-02-meet-the-dogs/index.html",
    "href": "post/2020-12-02-meet-the-dogs/index.html",
    "title": "Meet the dogs",
    "section": "",
    "text": "My happy little family at home consists primarily of noodle horses, or greyhounds as they’re more commonly known. We’ve got two greyhounds - Randy (13) and Cheeky (9). We hadn’t intended to adopt such old goobers, but that’s just how it turned out - we got Randy at 10, and we’ve only had Cheeky for a few months, but it feels like she’s been here for years too now."
  },
  {
    "objectID": "post/2020-12-02-meet-the-dogs/index.html#randy",
    "href": "post/2020-12-02-meet-the-dogs/index.html#randy",
    "title": "Meet the dogs",
    "section": "Randy",
    "text": "Randy\nRandy is my first son and I love him dearly. He’s wilful, loves chicken, and has old, creaky bones, but that doesn’t stop him from being a delight. He also obliges to being dressed up and having his photo taken:\n\nYou may have picked up the favicon I’ve used for this website - it’s a clipping from Randy’s Western photoshoot.\n(P.S if you live in Melbourne and want a silly pet picture we got these done through dog photog, they are hilarious and excellent.)"
  },
  {
    "objectID": "post/2020-12-02-meet-the-dogs/index.html#cheeky",
    "href": "post/2020-12-02-meet-the-dogs/index.html#cheeky",
    "title": "Meet the dogs",
    "section": "Cheeky",
    "text": "Cheeky\nAs her namesake suggests she is indeed Cheeky, doing everything in her power to get more food. I’m fairly certain someone replaced her stomach with a bag of holding, although I’m not sure how that would work with all the pooping. When we got Cheeky a few months ago, she had been living with the trainer who had raced her, but she’d only ever lived outside in the back yard. You could’ve fooled me though, she was immediately on the couch, forcing us to get a second couch just for her (the nice-old-lady-esque floral couch). She has a special affinity for cushions too:"
  },
  {
    "objectID": "post/2022-03-29-further-reflections-on-gender-identity/index.html",
    "href": "post/2022-03-29-further-reflections-on-gender-identity/index.html",
    "title": "Further reflections on gender identity",
    "section": "",
    "text": "It’s been quite a few months since I started thinking deeply about my own gender identity and not a week has gone by where I haven’t found myself pondering on it.\nRecently I started reading bell hooks’ “The Will to Change” and the first chapter has been eye-opening. I see the phrase “I feel seen” jokingly thrown around a lot, but having heard the first chapter I genuinely do feel seen. The discussion of patriarchy and patriarchal masculinity spoke to me so deeply. Her discussion of the socialisation of patriarchal masculinity, how from birth we are socialised - overtly and covertly - on what behaviours are ‘right’ and ‘wrong’ for boys, cut deep. It brought up such an incredibly vivid memory for me, of being in my early teens, maybe year 8 or 9 at school, and making the decision that I wasn’t going to cry any more. I’d always been a sensitive child and crying felt like a somewhat regular occurrence. At some point though I internalised the idea that boys don’t cry, so when I did cry there was this additional distress of violating this gender norm. Ultimately I decided that crying was not a thing for me any more. And I didn’t, I suppressed the urge and found myself less connected to my own emotions. That’s not to say I didn’t cry once in the last ~20 years, but the action indeed is a rarity and I find myself suppressing the urge to cry even today. It’s become such a default response, to suppress tears, that I often don’t realise I’m doing it.\nAnyway, the point about crying was just one thing out of many in the book that I really connected with. The notion though, that alternative forms of masculinity exist, has been a great thinking point for me. Annoyingly, it’s one of those bits of knowledge that when you hear for the first time you go “OF COURSE! HOW DID I NOT THINK OF THIS BEFORE!”, but I’m not going to beat myself up for not questioning decades of socialisation. Considering this new knowledge then, the next question is…"
  },
  {
    "objectID": "post/2022-03-29-further-reflections-on-gender-identity/index.html#what-does-masculinity-mean-to-me",
    "href": "post/2022-03-29-further-reflections-on-gender-identity/index.html#what-does-masculinity-mean-to-me",
    "title": "Further reflections on gender identity",
    "section": "What does masculinity mean to me?",
    "text": "What does masculinity mean to me?\nThe answer to this question is complicated and not fully formed yet, but it at least starts with disentangling masculinity from toxic masculinity. I need to spend some time thinking about what else masculinity means to me, aside from the stereotypical emotional coldness, physicality, aggression and dominance, or being ‘thick-skinned’. These are all the characteristics that I feel have been imprinted but never reflected who I actually was. So my goal for the next little while is to read up on alternative forms of masculinity. Realising that alternative forms of masculinity exist then got me wondering…"
  },
  {
    "objectID": "post/2022-03-29-further-reflections-on-gender-identity/index.html#am-i-actually-non-binaryagender",
    "href": "post/2022-03-29-further-reflections-on-gender-identity/index.html#am-i-actually-non-binaryagender",
    "title": "Further reflections on gender identity",
    "section": "Am I actually non-binary/agender?",
    "text": "Am I actually non-binary/agender?\nOr was this the only logical option at the time given I don’t relate at all to patriarchal imaginings of masculinity? As I said in the last post about gender identity, I was non-binary for the time being. Maybe I still am? I’m questioning whether I want a gender at all, or if gender is just a construct which we use to understand ourselves and relate to other people. For the time being, separating myself from what I originally understood masculinity to be is helping me to reflect on what else masculinity could be, at which point I’ll hopefully have a better understanding of whether I do indeed consider myself to be male, or just accept the masculine parts of myself as an agender person.\nPart of the struggle I have is that I feel like I have a poor imagination for what alternative masculinities could look like, that I want someone to give me a handbook of masculinities for me to pick from. This feeling is an odd one because I’ve always wanted to reject categorising people into boxes, so this desire to place my gender identity into a box is uncharacteristic. Does this feeling come from a desire to ‘fit in’ to a box? Is it just laziness and wanting to be told who I am instead of engaging in serious introspective thought? I’m not sure, but I definitely do need to engage in further introspection.\nAt the moment I’m seeking out more writing on the concept of masculinity, so if you have any suggestions on texts you think might be relevant please send me a link on Twitter. I’m currently reading work by Karla Elliott and Sam de Boise and Jeff Hearn, so I’ll see where this literature takes me."
  },
  {
    "objectID": "post/2025-02-18-joke/index.html",
    "href": "post/2025-02-18-joke/index.html",
    "title": "What did the psychic say before streaking across the pitch?",
    "section": "",
    "text": "All will be revealed"
  },
  {
    "objectID": "post/2025-10-31-ghost-gum-rstheme/index.html",
    "href": "post/2025-10-31-ghost-gum-rstheme/index.html",
    "title": "A new RStudio theme: Ghost Gum",
    "section": "",
    "text": "So I took a picture more than a year ago. I took it because I liked the colour palette of these logs and thought it would make a nice RStudio theme. Well, over a year later, I finally got the zoomies and did what I’d intended and made the theme! I’ve called it Ghost Gum, although I don’t think the logs are actually Ghost Gums. It’s a cool name and a cool tree though. Enjoy!\nYou can find the theme along with my others on GitHub (https://github.com/benharrap/rsthemes). If you want to have a go making your RStudio theme, check out the guide I made here. I’d suggest using the Ghost Gum theme as the starting template though, I tried to streamline some of the options so you don’t need to change the colour in so many locations.\n\n\n\n\n\nNice logs\n\n\n\n\n\n\nGhost Gum applied to code\n\n\n\n\n\n\n\nA Quarto document view"
  },
  {
    "objectID": "post/2022-02-10-rmarkdown-is-great/index.html",
    "href": "post/2022-02-10-rmarkdown-is-great/index.html",
    "title": "RMarkdown is great",
    "section": "",
    "text": "The title says it all really. RMarkdown, along with bookdown, has made my life so much easier when it comes to writing up papers and reports. If you’re a non-R user I hope this blog post convinces you to ditch other word processing software and make the jump to RMarkdown. It’s free!\nThis post was borne out of a tweet about using RMarkdown that seemed to be well received, and someone asked if there was a tutorial. There probably is already, but I figured I would write my own mini-guide on the things I do that make writing so much easier in RMarkdown. This isn’t going to be comprehensive but hopefully it gives you enough of an idea that if you run into trouble you can google your way out of it.\nBefore we get into why writing reports using RMarkdown is a no-brainer I want to preface that I am absolutely not an expert in R or RMarkdown and it’s quite possible there are smarter/cleaner/more efficient ways of doing everything here. What I will show you though is all the things that I think are really swell.\nI write all my documents and knit to PDF, so all my advice is based around this setup. No idea if it works the same if you knit to other formats. Also, there is some degree of assumed knowledge in this post, for example you know what it means to knit a document or what a code chunk is. If you’re unsure about what something means you can google it - this is how I learned most of my knowledge. If you are really stuck you can always send me a tweet. I can’t promise I can help but it’s possible.\nOne final caveat - I’m a Windows user. All this stuff is probably functionally the same on Mac but I couldn’t tell you so you might need to translate my Windows instructions into Mac. If you’re a linux user… Well you probably know how to do all of this anyway, or at the very least you’re a sucker for software punishment so will have no qualms googling your own problems.\nOk, time to get into the good stuff."
  },
  {
    "objectID": "post/2022-02-10-rmarkdown-is-great/index.html#stuff-that-made-my-life-easier",
    "href": "post/2022-02-10-rmarkdown-is-great/index.html#stuff-that-made-my-life-easier",
    "title": "RMarkdown is great",
    "section": "Stuff that made my life easier",
    "text": "Stuff that made my life easier\n\nFolder structure\nThis section isn’t required by the way, but starting out with a coherent and organised folder structure is nice. My brief stint in web development taught me a lot about directory structure, which is why I do things this way. It might not be super necessary but having a consistent way of organising things makes it easier to find what you’re looking for when you come back to a project after a year. There are plenty of resources out there on good folder structures, so I won’t spend too long here. Below is a toy example of what a nicely organised project folder might look like:\n2022-02-10-chapter-3\n- code\n    analysis.R\n    cleaning.R\n- data\n  - raw-data\n      original_data.csv\n  clean-data.csv\n- img\n    histogram.pdf\n    survival-curve.pdf\n- meetings\n    2022-02-10.txt\n- tab\n    summary-stats.csv\n    interactions.csv\nchapter-3.Rproj\ncitation.csl\nreferences.bib\nwriteup.Rmd\nwriteup.pdf\nI have separate folders for my code, data, images, meeting notes, and tables. Then in the main directory I have the R project file, my references, and my RMarkdown file with the write up in it. I do often end up with other random files in the folder that I don’t have a home for and that’s fine, but at least most things have a home. This is what works for me, if it doesn’t work for you, you do you.\nI always start each project by making a new folder where I’m planning to keep everything and name it using the convention “yyyy-mm-dd-project-name”. The date being the date on which I created the folder, and doing so means alphanumerically sorting the folders also sorts them chronologically. Nice!\n\n\nWorkflow\nThis section is where the basis for the magic begins. Getting this right is critical to automating the numbers, tables, and figures in your write up.\nI try my best to split my code up into different .R files depending on what I’m doing, with each subsequent file starting off with the data produced at the end of the previous file. This means if you need to edit something during the cleaning phase you can do so, and as long as you haven’t done anything drastic, your changes shouldn’t break anything downstream. The order I tend to follow in my code is:\n\nGetting the data together\n\nFor my thesis I work with multiple linked datasets, each contained in their own .csv file. For an analysis I might need to use information from births data, deaths data, and child protection data. So the first thing I do is get all my data together. This usually just means running a bunch of read_csv() commands to get all the datasets in that I need.\n\nCleaning the data\n\nNext I look through each dataset and make sure it contains what I think it should, doesn’t contain any nonsensical values (e.g. negative ages), and fix any errors that I come across. For me, cleaning the data means only working with the existing variables and values in the dataset, distinct from making new variables which I do in the next section.\n\nPreparing the data\n\nI suppose ‘preparing’ the data is just another type of cleaning, but I like to call them different things because it helps separate out the two processes. By preparing data I mean creating new variables or datasets based on the result of the cleaning stage. This could be performing a bunch of joins, reshaping your data from wide to long, making composite variables. The goal of this section is to end up with the variables and datasets that you need for your analysis.\n\nAnalysing the data\n\nThis is arguably the exciting section, where you get to fit your models, plot your graphs, create your summary tables. Anything that you plan to include in the write up of your analysis should be saved as a distinct file. This means any tables or figures should be saved in the folders you made for them (see @Folder Structure). By doing this you don’t have to re-run the entirety of your code when you come back to work on your write up.\n\nWriting up\n\nIdeally all your analysis is done and all you need to do is write up the results. Assuming each of the previous stages has gone well, the tips in the next few sections should make writing up a little less painful.\n\n\nEasy citations\nHave you been terrorized by EndNote? Is Mendeley telling you the MS Word addin is not installed even though you’ve installed it three times? Has Zotero … well I don’t know anything about Zotero but every software has its bugs. Anyway, ditch the citation management software, we’re doing hipster references now. (Note: you don’t have to ditch your reference management software, see my final comment in this section)\nThe end goal of using RMarkdown (or is it bookdown? I don’t know) for citations is to reduce the burden of keeping track of your in-text references, adding them to the bibliography, and getting the formatting of your references correct. All you need to do is keep your references file up to date.\nSo to start, you need to make a references file. If you currently have all your references in one of the aforementioned software then you will need to export it to a .bib file. Some of them already store references in this file format anyway so it’s no trouble, others you will need to figure out how to export as a .bib. One way or another you need to have a .bib file. Fortunately, if you’re not sure how to export your existing references list google will have the answer.\nIf you’re starting from scratch, open up your project folder, right-click and make a new text file. Edit the name and call it references.bib, making sure to delete the .txt so it’s called references.bib not references.bib.txt. If you can’t delete the .txt extension you might need to change your explorer settings to allow you to do so.\nOk so you have your shiny new references.bib. Now we need to add citations to it. Every journal’s website has some way of exporting citations as a .bib. Some journals make it way too complicated for my liking, but it is possible. When you’re on the page of the article that you want to cite, find the ‘Cite this’ button and click ‘Export as .bib’ or whatever sounds like it’ll give you a .bib file. It could also say ‘export as BibTeX’, since .bib is the file extension for BibTeX files. This is what it looks like on Elsevier’s website:\n\nIf it’s not possible, you can always go to Google Scholar, search for the article, and get the citation that way. I usually do this if I forgot to download the citation at the same time as I downloaded the article or if it’s a report or something from ‘grey literature’. The latter reason makes Google Scholar quite handy as it saves you from having to manually create the citation. Below is what you need to click on in Google Scholar to get a BibTeX citation.\n\nOnce you have your citation the next step is to put it in your references.bib file. All you need to do is copy and paste it from the file you just downloaded (or directly from the browser if you used Google Scholar). I like to use Notepad to open my references file because I’m a reference hipster but you can open it in RStudio too. I should probably do this but Notepad does the job and I like it. You can paste the citation anywhere in your references file as long as it’s not inside of another citation. RMarkdown will let you know if there’s a problem with your references file anyway, so if you make a boo-boo you’ll hear about it. I did try to keep my references file in alphabetical order by first author’s last name, but it got out of hand pretty quickly and now it’s a jumbled mess. Fortunately CTRL + F exists so who cares. Here’s a snippet from my references.bib for my PhD thesis.\n\nNext we have an example of a citation, the very first publication I was an author on.\n@article{eaton2019,\n  title={Incidence of treated first episode psychosis from an Australian early intervention service and its association with neighbourhood characteristics},\n  author={Eaton, Scott and Harrap, Benjamin and Downey, Linglee and Thien, Kristen and Bowtell, Meghan and Bardell-Williams, Melissa and Ratheesh, Aswin and McGorry, Patrick and O'Donoghue, Brian},\n  journal={Schizophrenia Research},\n  volume={209},\n  pages={206--211},\n  year={2019},\n  publisher={Elsevier}\n}\nNote at the beginning of the citation immediately after the opening bracket { it says eaton2019. This string is what you will use when citing that article in the text of your RMarkdown document. Pick a convention for this string and stick to it so you don’t need to keep looking through your reference file to find the name you gave to the citation. My preference is first author’s last name and year of publication. If they have multiple publications in a year I just put a/b/c at the end of each publication to distinguish them as you can’t have two citations with the same name.\nWith your references.bib filled in and ready to go, now you need to make your citations in text. Every citation begins with the @ symbol followed by the string for the article you want to cite. In the above example recall it was eaton2019 so in our RMarkdown text we would type something like @eaton2019 found... or greater incidence of first episode psychosis [@eaton2019]. Note the use of square brackets in the second example.\n@eaton2019 found... becomes “Eaton et al. (2019) found…”\nwhereas\ngreater incidence of first episode psychosis [@eaton2019] becomes “greater incidence of first episode psychosis (Eaton et al. 2019)”\nNow you know how to add citations to your references file, add everything you read in there. It doesn’t matter if it’s full of unused citations, only the ones you cite in text will appear in your references list.\nThere are two final pieces to this puzzle. The first is the citation format. Depending on the requirements of the journal you’re submitting to, or professor you’re writing an assignment for, download the appropriate csl file for the citation format. You can find an enormous list of csl files on Zotero’s website, which is where the bookdown authors suggest you look.\nThe beauty of being able to switch your citation style by changing one line of code brings a tear to my eye. If only I knew about this in my undergraduate degree, I wouldn’t have missed those couple of marks for correct formatting. You do need to tell RMarkdown to use the csl file though, so in the header of your document you need to include the following code\nbibliography: \"references.bib\"\ncsl: \"harvard-the-university-of-melbourne.csl\"\nThe second piece is to tell RMarkdown where you want your reference list to go. Just place the following bit of code where you want your references to go and it’ll get populated when you knit the document.\n&lt;div id=\"refs\"&gt;&lt;/div&gt;\nThat’s it!\nOne final comment here is that you can stick with your existing reference management software - as long as you’re able to define the citation string (that first bit of text in the BibTeX reference) and export your reference list to a .bib file. If you can’t manually define that string you’ll find the default is something absolutely bonkers you’ll never remember, like S0022283665802716.\nI prefer to manually manage my references because ultimately it doesn’t matter how it’s ordered. I just stick every citation for everything I read into my references.bib file and when it comes to writing up, everything I’ve read is ready to be cited.\n\n\nAutomatic numbering for tables and figures\nPicture this - you’ve finished your first draft and there’s a smattering of tables and figures. For each table and figure you manually wrote out its number based on where it appears in the article and each of them is referred to multiple times throughout the text. Your collaborator gives you feedback that Figure 3 should come earlier in the article, Table 5 is unnecessary, and maybe Figure 4 should go in the appendix. Great! But now you have to go back and change their numbers and make sure your in-text references match these new numbers.\nThis is a horrible job and very much error-prone. We’re human after all. Fortunately bookdown can take care of the numbering for you.\nThe first thing you need to do is set the output in the header to pdf_document2. If you are knitting to a regular pdf the automatic numbering doesn’t work. You should have something like this in the header:\noutput:   \n  bookdown::pdf_document2\nNext, you need to give a name to each code chunk that you want to include in your text. For consistency you could name all the code chunks in your document but I only bother if it’s a table or figure I’m including in the text. In the below example I have a couple of summary tables from my beer spreadsheet. Notice in the code chunks below I have called the two tables rating and prior, which is what we’ll use for our referencing.\n{r rating}\nkable(rating, caption = \"Average cost and rating by style\")\n\n\n\nAverage cost and rating beer by style\n\n\nStyle\nPrice\nRating\n\n\n\n\nWild Ale\n5.50\n3.0\n\n\nDouble Neipa\n9.00\n2.0\n\n\nAmerican Ipa\n10.00\n2.0\n\n\nBrown Ale\n13.44\n3.3\n\n\nBelgian Tripel\n5.00\n1.0\n\n\n\n\n\n{r prior}\nkable(prior, caption = \"Average rating by number of beers consumed prior\")\n\n\n\nAverage rating by number of beers consumed prior\n\n\nBeers\nRating\n\n\n\n\n0\n2.6\n\n\n1\n2.7\n\n\n2\n2.5\n\n\n3\n2.5\n\n\n4+\n2.4\n\n\n\n\n\nHopefully you noticed these tables were already assigned numbers - the rating by style is Table 1 and the rating by number of beers prior is Table 2. I didn’t assign these numbers, they were automatically assigned for me. So how do we automate the in-text numbers? You simply use the code @\\ref(tab:&lt;your chunk name here&gt;), replacing the angle brackets with the name of your chunk that has the table in it. So if I were to reference the two tables above I’d use Table @\\ref(tab:rating) and Table @\\ref(tab:prior). Note that you still need to write out ‘Table’ beforehand, the reference only grabs the number.\nThe above method for tables is basically the same for figures too, you instead use @\\ref(fig:&lt;your chunk name here&gt;) - note ‘fig’ has replaced ‘tab’ in the round brackets.\nOne nuance I found is that the name of your code chunk is important. For example I called a chunk interactions_all and the auto-numbering did not work, it instead spat out @\\ref(fig:interactions_all) in the text. I renamed the chunk to all and updated the reference accordingly and it worked fine. Maybe it was an issue with the length of the name, maybe it was the underscore. I’m sure if I read the bookdown manual I’d understand why but who has time to read the manual, right!?\n\n\nAutomatic in-text numbers\nTyping in the numbers from your analysis is error prone - we’ve already established that we’re all human. Also, it’s a massive pain in the ass if you need to update everything because of changes to your code. Maybe your cohort is smaller now so all of your descriptive statistics changed, but instead of putting them in a table (like the previous section), you typed them into the body of your article. Well, RMarkdown allows you to do in-text R code too, as we’ll demonstrate.\nstats &lt;- beer %&gt;% \n  summarise(litres = round(sum(Ml)/1000),\n            minabv = min(Abv),\n            maxabv = max(Abv))\nIn the code above we made a few summary statistics and saved them in a dataframe called stats. If we want to insert them into the text, we just need to write some inline R code. For example, over the course of my beer recording adventures I consumed 131 litres of beer, with the least alcoholic beer coming in at 0.4% and the most alcoholic at 13%. The inline code I included for these three statistics were\n` r stats$litres`\n` r stats$minabv`\n` r stats$maxabv`\nFor the latter two, I included the percentage symbol immediately after the closing backtick to have it attached to the number. Also, in the three examples note the space between the first backtick and the ‘r’. This shouldn’t be there - I just had to include the space otherwise the code gets evaluated and you would see the numbers instead of the code."
  },
  {
    "objectID": "post/2022-02-10-rmarkdown-is-great/index.html#minor-gripes",
    "href": "post/2022-02-10-rmarkdown-is-great/index.html#minor-gripes",
    "title": "RMarkdown is great",
    "section": "Minor gripes",
    "text": "Minor gripes\nOk so BIIIIIIIIIG preface here that it’s highly likely that the stuff in this section is actually doable in R, it’s just these annoyances are so minor that I don’t mind my current way of overcoming them. For example, I use MS Word to get a word count but I just googled to see if you can get a word count in R and it turns out there’s a package called wordcountaddin. Not sure if I’ll use this package but it illustrates my point. I can’t think of a time I’ve not been able to find a package that does the thing that I need.\n\nSpell checking\nThe spell check function in RStudio is handy for picking up some spelling errors (duh) but there’s no checking for grammar, so my current method of doing a grammar check is to open the knitted PDF using MS Word. Just open up Word, click File -&gt; Open, then open the PDF and Word will do its best to translate the file into a Word document. Usually this works fine and often picks up an issue here or there that needs fixing. Note this isn’t a substitution for actual proof-reading - still do this! Apologies to non-Word users, not sure how you would do it without Word but I’m sure there’s a way.\n\n\nWord count\nWhen I’ve got the document open in Word I also do the word count. Criteria for word counts vary from journal to journal, with some including tables, some excluding, references do or don’t count. Anyway, I just delete all the non-contributing content and get my word count that way. Not the most efficient approach but it’s not painful and it works.\n\n\nFiguring stuff out is hard\nSometimes things break, or I can’t get them the way I want them to work, and it takes me ages to figure stuff out. Initially I would cringe at the thought of it taking me days to figure out how to make a table using R, when I could just make it in two minutes in MS Word. However I have spend countless hours over the past few years updating the same table over and over again due to changes in the data. Taking two days to learn how to make those tables in R would have saved me many more days of work in the long run. Having drunk the kool-aid I am now delighted that it took me three hours to figure out how to add an extra row to a table header.\nThe point I want to make is that if you are reading this blog post and trying to follow along and things don’t make sense or don’t work, don’t worry. You’ll figure it out eventually, this is just the process of learning something that is actually quite challenging to pick up."
  },
  {
    "objectID": "post/2022-02-10-rmarkdown-is-great/index.html#acknowledgements",
    "href": "post/2022-02-10-rmarkdown-is-great/index.html#acknowledgements",
    "title": "RMarkdown is great",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nTo write this blog post I used R (R Core Team 2021), RMarkdown (Allaire et al. 2021), knitr (Xie 2014), and tidyverse (Wickham et al. 2019)."
  },
  {
    "objectID": "post/2022-02-10-rmarkdown-is-great/index.html#references",
    "href": "post/2022-02-10-rmarkdown-is-great/index.html#references",
    "title": "RMarkdown is great",
    "section": "References",
    "text": "References\nHey look, here’s a reference list that was generated automatically thanks to RMarkdown!\n\n\nAllaire, J, Xie, Y, McPherson, J, Luraschi, J, Ushey, K, Atkins, A, Wickham, H, Cheng, J, Chang, W & Iannone, R 2021, Rmarkdown: Dynamic documents for r, accessed from &lt;https://github.com/rstudio/rmarkdown&gt;.\n\n\nEaton, S, Harrap, B, Downey, L, Thien, K, Bowtell, M, Bardell-Williams, M, Ratheesh, A, McGorry, P & O’Donoghue, B 2019, “Incidence of treated first episode psychosis from an australian early intervention service and its association with neighbourhood characteristics,” Schizophrenia Research, vol. 209, pp. 206–211.\n\n\nR Core Team 2021, R: A language and environment for statistical computing, R Foundation for Statistical Computing, Vienna, Austria, accessed from &lt;https://www.R-project.org/&gt;.\n\n\nWickham, H, Averick, M, Bryan, J, Chang, W, McGowan, LD, François, R, Grolemund, G, Hayes, A, Henry, L, Hester, J, Kuhn, M, Pedersen, TL, Miller, E, Bache, SM, Müller, K, Ooms, J, Robinson, D, Seidel, DP, Spinu, V, Takahashi, K, Vaughan, D, Wilke, C, Woo, K & Yutani, H 2019, “Welcome to the tidyverse,” Journal of Open Source Software, vol. 4, no. 43, p. 1686.\n\n\nXie, Y 2014, “Knitr: A comprehensive tool for reproducible research in R,” in V Stodden, F Leisch, & RD Peng (eds), Implementing reproducible computational research, Chapman; Hall/CRC."
  },
  {
    "objectID": "post/2023-10-20-joke/index.html",
    "href": "post/2023-10-20-joke/index.html",
    "title": "How did the vegetable gardener lower their taxable income?",
    "section": "",
    "text": "Celery sacrifice"
  },
  {
    "objectID": "post/2025-01-10-stata-to-r/index.html",
    "href": "post/2025-01-10-stata-to-r/index.html",
    "title": "Switching from Stata to R",
    "section": "",
    "text": "Making the transition from Stata to R can be challenging as the two languages are different in some fundamental ways. My initial training in biostatistics was using Stata, however I made a concerted effort to learn R by doing my entire PhD using the language. There are some things that I still struggle with in R that I found a lot easier in Stata, but that’s ok - we’re all still learning!\nThis post acts as a reference to provide Stata and R code side-by-side to help people switching between the two languages. There’s a few things to note before diving in:"
  },
  {
    "objectID": "post/2025-01-10-stata-to-r/index.html#workflow-differences",
    "href": "post/2025-01-10-stata-to-r/index.html#workflow-differences",
    "title": "Switching from Stata to R",
    "section": "Workflow differences",
    "text": "Workflow differences\nI’ll briefly outline some important things to know when switching from Stata to R, because while R can do everything Stata can do, it goes about it differently.\n\nPackages\nPackages are the reason that R is such a powerful tool. Packages can be thought of as a collection of functions, typically centered around a particular theme or method. Base R is refers to the functions included by default when you install R on your machine. The main thing to know with R packages is that if you can imagine a function, someone’s probably already written a package for it.\nI personally find that base R code can be quite arcane to read, which is why I’m such a tidyverse fan. The tidyverse is a collection of packages that is incredibly popular and for good reason; the design of the packages share consistent philosophy around how code should be written (see their website if you want to learn more).\nTo install R packages just run install.packages(\"&lt;package name&gt;\"). To use the package, run library(&lt;package name&gt;) to load in all the functions from that package into your current R session.\nYou can also use specific functions from packages by loading the functions in specifically (using include.only), or by explicitly calling the function without loading the package (using ::), demonstrated in the example below.\n\nLoad specific functionCall function without loading\n\n\nlibrary(haven, include.only = \"read_dta\")\nauto &lt;- read_dta(\"/Applications/Stata/auto.dta\")\n\n\nauto &lt;- haven::read_dta(\"/Applications/Stata/auto.dta\")\n\n\n\n\n\nMultiple datasets\nStata can sort of do this but nothing like how R does. Instead of using frame to create and manage multiple in-memory datasets and frame change to switch between datasets, you can just load multiple datasets into R, assign them names, and simply call these names when going about your work, no explicit switching required. I won’t go into detail here as you’ll very quickly figure this out as you start to use R, but I think it’s one of the greatest advantages of R over Stata.\n\n\nPipes\nUsing the auto dataset as an example, say we wanted to create a dataset of only domestic cars and analyse their weight to length ratio by brand. In Stata, each line of your code would be executed sequentially and independently with the results window returning something after each step:\nsysuse auto\ndrop if foreign == 1\ngen wgt_len_ratio = weight/length\ngen brand = substr(make, 1, ustrpos(make, \" \")-1)\nsort brand\nby brand: summarize wgt_len_ratio\nYou can write R code in this fashion too but there’s something nice about using pipes. You can think of pipes as literal pipes, you put something in at one end of the pipe and something comes out the other end. In our case, data goes in one end, your code is what happens inside of the pipe, and the result of your code is what comes out the other end. In R there’s two different pipes, the base pipe |&gt; and the magrittr pipe %&gt;%. You probably don’t need to worry about the difference for now, but for those interested see this post on the tidyverse website.\nThe same operation as above in R could be done as:\nauto &lt;- haven::read_dta(\"/Applications/Stata/auto.dta\")\n\nauto |&gt; \n  filter(foreign == 0) |&gt; \n  mutate(\n    wgt_len_ratio = weight/length,\n    brand = str_extract(make, \"\\\\w+\")\n    ) |&gt; \n  group_by(brand) |&gt; \n  summarise(\n    n = n(),\n    mean = mean(wgt_len_ratio),\n    sd = sd(wgt_len_ratio),\n    min = min(wgt_len_ratio),\n    max = max(wgt_len_ratio)\n  )\nIt’s a little longer in length than the Stata example, however I find pipes and tidyverse in particular make the code more readable and easier to follow and navigate (the indentations also help). The auto dataset goes in to the start of the pipe, we perform some operations to it, and the output of the pipe is the summary we wanted.\n\n\nAssigning output\nOne of the main things to adjust to in R is the need to assign your output. In Stata, if you were to create a new variable, you would just write gen new_var = old_var*2 and it would automatically create new_var in the current dataset. Similarly, if you run a regression model, Stata stores a bunch of information in the background that you can access, such as via the lincom and margins functions.\nIn R, the default is to display the output of your code in the console (similar to Stata’s results window). So if you were to run auto |&gt; mutate(new_var = 1) it would just print the result in the console. Instead, you need to assign the output using the assignment operator &lt;- to an object, either an existing or a new one. For example:\n\nauto &lt;- auto |&gt; mutate(new_var = 1) writes over the object named auto, which is our dataset\nauto_new &lt;- auto |&gt; mutate(new_var = 1) creates a new object called auto_new and leaves the original auto object unchanged\n\nIn the example where we calculated summary statistics by car brand, if you were to run the R code it would simply output the summary statistics in the console. If you wanted to do something with the summary statistics later, you would assign the output.\nOne aspect of this feature is that it completely circumvents the need for Stata’s preserve and restore. Just assign the output of your code to a new object where you would instead have used preserve and restore. This makes it handy for analyses of data at different stages of cleaning or analysis.\n\n\nFurther resources\nThe resources I would recommend for learning more R are:\n\nR for Data Science\nAdvanced R\nggplot2: Elegant Graphics for Data Analysis\nFundamentals of Data Visualization\n\nNote that Fundamentals of Data Visualization doesn’t include the R code by default. Instead, Claus provides a link on the welcome page to the book’s GitHub repo, which you can search through to find the code to replicate the graphs in the book."
  },
  {
    "objectID": "post/2025-01-10-stata-to-r/index.html#converting-stata-to-r-code",
    "href": "post/2025-01-10-stata-to-r/index.html#converting-stata-to-r-code",
    "title": "Switching from Stata to R",
    "section": "Converting Stata to R code",
    "text": "Converting Stata to R code\nI’ve included the functions that I use most commonly in my work, however there’s many more functions out there, and many arguments within these functions! The best thing you can do is read the documentation for the functions you’re using. If you get stuck it’s time to head to google!\n\nModifying variables\nA lot of data cleaning work involves modifying or creating variables in some way. In the tidyverse, variables are typically created or modified using the mutate() function.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nStata\nR\nNote\n\n\n\n\nMaking/modifying variables\ngen weight_kg = weight/2.205\nmutate(weight_kg = weight/2.205)\nmutate overwrites existing variables without warning, unlike Stata\n\n\nMake a string variable numeric\ndestring price\nmutate(price = as.numeric(price)\nPrice is already a numeric variable, you get the idea though. as.numeric is a base R function\n\n\nMake a numeric variable into a string\ntostring price\nmutate(price = as.character(price)\nas.character is a base R function\n\n\nMake a variable missing\ngen new_var = .\nmutate(new_var = NA)\nRemember that Stata treats missing values as large positive numbers? Yeah R doesn’t do that\n\n\nCreate a variable using conditions\ngen price_10k = 0 then replace price_10k = 1 if price &gt;=10000\nmutate(price_10k = case_when(price &gt;= 10000 ~ 1, .default = 0))\ncase_when() can be used for many of the functions in egen too\n\n\n\n\n\n\n\n\n\nOther basics\nThese functions are more about performing other operations to datasets than changing or modifying variables.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunction\nStata\nR\nNote\n\n\n\n\nRenaming variables\nrename weight weight_lbs\nrename(weight_lbs weight)\nThe arguments are back to front in R. Stata is &lt;current name&gt; &lt;new name&gt;, dplyr is &lt;new name&gt; &lt;current name&gt;\n\n\nDropping variables\ndrop mpg\nselect(-mpg)\nThe minus is what drops the variable. Without the minus it would instead keep only mpg\n\n\nDropping observations\ndrop if foreign == 1\nfilter(foreign != 1)\nFilter keeps observations that meet criteria, rather than drops them, hence the inverse condition\n\n\nReshaping wider\nreshape wide mpg, i(make) j(turn)\npivot_wider(names_from = ‘turn’, values_from = ‘mpg’)\n \n\n\nReshaping longer\nreshape long rep, i(make) j(newvar)\npivot_longer(c(rep78,rep79), values_to = ‘newvar’)\nTo run this example, first create rep79, which I created as rep78+1\n\n\nSummarising data\nsummarize mpg\nsummarise(obs = n(mpg), mean = mean(mpg), stddev = sd(mpg), min = min(mpg), max = max(mpg)\ndplyr treats summarise and summarize as synonyms, so use whichever you prefer.\n\n\nGrouping operations\nby foreign:\ngroup_by(foreign)\nYou would use group_by() in the line before the operation that you want to apply the grouping to. Once you no longer need the grouping to be in place, use ungroup(), otherwise all subsequent operations will be grouped\n\n\nSeed setting\nset seed 1234\nset.seed(1234)\n \n\n\n\n\n\n\n\n\n\nRegression\nThe correspondences here represent the models that you need to run to generate (usually) the same results, not the code that will produce the same output. If you simply run the R code it will output something minimal, instead you will want to assign the model to an object. For the linear regression example, this would be model &lt;- lm(price ~ mpg, data = auto) followed by using the summary function on that object summary(model).\nI say ‘usually’ the same results because for some methods there seems to be some minor difference under the hood that means estimates differ slightly. For example, in the negative binomial example the standard errors for mpg are different at the 4th decimal. Always check your outputs :)\nFinally, I only include some basic regression models here. In epidemiology we often need to deal with observations that aren’t independent, such as in longitudinal studies. Methods such as generalised estimating equations (GEEs) and mixed effects models are supported in R. For GEEs, see the gee package (link). For mixed effects models, the lme4 (link) is popular.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel\nStata\nR\nNote\n\n\n\n\nSimple linear regression\nreg price mpg\nlm(price ~ mpg, data = auto)\n \n\n\nLogistic regression\nlogit foreign mpg\nglm(foreign ~ mpg, data = auto, family = \"binomial\")\n \n\n\nPoisson regression\npoisson rep78 mpg\nglm(rep78 ~ mpg, data = auto, family = \"poisson\")\n \n\n\nNegative binomial regression\nnbreg displacement mpg\nMASS::glm.nb(displacement ~ mpg, data = auto)\nRequires the MASS package"
  },
  {
    "objectID": "post/2025-01-10-stata-to-r/index.html#data-visualisation",
    "href": "post/2025-01-10-stata-to-r/index.html#data-visualisation",
    "title": "Switching from Stata to R",
    "section": "Data visualisation",
    "text": "Data visualisation\nAnother great feature of R is ggplot2, the tidyverse package used to create plots. There are so many ways to customise plots using ggplot2 that I won’t cover them here - check out the documentation if you want to learn more.\nNote that some of these plots don’t make any sense, it’s just to demonstrate the code.\n\nHistograms\n\nauto |&gt;\n  ggplot(aes(x = weight)) +\n  geom_histogram() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nDensity plots\n\nauto |&gt;\n  ggplot(aes(x = weight)) +\n  geom_density() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nBar charts\n\nauto |&gt;\n  ggplot(aes(x = headroom, y = rep78)) +\n  geom_col() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nLine charts\n\nauto |&gt;\n  ggplot(aes(x = weight, y = length)) +\n  geom_line() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nScatter plots\n\nauto |&gt;\n  ggplot(aes(x = weight, y = length)) +\n  geom_point() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nBox plots\n\nauto |&gt;\n  ggplot(aes(x = foreign, y = price, group = foreign)) +\n  geom_boxplot() +\n  theme_bw()\n\n\n\n\n\n\n\n\n\n\nViolin plots\n\nauto |&gt;\n  ggplot(aes(x = foreign, y = price, group = foreign)) +\n  geom_violin() +\n  theme_bw()"
  },
  {
    "objectID": "post/2025-01-10-stata-to-r/index.html#customising-data-visualisations",
    "href": "post/2025-01-10-stata-to-r/index.html#customising-data-visualisations",
    "title": "Switching from Stata to R",
    "section": "Customising data visualisations",
    "text": "Customising data visualisations\nThe different plots are outlined above but you will probably want to customise them further so they look nice. I already did some theming with theme_bw() but we can do more than that. Note my preference for theme_bw() over theme_minimal() (another popular theme) stems from the fact that theme_bw() has a white background, while theme_minimal() has a transparent background, which causes problems in some circumstances.\nTo make changes to elements of a plot you add things to it with the + symbol. In the examples above I specify the ggplot2 aesthetics, what kind of plot (the geom_* part), and finish with the theme. These components are connected with the + symbol.\nSince ggplot2 is so heavily customisable, I won’t go into too much detail here except to provide code that demonstrates some of the common things you’d want to do to a plot.\n\nauto |&gt;\n  ggplot(aes(x = weight, y = length, colour = factor(foreign))) +\n  geom_point(\n    size = 4, # This changes the size of the dots\n  ) +\n  scale_x_continuous(\n    name = \"Weight (lbs)\", # The axis title\n    labels = scales::label_comma(), # Adds a comma to the axis, using the scales package\n    limits = c(1500,5000), # The limits of the axis\n    breaks = seq(1500,5000,500), # Change main grid lines, which is where labels appear\n            # seq() specifies we want them to go from 1000 to 6000 in increments of 500\n    minor_breaks = NULL, # Turn off the smaller grid lines\n  ) +\n  scale_y_continuous(\n    name = \"Length (inches)\",\n    limits = c(140, 240),\n    breaks = seq(140,240,10),\n    minor_breaks = NULL\n  ) +\n  scale_colour_manual(\n    name = \"Car origin\", # Changes the legend name\n    values = c(\"red\",\"blue\"), # Set the colour of the points\n    labels = c(\"Domestic\",\"Foreign\") # Change the legend label names\n  ) +\n  theme_bw() +\n  theme(\n    text = element_text(\n      family = \"serif\", # Change the font of the plot\n      size = 16, # Change the text size\n      ),\n    legend.position = \"bottom\" # Change where the legend is\n    )"
  },
  {
    "objectID": "post/two-more-rsthemes/index.html",
    "href": "post/two-more-rsthemes/index.html",
    "title": "Two new RStudio themes",
    "section": "",
    "text": "Sometimes you see a picture and think to yourself “oh I like the colour composition here”. Well when I think that, I also think “this would make a great RStudio theme”. So I’ve created two more RStudio themes!\nI’ve renamed my original noodle repository, where I kept the first theme I created, to rsthemes since it made sense to keep all of the themes I’ve made together. You can find it here: https://github.com/benharrap/rsthemes"
  },
  {
    "objectID": "post/two-more-rsthemes/index.html#knitted",
    "href": "post/two-more-rsthemes/index.html#knitted",
    "title": "Two new RStudio themes",
    "section": "Knitted",
    "text": "Knitted\nThe knitted theme came from a jumper that I got for my kid. My partner and I were at a market for locally made goods and came across this stand where a nanna was selling little knitted jumpers that she made. It was the coolest jumper I’d ever seen and I wish she made them in adult sizes too. There’s no point trying to describe it, just take a look. I love the bright colours in the jumper and the pale colours looked like they’d work as a background, so I turned it into an RStudio theme. I’m pretty happy with the results!\n\n\n\n\n\nThe incredible jumper\n\n\n\n\n\n\nThe knitted theme applied to code\n\n\n\n\n\n\n\nThe knitted theme applied to RMarkdown"
  },
  {
    "objectID": "post/two-more-rsthemes/index.html#corymbia",
    "href": "post/two-more-rsthemes/index.html#corymbia",
    "title": "Two new RStudio themes",
    "section": "Corymbia",
    "text": "Corymbia\nI was out for a walk in Canberra’s botanic gardens and walked past this beautiful plant, later identified by my dad as corymbia ficifolia. It’s an Australian native with gorgeous blooms. While I’d already walked past it I thought it was such a lovely colour scheme that I went back to snap a picture.\n\n\n\n\n\nCorymbia ficifolia\n\n\n\n\n\n\nThe corymbia theme applied to code\n\n\n\n\n\n\n\nThe corymbia theme applied to RMarkdown"
  },
  {
    "objectID": "post.html",
    "href": "post.html",
    "title": "Posts",
    "section": "",
    "text": "What is the sheep’s favourite graph?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nNov 5, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nA new RStudio theme: Ghost Gum\n\n\n\n\n\n\ncode\n\nR\n\ndesign\n\n\n\n\n\n\n\n\n\nOct 31, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nHow did the geologist carry their books to school?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nOct 30, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat the hell is networking?\n\n\n\n\n\n\nacademia\n\nwork\n\ncommunity\n\n\n\n\n\n\n\n\n\nOct 29, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nI can only play in your back yard if you invite me in\n\n\n\n\n\n\nacademia\n\nprogramming\n\nstatistics\n\n\n\n\n\n\n\n\n\nOct 10, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nUsing R to extract results from Stata log files\n\n\n\n\n\n\nR\n\nStata\n\nprogramming\n\n\n\n\n\n\n\n\n\nSep 24, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nJoining strings with missing data together in R\n\n\n\n\n\n\nR\n\nprogramming\n\nstrings\n\n\n\n\n\n\n\n\n\nSep 24, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did the doctor prescribe Dumbo to help with his pain?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nAug 6, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhy don’t statisticians like getting feedback?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nJul 28, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nMy gardener friend crossbred cauliflower and watermelon and it was the saddest plant I’ve ever seen\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nJul 23, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nNot all missings are created equal\n\n\n\n\n\n\nR\n\nprogramming\n\n\n\n\n\n\n\n\n\nJul 14, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nAn R function for pronouns\n\n\n\n\n\n\nR\n\nprogramming\n\nquarto\n\n\n\n\n\n\n\n\n\nJun 12, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\ntidyverse functions you might not know about\n\n\n\n\n\n\nR\n\nprogramming\n\ndata\n\n\n\n\n\n\n\n\n\nMay 23, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nHow did Francis pay for his ticket to heaven?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nApr 28, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nA big ask: doing literally anything apparently\n\n\n\n\n\n\nself\n\nacademia\n\n\n\n\n\n\n\n\n\nMar 29, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat makes a good variable naming convention\n\n\n\n\n\n\nsurvey design\n\nR\n\ncode\n\nresearch\n\n\n\n\n\n\n\n\n\nMar 3, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did Euclid say when Dante asked about his bronzed complexion?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did the psychic say before streaking across the pitch?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nHow can you tell that statisticians love Vietnamese food?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nFeb 17, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nSwitching from Stata to R\n\n\n\n\n\n\ncode\n\nR\n\nStata\n\nresearch\n\n\n\n\n\n\n\n\n\nJan 10, 2025\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nIncluding your publications on your Quarto website\n\n\n\n\n\n\nquarto\n\nR\n\nacademia\n\n\n\n\n\n\n\n\n\nDec 18, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nMigrating from blogdown/Hugo to Quarto\n\n\n\n\n\n\nquarto\n\nR\n\n\n\n\n\n\n\n\n\nDec 16, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nReflecting on my PhD experience\n\n\n\n\n\n\nacademia\n\nself\n\nphd\n\n\n\n\n\n\n\n\n\nAug 10, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat did the pig get to help with their dry skin?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nJul 10, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nMaking a custom RStudio theme\n\n\n\n\n\n\nR\n\nprogramming\n\ndesign\n\n\n\n\n\n\n\n\n\nMay 26, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nThe Health of Aboriginal Children in Western Australia in the Context of the Child Protection System\n\n\nMSPGH PhD Completion Seminar\n\n\n\nacademia\n\nresearch\n\nphd\n\n\n\n\n\n\n\n\n\nMay 10, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nTwo new RStudio themes\n\n\n\n\n\n\ncode\n\nR\n\ndesign\n\n\n\n\n\n\n\n\n\nApr 29, 2024\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nHow did the vegetable gardener lower their taxable income?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nOct 20, 2023\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nGoing to the ATSIMA 2023 conference\n\n\n\n\n\n\nacademia\n\nconference\n\nresearch\n\n\n\n\n\n\n\n\n\nOct 9, 2023\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nA brief introduction to research for health professionals\n\n\nResearch on the Run 2021, Ballarat Health Services\n\n\n\nresearch\n\nconsulting\n\n\n\n\n\n\n\n\n\nJul 17, 2023\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do you call music composed by apes?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nNov 29, 2022\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nFurther reflections on gender identity\n\n\n\n\n\n\nself\n\n\n\n\n\n\n\n\n\nMar 29, 2022\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nRMarkdown is great\n\n\n\n\n\n\nresearch\n\ncode\n\nR\n\n\n\n\n\n\n\n\n\nFeb 10, 2022\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhy are cows bad at the tightrope?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nNov 29, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhat I Didn’t Learn at University\n\n\n\n\n\n\nacademia\n\n\n\n\n\n\n\n\n\nAug 3, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nThinking About Gender Identity\n\n\n\n\n\n\nself\n\n\n\n\n\n\n\n\n\nJul 30, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nThe Health of Aboriginal Children in Western Australia and its Intersection with the Child Protection System\n\n\nPhD Confirmation Report, May 2021\n\n\n\nresearch\n\nacademia\n\nphd\n\n\n\n\n\n\n\n\n\nJun 28, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nPhD Confirmation Presentation\n\n\n\n\n\n\nresearch\n\nacademia\n\nphd\n\n\n\n\n\n\n\n\n\nJun 28, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nBasil Pesto\n\n\n\n\n\n\nfood\n\nself\n\n\n\n\n\n\n\n\n\nApr 24, 2021\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nWhy was Christmas ruined for the Germans?\n\n\n\n\n\n\njoke\n\n\n\n\n\n\n\n\n\nDec 3, 2020\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nDesigning a t-shirt\n\n\n\n\n\n\ndesign\n\nstatistics\n\nSSA\n\n\n\n\n\n\n\n\n\nDec 2, 2020\n\n\nBen Harrap\n\n\n\n\n\n\n\n\n\n\n\n\nMeet the dogs\n\n\n\n\n\n\nself\n\n\n\n\n\n\n\n\n\nDec 2, 2020\n\n\nBen Harrap\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "Hasthi UW Dissanayake, George Guruwiwi, J Dhurrkay, Josh C Tynan, Sabine Braat, Benjamin Harrap, Tim Trudgen, Sarah Hanieh, Bronwyn Clark, Michaela Spencer, Michael Christie, Emma Tonkin, Emily Armstrong, Leonard C Harrison, John M Wentworth, Julie K Brimblecombe, Beverley-Ann Biggs Medical Journal of AustraliaLink to article\n\n\nClick for abstract\n\n Objective\nTo evaluate the impact of a 4-month dietary and lifestyle program co-designed and led by Aboriginal and Torres Strait Islander people on weight and metabolic markers, diet, and physical activity in overweight and obese adults in a remote Indigenous community.\nStudy design\nSingle arm, pre–post intervention study.\nSetting, participants\nAdult residents (18–65 years) of a remote Northern Territory community with body mass index (BMI) values of at least 25 kg/m2 or waist circumferences exceeding 94 cm (men) or 80 cm (women).\nIntervention\nHope for Health, a culturally sensitive 4-month program supporting self-managed health improvement based on dietary and lifestyle change, 1 August to 30 November 2022.\nMain outcome measures\nWeight loss of at least 5%; changes in BMI, waist circumference, other metabolic markers (blood pressure, biomarkers of metabolic health and inflammation), diet, and physical activity; participant perceptions of the program.\nResults\nWe assessed outcomes for 55 participants who completed weight assessments at both baseline and program end (mean age, 42.5 years [standard deviation, 10.1 years]; 36 women [65%]). Forty participants lost and 15 gained weight; overall mean weight loss was 1.5 kg (95% confidence interval [CI], 0.5–2.4 kg), and ten participants (18%; 95% CI, 9–31%) achieved at least 5% weight reduction. The mean change in BMI (53 participants) was –0.60 kg/m2 (95% CI, –0.93 to –0.27 kg/m2), in waist circumference (53 participants) –3.2 cm (95% CI, –4.7 to –1.7 cm), and in low-density lipoprotein cholesterol level (37 participants) –0.28 mmol/L (95% CI, –0.47 to –0.08 mmol/L); the relative decline in the HbA1c level geometric mean (50 participants) was 11% (95% CI, 6–15%). The intake of breads and cereals (median change, –1.5 [95% CI, –2.0 to –1.0] serves/day) and sugar-sweetened beverages (–0.6 [95% CI, –1.4 to –0.1] serves/day) declined; the amount of moderate and vigorous physical activity increased by a median of 103 min/day (95% CI, 74–136 min/day; 19 participants). The program focus on integrating healthy bodies and networks of kin, healthy governance, vibrant language and ceremony, and a healthy environment were seen as central to its value and benefit.\nConclusions\nCommunity appreciation of the program and the improvements in cardiometabolic risk factors are encouraging, providing an example of a culturally sensitive, co-designed initiative led by Indigenous people for reducing the prevalence of chronic disease in remote areas."
  },
  {
    "objectID": "publications.html#improving-cardiometabolic-risk-factors-in-aboriginal-and-torres-strait-islander-people-in-northeast-arnhem-land-single-arm-trial-of-a-co-designed-dietary-and-lifestyle-program",
    "href": "publications.html#improving-cardiometabolic-risk-factors-in-aboriginal-and-torres-strait-islander-people-in-northeast-arnhem-land-single-arm-trial-of-a-co-designed-dietary-and-lifestyle-program",
    "title": "Publications",
    "section": "",
    "text": "Hasthi UW Dissanayake, George Guruwiwi, J Dhurrkay, Josh C Tynan, Sabine Braat, Benjamin Harrap, Tim Trudgen, Sarah Hanieh, Bronwyn Clark, Michaela Spencer, Michael Christie, Emma Tonkin, Emily Armstrong, Leonard C Harrison, John M Wentworth, Julie K Brimblecombe, Beverley-Ann Biggs Medical Journal of AustraliaLink to article\n\n\nClick for abstract\n\n Objective\nTo evaluate the impact of a 4-month dietary and lifestyle program co-designed and led by Aboriginal and Torres Strait Islander people on weight and metabolic markers, diet, and physical activity in overweight and obese adults in a remote Indigenous community.\nStudy design\nSingle arm, pre–post intervention study.\nSetting, participants\nAdult residents (18–65 years) of a remote Northern Territory community with body mass index (BMI) values of at least 25 kg/m2 or waist circumferences exceeding 94 cm (men) or 80 cm (women).\nIntervention\nHope for Health, a culturally sensitive 4-month program supporting self-managed health improvement based on dietary and lifestyle change, 1 August to 30 November 2022.\nMain outcome measures\nWeight loss of at least 5%; changes in BMI, waist circumference, other metabolic markers (blood pressure, biomarkers of metabolic health and inflammation), diet, and physical activity; participant perceptions of the program.\nResults\nWe assessed outcomes for 55 participants who completed weight assessments at both baseline and program end (mean age, 42.5 years [standard deviation, 10.1 years]; 36 women [65%]). Forty participants lost and 15 gained weight; overall mean weight loss was 1.5 kg (95% confidence interval [CI], 0.5–2.4 kg), and ten participants (18%; 95% CI, 9–31%) achieved at least 5% weight reduction. The mean change in BMI (53 participants) was –0.60 kg/m2 (95% CI, –0.93 to –0.27 kg/m2), in waist circumference (53 participants) –3.2 cm (95% CI, –4.7 to –1.7 cm), and in low-density lipoprotein cholesterol level (37 participants) –0.28 mmol/L (95% CI, –0.47 to –0.08 mmol/L); the relative decline in the HbA1c level geometric mean (50 participants) was 11% (95% CI, 6–15%). The intake of breads and cereals (median change, –1.5 [95% CI, –2.0 to –1.0] serves/day) and sugar-sweetened beverages (–0.6 [95% CI, –1.4 to –0.1] serves/day) declined; the amount of moderate and vigorous physical activity increased by a median of 103 min/day (95% CI, 74–136 min/day; 19 participants). The program focus on integrating healthy bodies and networks of kin, healthy governance, vibrant language and ceremony, and a healthy environment were seen as central to its value and benefit.\nConclusions\nCommunity appreciation of the program and the improvements in cardiometabolic risk factors are encouraging, providing an example of a culturally sensitive, co-designed initiative led by Indigenous people for reducing the prevalence of chronic disease in remote areas."
  },
  {
    "objectID": "publications.html#mental-and-neurodevelopmental-health-needs-of-aboriginal-children-with-experience-of-out-of-home-care-a-western-australian-data-linkage-study",
    "href": "publications.html#mental-and-neurodevelopmental-health-needs-of-aboriginal-children-with-experience-of-out-of-home-care-a-western-australian-data-linkage-study",
    "title": "Publications",
    "section": "Mental and neurodevelopmental health needs of Aboriginal children with experience of out-of-home care: a Western Australian data-linkage study",
    "text": "Mental and neurodevelopmental health needs of Aboriginal children with experience of out-of-home care: a Western Australian data-linkage study\nBenjamin Harrap, Alison Gibberd, Melissa O’Donnell, Jocelyn Jones, Richard Chenhall, Bridgette McNamara, Koen Simons, Sandra Eades Australian and New Zealand Journal of Public HealthLink to article\n\n\nClick for abstract\n\n Objective\nTo identify additional mental and neurodevelopmental health needs of Aboriginal children born in Western Australia, who are placed in out-of-home care (OOHC), relative to Aboriginal children born in Western Australia who were not placed.\nMethods\nData-linkage of hospitalisations, health registries and child protective services data for all Aboriginal children born in WA between 2000 and 2013 was used. Children placed in out-of-home care between 2000 and 2019 were matched to children never placed and prevalence and cumulative incidence estimates of mental and neurodevelopmental health conditions were compared.\nResults\nChildren placed in out-of-home care had a three times greater prevalence of mental and neurodevelopmental health conditions generally. The prevalence of foetal alcohol spectrum disorder was ten times higher, and post-traumatic stress disorder was seven times higher for those placed in out-of-home care. Cumulative incidence plots highlighted for different conditions the ages at which the rate of diagnosis diverges between the two groups.\nConclusions\nChildren placed in out-of-home care had greater mental and neurodevelopmental health needs generally when compared to children never placed in out-of-home care.\nImplications for Public Health\nChild protective services must ensure culturally safe, comprehensive, wrap-around services for Aboriginal children and their families are provided. Approaches should build on the strength of children, families and culture and avoid stigmatising children and their parents."
  },
  {
    "objectID": "publications.html#aboriginal-children-placed-in-out-of-home-care-pathways-through-the-child-protection-system",
    "href": "publications.html#aboriginal-children-placed-in-out-of-home-care-pathways-through-the-child-protection-system",
    "title": "Publications",
    "section": "Aboriginal children placed in out-of-home care: Pathways through the child protection system",
    "text": "Aboriginal children placed in out-of-home care: Pathways through the child protection system\nFernando Lima, Melissa O’Donnell, Alison Gibberd, Kathleen Falster, Emily Banks, Jocelyn Jones, Robyn Williams, Francine Eades, Benjamin Harrap, Richard Chenhall, Olivia Octoman, Sandra Eades Australian Social WorkLink to article\n\n\nClick for abstract\n\n The overrepresentation of Aboriginal and Torres Strait Islander (respectfully referred to hereafter as “Aboriginal”) children in the child protection system is a concern in Australia, with Aboriginal children placed in out-of-home care at a rate 11 times that of non-Aboriginal children. This study utilised linked administrative data to determine the longitudinal child protection pathways from birth to age 10 years for a cohort of 15,815 Aboriginal children born in Western Australia between 2000 and 2006. In total, 9,269 (59%) children did not have any contact with child protection between one year prior to birth and their 11th birthday. Conversely, 6,546 (41%) Aboriginal children were involved with child protection during the study period, with 1,405 (9%) children placed in out-of-home care. Infants who had a child protection notification were more likely than other age groups to have a substantiated notification of abuse and neglect and placed in out-of-home care. More than half (56%) of all children were predominantly placed in kinship care; however, only 22% had their first placement with kinship carers. Aboriginal-led strategies together with the support and commitment of all levels of government are required to reduce entry into care and improve outcomes for Aboriginal children in care."
  },
  {
    "objectID": "publications.html#cumulative-incidence-of-child-protection-system-contacts-among-a-cohort-of-western-australian-aboriginal-children-born-2000-to-2013",
    "href": "publications.html#cumulative-incidence-of-child-protection-system-contacts-among-a-cohort-of-western-australian-aboriginal-children-born-2000-to-2013",
    "title": "Publications",
    "section": "Cumulative incidence of child protection system contacts among a cohort of Western Australian Aboriginal children born 2000 to 2013",
    "text": "Cumulative incidence of child protection system contacts among a cohort of Western Australian Aboriginal children born 2000 to 2013\nBenjamin Harrap, Alison Gibberd, Melissa O’Donnell, Koen Simons, Jocelyn Jones, Fernando Lima, Daniel McAullay, Kathleen Falster, Emily Banks, Sandra Eades Child Abuse & NeglectLink to article\n\n\nClick for abstract\n\n Background\nReducing the over-representation of Aboriginal children in the child protection system is a key target for the Australian government.\nObjective\nWe aimed to provide more recent evidence on the population-level cumulative incidence of contacts for Aboriginal children with child protective services (CPS) in Western Australia (WA).\nParticipants and Setting\nLinked administrative data was provided for WA CPS between 2000 and 2015 for 33,709 Aboriginal children born in WA between 2000 and 2013.\nMethods\nDescriptive summaries and cumulative incidence estimates were used to examine changes in CPS contact trends over time and within sibling groups.\nResults\nThere was an increase in early-childhood contacts for children born more recently, with 7.6 % and 2.3 % of children born in 2000–2001 having a notification and placement in out-of-home care by age one, respectively, compared to 15.1 % and 4.3 % of children born in 2012–2013. Among sibling groups where at least one sibling had a CPS contact, approximately half of children had their first contacts on the same date as another sibling. For children born after one of their siblings had been placed in out-of-home care, 31.9 % had themselves been placed in out-of-home care by age one.\nConclusions\nMultiple children tend to be placed into out-of-home care when at least one sibling is, which is likely to have a significant impact on families affected. The additional risk of placement also carries over to children born after the first removal in a sibling group, highlighting the need for further support to prevent future removals."
  },
  {
    "objectID": "publications.html#a-randomised-controlled-trial-of-email-versus-mailed-invitation-letter-in-a-national-longitudinal-survey-of-physicians",
    "href": "publications.html#a-randomised-controlled-trial-of-email-versus-mailed-invitation-letter-in-a-national-longitudinal-survey-of-physicians",
    "title": "Publications",
    "section": "A randomised controlled trial of email versus mailed invitation letter in a national longitudinal survey of physicians",
    "text": "A randomised controlled trial of email versus mailed invitation letter in a national longitudinal survey of physicians\nBenjamin Harrap, Tamara Taylor, Grant Russell, Anthony Scott PLoS OneLink to article\n\n\nClick for abstract\n\n Despite their low cost, the use of email invitations to distribute surveys to medical practitioners have been associated with lower response rates. This research compares the difference in response rates from using email approach plus online completion rather than a mailed invitation letter plus a choice of online or paper completion. A parallel randomised controlled trial was conducted during the 11th annual wave of the nationally representative Medicine in Australia: Balancing Employment and Life (MABEL) longitudinal survey of doctors. The control group was invited using a mailed paper letter (including a paper survey plus instructions to complete online) and three mailed paper reminders. The intervention group was approached in the same way apart from the second reminder when they were approached by email only. The primary outcome is the response rate and the statistical analysis was blinded. 18,247 doctors were randomly allocated to the control (9,125) or intervention group (9,127), with 9,108 and 9,107 included in the analysis. Using intention to treat analysis, the response rate in the intervention group was 35.92% compared to 37.59% in the control group, a difference of -1.66 percentage points (95% CI: -3.06 to -0.26). The difference was larger for General Practitioners (-2.76 percentage points, 95% CI: -4.65 to -0.87) compared to other specialists (-0.47 percentage points, 95% CI: -2.53 to 1.60). For those who supplied an email address, the average treatment effect on the treated was higher at -2.63 percentage points (95% CI: -4.50 to -0.75) for all physicians, -3.17 percentage points (95% CI: -5.83 to -0.53) for General Practitioners, and -2.1 percentage points (95% CI: -4.75 to 0.56) for other specialists. For qualified physicians, using email to invite participants to complete a survey leads to lower response rates compared to a mailed letter. Lower response rates need to be traded off with the lower costs of using email rather than mailed letters."
  },
  {
    "objectID": "publications.html#feasibility-and-acceptability-of-low-intensity-mental-health-support-via-a-telehealth-enabled-network-for-adults-with-type-1-and-type-2-diabetes-the-listen-pilot-study",
    "href": "publications.html#feasibility-and-acceptability-of-low-intensity-mental-health-support-via-a-telehealth-enabled-network-for-adults-with-type-1-and-type-2-diabetes-the-listen-pilot-study",
    "title": "Publications",
    "section": "Feasibility and acceptability of “low-intensity mental health support via a telehealth-enabled network” for adults with type 1 and type 2 diabetes: The LISTEN pilot study",
    "text": "Feasibility and acceptability of “low-intensity mental health support via a telehealth-enabled network” for adults with type 1 and type 2 diabetes: The LISTEN pilot study\nEdith E. Holloway, Shikha Gray, Jennifer Halliday, Benjamin Harrap, Carolyn Hines, Timothy C. Skinner, Jane Speight & Christel Hendrieckx Pilot and Feasibility StudiesLink to article\n\n\nClick for abstract\n\n Background\nThis study examined the feasibility and acceptability of the low-intensity mental health support via telehealth-enabled network (LISTEN) intervention, for adults with diabetes, facilitated by diabetes health professionals (HPs).\nMethods\nLISTEN training. Three HPs participated in three half-day online workshops and applied their learnings during training cases (maximum four). Competency was assessed with a validated tool and achieved ‘satisfactory’ ratings for three consecutive sessions. LISTEN pilot. A single-group, pre-post study (up to four LISTEN sessions) with online assessments at baseline, post-intervention, and 4-week follow-up. Eligible participants were adults with type 1 or type 2 diabetes, with diabetes distress, but excluded if they had moderate/severe depressive and/or anxiety symptoms. Feasibility was assessed via recruitment and session completion rates. Acceptability was assessed with post-intervention self-report data. Changes in diabetes distress and general emotional well-being from baseline (T1) were explored at post-intervention (T2) and at 4-week follow-up (T3).\nResults\nTwo HPs achieved competency (median training case sessions required: 7) and progressed to deliver LISTEN in the pilot study. In the pilot, N = 16 adults (Med [IQR] age: 60 [37–73] years; 13 women) with diabetes participated (median sessions per participant: 2). Twelve participants (75%) completed the post-intervention assessment (T2): 92% endorsed the number of sessions offered as ‘just right’, 75% felt comfortable talking with the HP, and 67% were satisfied with LISTEN. Perceived limitations were the structured format and narrow scope of problems addressed. Diabetes distress scores were lower post-intervention.\nConclusions\nThis pilot demonstrates the feasibility of training HPs to deliver LISTEN, and the acceptability and potential benefits of LISTEN for adults with diabetes. The findings highlight adaptations that may enhance the delivery of, and satisfaction with, LISTEN that will be tested in a hybrid type 1 effectiveness-implementation trial."
  },
  {
    "objectID": "publications.html#the-statistical-society-of-australia-equity-diversity-and-inclusivity-survey-report-2022",
    "href": "publications.html#the-statistical-society-of-australia-equity-diversity-and-inclusivity-survey-report-2022",
    "title": "Publications",
    "section": "The Statistical Society of Australia Equity, Diversity, and Inclusivity Survey Report 2022",
    "text": "The Statistical Society of Australia Equity, Diversity, and Inclusivity Survey Report 2022\nBenjamin Harrap, Jessica Kasza, Nicole De La Mata, Katrina Scurrah, Karen Lamb, Matthew Spittal, Andrew van Burgel, Rushani Wijesuriya Statistical Society of AustraliaLink to article\n\n\nClick for abstract\n\n The Statistical Society of Australia’s (SSA) Equity Diversity and Inclusivity (EDI) Comittee conducted a survey on EDI issues as they related to the SSA, seeking responses from both members and non-members to open and closed questions. Sixty-four responses were received over a one-and-a-half month period. Eighty-seven percent of respondents were current members and 56% did not consider themselves as coming from an under-represented background. The majority of respondents, regardless of background, considered the SSA to be an inclusive and welcoming organisation, however for those from an under-represented background only half always felt welcome at SSA-run events. Responses to the open-ended questions generated discussion among the EDI Committee and broader Executive Committee, which has resulted in the work being done to address how the SSA recruits members to join its councils, what topics the SSA should make public statements on, and making information on the organisational structure of the SSA more easily accessible to new members."
  },
  {
    "objectID": "publications.html#australias-superior-skilled-migration-outcomes-compared-with-canadas",
    "href": "publications.html#australias-superior-skilled-migration-outcomes-compared-with-canadas",
    "title": "Publications",
    "section": "Australia’s superior skilled migration outcomes compared with Canada’s",
    "text": "Australia’s superior skilled migration outcomes compared with Canada’s\nBenjamin Harrap, Lesleyanne Hawthorne, Margaret Holland, James Ted McDonald, Anthony Scott International MigrationLink to article\n\n\nClick for abstract\n\n Australia and Canada are global exemplars of skilled migration policy, designed to have important effects on economic growth. This article assesses the development and outcomes of their permanent migration programmes for a range of regulated professions. We compare the matched census data from both countries in 2016 and then examine the key drivers of the major differences found through qualitative interviews. Although the trends in numbers and source countries and characteristics of skilled migrants are similar, their earnings relative to equivalent native-born earnings are far lower in Canada than in Australia. This reflects the Australian government’s greater power to initiate and drive policy reform agendas, early strategies designed to enhance foreign credential recognition and a heightened role for employers including through two-step migration. Canada has recently announced significantly expanded migration intakes. These seem unlikely to lead to strong economic growth, unless entry requirements are tightened and more targeted support provided."
  },
  {
    "objectID": "publications.html#a-pedometer-guided-physical-activity-intervention-for-obese-pregnant-women-the-fit-mum-study-randomized-feasibility-study",
    "href": "publications.html#a-pedometer-guided-physical-activity-intervention-for-obese-pregnant-women-the-fit-mum-study-randomized-feasibility-study",
    "title": "Publications",
    "section": "A pedometer-guided physical activity intervention for obese pregnant women (the fit MUM study): Randomized feasibility study",
    "text": "A pedometer-guided physical activity intervention for obese pregnant women (the fit MUM study): Randomized feasibility study\nJai N Darvall, Andrew Wang, Mohamed Nusry Nazeem, Cheryce L Harrison, Lauren Clarke, Chennelle Mendoza, Anna Parker, Benjamin Harrap, Glyn Teale, David Story, Elizabeth Hessian JMIR mHealth and uHealthLink to article\n\n\nClick for abstract\n\n Background\nObesity in pregnancy is a growing problem worldwide, with excessive gestational weight gain (GWG) occurring in the majority of pregnancies. This significantly increases risks to both mother and child. A major contributor to both prepregnancy obesity and excessive GWG is physical inactivity; however, past interventions targeting maternal weight gain and activity levels during the antenatal period have been ineffective in women who are already overweight. Pedometer-guided activity may offer a novel solution for increasing activity levels in this population.\nObjective\nThis initial feasibility randomized controlled trial aimed to test a pedometer-based intervention to increase activity and reduce excessive GWG in pregnant women.\nMethods\nWe supplied 30 pregnant women with obesity a Fitbit Zip pedometer and randomized them into 1 of 3 groups: control (pedometer only), app (pedometer synced to patients’ personal smartphone, with self-monitoring of activity), or app-coach (addition of a health coach–delivered behavioral change program). Feasibility outcomes included participant compliance with wearing pedometers (days with missing pedometer data), data syncing, and data integrity. Activity outcomes (step counts and active minutes) were analyzed using linear mixed models and generalized estimating equations.\nResults\nA total of 30 participants were recruited within a 10-week period, with a dropout rate of 10% (3/30; 2 withdrawals and 1 stillbirth); 27 participants thus completed the study. Mean BMI in all groups was ≥35 kg/m2. Mean (SD) percentage of missing data days were 23.4% (20.6%), 39.5% (32.4%), and 21.1% (16.0%) in control, app group, and app-coach group patients, respectively. Estimated mean baseline activity levels were 14.5 active min/day and 5455 steps/day, with no significant differences found in activity levels between groups, with mean daily step counts in all groups remaining in the sedentary (5000 steps/day) or low activity (5000-7499 steps/day) categories for the entire study duration. There was a mean decrease of 7.8 steps/day for each increase in gestation day over the study period (95% CI 2.91 to 12.69, P=.002).\nConclusions\nActivity data syncing with a personal smartphone is feasible in a cohort of pregnant women with obesity. However, our results do not support a future definitive study in its present form. Recruitment and retention rates were adequate, as was activity data syncing to participants’ smartphones. A follow-up interventional trial seeking to reduce GWG and improve activity in this population must focus on improving compliance with activity data recording and behavioral interventions delivered."
  },
  {
    "objectID": "publications.html#medicine-in-australia-balancing-employment-and-life-mabel.-mabel-user-manual-wave-11-release",
    "href": "publications.html#medicine-in-australia-balancing-employment-and-life-mabel.-mabel-user-manual-wave-11-release",
    "title": "Publications",
    "section": "Medicine in Australia: Balancing employment and life (MABEL). MABEL user manual: Wave 11 release",
    "text": "Medicine in Australia: Balancing employment and life (MABEL). MABEL user manual: Wave 11 release\nSandie Szawlowski, Ben Harrap, Anne Leahy, Anthony Scott Melbourne Institute: Applied Economic & Social ResearchLink to article\n\n\nClick for abstract"
  },
  {
    "objectID": "publications.html#incidence-of-treated-first-episode-psychosis-from-an-australian-early-intervention-service-and-its-association-with-neighbourhood-characteristics",
    "href": "publications.html#incidence-of-treated-first-episode-psychosis-from-an-australian-early-intervention-service-and-its-association-with-neighbourhood-characteristics",
    "title": "Publications",
    "section": "Incidence of treated first episode psychosis from an Australian early intervention service and its association with neighbourhood characteristics",
    "text": "Incidence of treated first episode psychosis from an Australian early intervention service and its association with neighbourhood characteristics\nScott Eaton, Benjamin Harrap, Linglee Downey, Kristen Thien, Meghan Bowtell, Melissa Bardell-Williams, Aswin Ratheesh, Patrick McGorry, Brian O’Donoghue Schizophrenia ResearchLink to article\n\n\nClick for abstract\n\n Objectives\nPsychotic disorder incidence varies geographically and is associated with neighbourhood characteristics, including social deprivation, population density, unemployment, social capital or social fragmentation. Yet it is not known whether these findings are applicable to Australia’s unique geography. This study aimed to determine whether the incidence of first episode psychosis (FEP) varies according to neighbourhood characteristics in an Australian cohort.\nMethod\nThis study included all young people, aged 15 to 24, with an FEP who attended Orygen Youth Health in Melbourne, from a geographically defined catchment area encompassing Northern and Western Melbourne, over a 44-month period. Neighbourhood demographic data was collected from the 2011 Australian National Census. Negative binomial regression was used to determine incidence rate ratios controlled for age, sex and migrant status.\nResults\nA total of 747 young people had an FEP during the 44-month study period and 722 were included in this study. Of these, 58.0% were males and 67.9% had a non-affective psychotic disorder; the mean age of the cohort was 19.1 years. The incidence of FEP in young people aged 15 to 24 in the catchment area was 123.2 per 100,000 person-years. There was a higher incidence of FEP in neighbourhoods of greatest social deprivation (IRR = 1.65, CI = 1.06–2.51, p = .02), highest unemployment (IRR = 1.56, CI = 1.04–2.35, p = .03) and above average social fragmentation (IRR = 1.42, CI = 1.02–1.97, p = .04), when controlled for age, sex and migrant status.\nConclusions\nThis study highlights variation in psychotic disorder incidence and the need for this disparity to be reflected in appropriate resource allocation."
  }
]